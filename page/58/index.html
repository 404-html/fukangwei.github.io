<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="泥腿子出身">
<meta property="og:url" content="http://fukangwei.gitee.io/page/58/index.html">
<meta property="og:site_name" content="泥腿子出身">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="泥腿子出身">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/page/58/">





  <title>泥腿子出身</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泥腿子出身</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/Keras之图像预处理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/Keras之图像预处理/" itemprop="url">Keras之图像预处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T18:04:55+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="ImageDataGenerator类"><a href="#ImageDataGenerator类" class="headerlink" title="ImageDataGenerator类"></a>ImageDataGenerator类</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.ImageDataGenerator(</span><br><span class="line">    featurewise_center=<span class="keyword">False</span>, samplewise_center=<span class="keyword">False</span>, featurewise_std_normalization=<span class="keyword">False</span>,</span><br><span class="line">    samplewise_std_normalization=<span class="keyword">False</span>, zca_whitening=<span class="keyword">False</span>, zca_epsilon=<span class="number">1e-06</span>, rotation_range=<span class="number">0.0</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.0</span>, height_shift_range=<span class="number">0.0</span>, brightness_range=<span class="keyword">None</span>, shear_range=<span class="number">0.0</span>,</span><br><span class="line">    zoom_range=<span class="number">0.0</span>, channel_shift_range=<span class="number">0.0</span>, fill_mode=<span class="string">'nearest'</span>, cval=<span class="number">0.0</span>, horizontal_flip=<span class="keyword">False</span>,</span><br><span class="line">    vertical_flip=<span class="keyword">False</span>, rescale=<span class="keyword">None</span>, preprocessing_function=<span class="keyword">None</span>, data_format=<span class="keyword">None</span>, validation_split=<span class="number">0.0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>通过实时数据增强生成张量图像数据批次，数据将不断循环。</p>
<ul>
<li><code>featurewise_center</code>：布尔值，将输入数据的均值设置为<code>0</code>，逐特征进行。</li>
<li><code>samplewise_center</code>：布尔值，将每个样本的均值设置为<code>0</code>。</li>
<li><code>featurewise_std_normalization</code>：布尔值，将输入除以数据标准差，逐特征进行。</li>
<li><code>samplewise_std_normalization</code>：布尔值，将每个输入除以其标准差。</li>
<li><code>zca_epsilon</code>：<code>ZCA</code>白化的<code>epsilon</code>值，默认为<code>1e-6</code>。</li>
<li><code>zca_whitening</code>：布尔值，是否应用<code>ZCA</code>白化。</li>
<li><code>rotation_range</code>：整数，随机旋转的度数范围。</li>
<li><code>width_shift_range</code>：浮点数、一维数组或整数：</li>
</ul>
<ol>
<li><code>float</code>：如果小于<code>1</code>，则是除以总宽度的值；如果大于等于<code>1</code>，则为像素值。</li>
<li><code>一维数组</code>：数组中的随机元素。</li>
<li><code>int</code>：来自间隔(<code>-width_shift_range, +width_shift_range</code>)之间的整数个像素。</li>
</ol>
<p><code>width_shift_range</code>为<code>2</code>时，可能值是整数<code>[-1, 0, +1]</code>，与<code>width_shift_range = [-1, 0, +1]</code>相同；而<code>width_shift_range</code>为<code>1.0</code>时，可能值是<code>[-1.0, +1.0)</code>之间的浮点数。</p>
<ul>
<li><code>height_shift_range</code>：浮点数、一维数组或整数：</li>
</ul>
<ol>
<li><code>float</code>：如果小于<code>1</code>，则是除以总宽度的值；如果大于等于<code>1</code>，则为像素值。</li>
<li><code>一维数组</code>：数组中的随机元素。</li>
<li><code>int</code>：来自间隔<code>(-height_shift_range, +height_shift_range)</code>之间的整数个像素。</li>
</ol>
<p><code>height_shift_range</code>为<code>2</code>时，可能值是整数<code>[-1, 0, +1]</code>，与<code>height_shift_range = [-1, 0, +1]</code>相同；而<code>height_shift_range</code>为<code>1.0</code>时，可能值是<code>[-1.0, +1.0)</code>之间的浮点数。</p>
<ul>
<li><code>shear_range</code>：浮点数，剪切强度(以弧度逆时针方向剪切角度)。</li>
<li><code>zoom_range</code>：浮点数或<code>[lower, upper]</code>，随机缩放范围。如果是浮点数，<code>[lower, upper] = [1 - zoom_range, 1 + zoom_range]</code>。</li>
<li><code>channel_shift_range</code>：浮点数，随机通道转换的范围。</li>
<li><code>fill_mode</code>：<code>constant</code>、<code>nearest</code>、<code>reflect</code>和<code>wrap</code>之一。输入边界以外的点根据给定的模式填充：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>选项</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>constant</code></td>
<td><code>kkkkkkkk&#124;abcd&#124;kkkkkkkk(cval = k)</code></td>
</tr>
<tr>
<td><code>nearest</code></td>
<td><code>aaaaaaaa&#124;abcd&#124;dddddddd</code></td>
</tr>
<tr>
<td><code>reflect</code></td>
<td><code>abcddcba&#124;abcd&#124;dcbaabcd</code></td>
</tr>
<tr>
<td><code>wrap</code></td>
<td><code>abcdabcd&#124;abcd&#124;abcdabcd</code></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><code>cval</code>：浮点数或整数，用于边界之外的点的值。</li>
<li><code>horizontal_flip</code>：布尔值，随机水平翻转。</li>
<li><code>vertical_flip</code>：布尔值，随机垂直翻转。</li>
<li><code>rescale</code>：重缩放因子，默认为<code>None</code>。如果是<code>None</code>或<code>0</code>，则不进行缩放，否则将数据乘以所提供的值(在应用任何其他转换之前)。</li>
<li><code>preprocessing_function</code>：应用于每个输入的函数，这个函数会在任何其他改变之前运行。这个函数需要一个参数：一张图像(秩为<code>3</code>的<code>Numpy</code>张量)，并且应该输出一个同尺寸的<code>Numpy</code>张量。</li>
<li><code>data_format</code>：图像数据格式，<code>channels_first</code>或<code>channels_last</code>。<code>channels_last</code>模式表示图像输入尺寸应该为(<code>samples, height, width, channels</code>)；<code>channels_first</code>模式表示输入尺寸应该为(<code>samples, channels, height, width</code>)。默认为在<code>Keras</code>配置文件<code>~/.keras/keras.json</code>中的<code>image_data_format</code>值。如果你从未设置它，那它就是<code>channels_last</code>。</li>
<li><code>validation_split</code>：浮点数，保留用于验证的图像的比例(严格在<code>0</code>和<code>1</code>之间)。</li>
</ul>
<p>&emsp;&emsp;使用<code>flow</code>的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">y_train = np_utils.to_categorical(y_train, num_classes)</span><br><span class="line">y_test = np_utils.to_categorical(y_test, num_classes)</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    featurewise_center=<span class="keyword">True</span>, featurewise_std_normalization=<span class="keyword">True</span>, rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>, height_shift_range=<span class="number">0.2</span>, horizontal_flip=<span class="keyword">True</span>)</span><br><span class="line">datagen.fit(x_train)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 使用实时数据增益的批数据对模型进行拟合</span></span><br><span class="line">model.fit_generator(datagen.flow(x_train, y_train, batch_size=<span class="number">32</span>),</span><br><span class="line">                    steps_per_epoch=len(x_train) / <span class="number">32</span>, epochs=epochs)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):  <span class="comment"># 这里有一个更“手动”的例子</span></span><br><span class="line">    print(<span class="string">'Epoch'</span>, e)</span><br><span class="line">    batches = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> datagen.flow(x_train, y_train, batch_size=<span class="number">32</span>):</span><br><span class="line">        model.fit(x_batch, y_batch)</span><br><span class="line">        batches += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> batches &gt;= len(x_train) / <span class="number">32</span>:</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 我们需要手动打破循环，因为生成器会无限循环</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用<code>flow_from_directory</code>的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span> / <span class="number">255</span>, shear_range=<span class="number">0.2</span>,</span><br><span class="line">                                   zoom_range=<span class="number">0.2</span>, horizontal_flip=<span class="keyword">True</span>)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span> / <span class="number">255</span>)</span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    <span class="string">'data/train'</span>, target_size=(<span class="number">150</span>, <span class="number">150</span>), batch_size=<span class="number">32</span>, class_mode=<span class="string">'binary'</span>)</span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    <span class="string">'data/validation'</span>, target_size=(<span class="number">150</span>, <span class="number">150</span>), batch_size=<span class="number">32</span>, class_mode=<span class="string">'binary'</span>)</span><br><span class="line">model.fit_generator(train_generator, steps_per_epoch=<span class="number">2000</span>, epochs=<span class="number">50</span>,</span><br><span class="line">                    validation_data=validation_generator, validation_steps=<span class="number">800</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;同时转换图像和蒙版(<code>mask</code>)的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">data_gen_args = dict(featurewise_center=<span class="keyword">True</span>, featurewise_std_normalization=<span class="keyword">True</span>,</span><br><span class="line">                     rotation_range=<span class="number">90.</span>, width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">                     height_shift_range=<span class="number">0.1</span>, zoom_range=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 创建两个相同参数的实例</span></span><br><span class="line">image_datagen = ImageDataGenerator(**data_gen_args)</span><br><span class="line">mask_datagen = ImageDataGenerator(**data_gen_args)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 为fit和flow函数提供相同的种子和关键字参数</span></span><br><span class="line">seed = <span class="number">1</span></span><br><span class="line">image_datagen.fit(images, augment=<span class="keyword">True</span>, seed=seed)</span><br><span class="line">mask_datagen.fit(masks, augment=<span class="keyword">True</span>, seed=seed)</span><br><span class="line">​</span><br><span class="line">image_generator = image_datagen.flow_from_directory(<span class="string">'data/images'</span>, class_mode=<span class="keyword">None</span>, seed=seed)</span><br><span class="line">mask_generator = mask_datagen.flow_from_directory(<span class="string">'data/masks'</span>, class_mode=<span class="keyword">None</span>, seed=seed)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 将生成器组合成一个产生图像和蒙版(mask)的生成器</span></span><br><span class="line">train_generator = zip(image_generator, mask_generator)</span><br><span class="line">model.fit_generator(train_generator, steps_per_epoch=<span class="number">2000</span>, epochs=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<h3 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h3><p>&emsp;&emsp;将数据生成器用于某些示例数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.fit(x, augment=<span class="keyword">False</span>, rounds=<span class="number">1</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>它基于一组样本数据，计算与数据转换相关的内部数据统计。当且仅当<code>featurewise_center</code>、<code>featurewise_std_normalization</code>或<code>zca_whitening</code>设置为<code>True</code>时才需要。</p>
<ul>
<li><code>x</code>：样本数据，秩应该为<code>4</code>。对于灰度数据，通道轴的值应该为<code>1</code>；对于<code>RGB</code>数据，值应该为<code>3</code>。</li>
<li><code>augment</code>：布尔值，是否使用随机样本扩张。</li>
<li><code>rounds</code>：整数。如果使用数据增强(<code>augment=True</code>)，表明在数据上进行多少次增强。</li>
<li><code>seed</code>：整数，随机种子。</li>
</ul>
<h3 id="flow"><a href="#flow" class="headerlink" title="flow"></a>flow</h3><p>&emsp;&emsp;采集数据和标签数组，生成批量增强数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.flow(</span><br><span class="line">    x, y=<span class="keyword">None</span>, batch_size=<span class="number">32</span>, shuffle=<span class="keyword">True</span>, sample_weight=<span class="keyword">None</span>, seed=<span class="keyword">None</span>,</span><br><span class="line">    save_to_dir=<span class="keyword">None</span>, save_prefix=<span class="string">''</span>, save_format=<span class="string">'png'</span>, subset=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>x</code>：输入数据，秩为<code>4</code>的<code>Numpy</code>矩阵或元组。如果是元组，第一个元素应该包含图像，第二个元素是另一个<code>Numpy</code>数组或一列<code>Numpy</code>数组，它们不经过任何修改就传递给输出。可用于将模型杂项数据与图像一起输入。对于灰度数据，图像数组的通道轴的值应该为<code>1</code>，而对于<code>RGB</code>数据，其值应该为<code>3</code>。</li>
<li><code>y</code>：标签。</li>
<li><code>batch_size</code>：整数。</li>
<li><code>shuffle</code>：布尔值。</li>
<li><code>sample_weight</code>：样本权重。</li>
<li><code>seed</code>：整数。</li>
<li><code>save_to_dir</code>：<code>None</code>或字符串。这使您可以选择指定要保存的正在生成的增强图片的目录(用于可视化您正在执行的操作)。</li>
<li><code>save_prefix</code>：字符串，保存图片的文件名前缀(仅当<code>save_to_dir</code>设置时可用)。</li>
<li><code>save_format</code>：<code>png</code>和<code>jpeg</code>之一(仅当<code>save_to_dir</code>设置时可用)。</li>
<li><code>subset</code>：数据子集(<code>training</code>或<code>validation</code>)，如果在<code>ImageDataGenerator</code>中设置了<code>validation_split</code>。</li>
</ul>
<p>该函数返回一个生成元组(<code>x, y</code>)的<code>Iterator</code>，其中<code>x</code>是图像数据的<code>Numpy</code>数组(在单张图像输入时)，或<code>Numpy</code>数组列表(在多张图像输入时)，<code>y</code>是对应标签的<code>Numpy</code>数组。如果<code>sample_weight</code>不是<code>None</code>，生成的元组形式为(<code>x, y, sample_weight</code>)。如果<code>y</code>是<code>None</code>，只有<code>Numpy</code>数组<code>x</code>被返回。</p>
<h3 id="flow-from-directory"><a href="#flow-from-directory" class="headerlink" title="flow_from_directory"></a>flow_from_directory</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.flow_from_directory(</span><br><span class="line">    directory, target_size=(<span class="number">256</span>, <span class="number">256</span>), color_mode=<span class="string">'rgb'</span>, classes=<span class="keyword">None</span>,</span><br><span class="line">    class_mode=<span class="string">'categorical'</span>, batch_size=<span class="number">32</span>, shuffle=<span class="keyword">True</span>, seed=<span class="keyword">None</span>,</span><br><span class="line">    save_to_dir=<span class="keyword">None</span>, save_prefix=<span class="string">''</span>, save_format=<span class="string">'png'</span>,</span><br><span class="line">    follow_links=<span class="keyword">False</span>, subset=<span class="keyword">None</span>, interpolation=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>directory</code>：目标目录的路径，每个类应该包含一个子目录。任何在子目录树下的<code>PNG</code>、<code>JPG</code>、<code>BMP</code>、<code>PPM</code>或<code>TIF</code>图像，都将被包含在生成器中。</li>
<li><code>target_size</code>：整数元组(<code>height, width</code>)，所有的图像将被调整到的尺寸。</li>
<li><code>color_mode</code>：<code>grayscale</code>和<code>rbg</code>之一，图像是否被转换成<code>1</code>或<code>3</code>个颜色通道。</li>
<li><code>classes</code>：可选的类的子目录列表(例如<code>[&#39;dogs&#39;, &#39;cats&#39;]</code>)。如果未提供，类的列表将自动从<code>directory</code>下的子目录名称或结构中推断出来，其中每个子目录都将被作为不同的类(类名将按字典序映射到标签的索引)。包含从类名到类索引的映射的字典可以通过<code>class_indices</code>属性获得。</li>
<li><p><code>class_mode</code>：<code>categorical</code>、<code>binary</code>、<code>sparse</code>、<code>input</code>或<code>None</code>之一，决定返回的标签数组的类型：<code>categorical</code>是<code>2</code>维<code>one-hot</code>编码标签，<code>binary</code>是一维二进制标签，<code>sparse</code>是一维整数标签，<code>input</code>是与输入图像相同的图像(主要用于自动编码器)。如果为<code>None</code>，则不返回标签(生成器将只产生批量的图像数据，对于<code>model.predict_generator</code>、<code>model.evaluate_generator</code>等很有用)。请注意，如果<code>class_mode</code>为<code>None</code>，那么数据仍然需要驻留在<code>directory</code>的子目录中才能正常工作。</p>
</li>
<li><p><code>batch_size</code>：一批数据的大小。</p>
</li>
<li><code>shuffle</code>：是否混洗数据。</li>
<li><code>seed</code>：随机种子，用于混洗和转换。</li>
<li><code>save_to_dir</code>：<code>None</code>或字符串。这使你可以最佳地指定正在生成的增强图片要保存的目录(用于可视化你在做什么)。</li>
<li><code>save_prefix</code>：字符串，保存图片的文件名前缀(仅当<code>save_to_dir</code>设置时可用)。</li>
<li><code>save_format</code>：<code>png</code>和<code>jpeg</code>之一(仅当<code>save_to_dir</code>设置时可用)。</li>
<li><code>follow_links</code>：是否跟踪类子目录中的符号链接(默认为<code>False</code>)。</li>
<li><code>subset</code>：数据子集(<code>training</code>或<code>validation</code>)，如果在<code>ImageDataGenerator</code>中设置了<code>validation_split</code>。</li>
<li><code>interpolation</code>：如果目标尺寸与加载图像的尺寸不同，则使用插值方法重新采样图像。支持的方法有<code>nearest</code>、<code>bilinear</code>和<code>bicubic</code>。如果安装了<code>1.1.3</code>以上版本的<code>PIL</code>，还支持<code>lanczos</code>。如果安装了<code>3.4.0</code>以上版本的<code>PIL</code>，还支持<code>box</code>和<code>hamming</code>。</li>
</ul>
<p>该函数返回一个生成(<code>x, y</code>)元组的<code>DirectoryIterator</code>，其中<code>x</code>是一个包含一批尺寸为(<code>batch_size, *target_size, channels</code>)的图像的<code>Numpy</code>数组，<code>y</code>是对应标签的<code>Numpy</code>数组。</p>
<h3 id="get-random-transform"><a href="#get-random-transform" class="headerlink" title="get_random_transform"></a>get_random_transform</h3><p>&emsp;&emsp;为转换生成随机参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.get_random_transform(img_shape, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机种子；<code>img_shape</code>是整数元组，被转换的图像的尺寸。</p>
<h3 id="random-transform"><a href="#random-transform" class="headerlink" title="random_transform"></a>random_transform</h3><p>&emsp;&emsp;将随机变换应用于图像：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.random_transform(x, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>x</code>是<code>3D</code>张量，即单张图像；参数<code>seed</code>是随机种子。</p>
<h3 id="standardize"><a href="#standardize" class="headerlink" title="standardize"></a>standardize</h3><p>&emsp;&emsp;将标准化配置应用于一批输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.preprocessing.image.standardize(x)</span><br></pre></td></tr></table></figure>
<p>参数<code>x</code>是需要标准化的一批输入。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/Keras之循环层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/Keras之循环层/" itemprop="url">Keras之循环层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T17:19:11+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>&emsp;&emsp;该函数是循环神经网络层基类，请使用它的子类<code>LSTM</code>、<code>GRU</code>或<code>SimpleRNN</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.recurrent.Recurrent(</span><br><span class="line">    return_sequences=<span class="keyword">False</span>, go_backwards=<span class="keyword">False</span>,</span><br><span class="line">    stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>, implementation=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>所有的循环层(<code>LSTM</code>、<code>GRU</code>和<code>SimpleRNN</code>)都继承本层，因此下面的参数可以在任何循环层中使用：</p>
<ul>
<li><code>return_sequences</code>：布尔值，决定是返回输出序列中的最后一个输出，还是全部序列(<code>True</code>)。</li>
<li><code>go_backwards</code>：布尔值，如果为<code>True</code>，则逆向处理输入序列，并返回逆序后的序列。</li>
<li><code>stateful</code>：布尔值，如果为<code>True</code>，则一个<code>batch</code>中下标为<code>i</code>的样本的最终状态将会用作下一个<code>batch</code>同样下标的样本的初始状态。</li>
<li><code>unroll</code>：布尔值，如果为<code>True</code>，则网络将展开，否则就使用符号化的循环。当使用<code>TensorFlow</code>为后端时，循环网络本来就是展开的，因此该层不做任何事情。层展开会占用更多的内存，但会加速<code>RNN</code>的运算。层展开只适用于短序列。</li>
<li><code>implementation</code>：<code>0</code>、<code>1</code>或<code>2</code>。若为<code>0</code>，则<code>RNN</code>将以更少但是更大的矩阵乘法实现，因此在<code>CPU</code>上运行更快，但消耗更多的内存。如果设为<code>1</code>，则<code>RNN</code>将以更多但更小的矩阵乘法实现，因此在<code>CPU</code>上运行更慢，在<code>GPU</code>上运行更快，并且消耗更少的内存。如果设为<code>2</code>(仅<code>LSTM</code>和<code>GRU</code>可以设为<code>2</code>)，则<code>RNN</code>将把输入门、遗忘门和输出门合并为单个矩阵，以获得更加在<code>GPU</code>上更加高效的实现。注意，<code>RNN dropout</code>必须在所有门上共享，并导致正则效果性能微弱降低。</li>
<li><code>input_dim</code>：输入的维度(整数)，将此层用作模型中的第一层时，此参数(或者等价的指定<code>input_shape</code>)是必需的。</li>
<li><code>input_length</code>：当输入序列的长度固定时，该参数为输入序列的长度。当需要在该层后连接<code>Flatten</code>层，然后又要连接<code>Dense</code>层时，需要指定该参数，否则全连接的输出无法计算出来。注意，如果循环层不是网络的第一层，你需要在网络的第一层中指定序列的长度(通过<code>input_shape</code>指定)。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：<code>3D</code>张量，尺寸为(<code>batch_size, timesteps, input_dim</code>)。<br>&emsp;&emsp;输出尺寸：如果<code>return_state</code>为<code>True</code>，则返回张量列表。第一个张量为输出，剩余的张量为最后的状态，每个张量的尺寸为(<code>batch_size, units</code>)；否则返回尺寸为(<code>batch_size, units</code>)的<code>2D</code>张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># now model.output_shape == (None, 32)</span></span><br><span class="line">model.add(LSTM(<span class="number">32</span>, input_shape=(<span class="number">10</span>, <span class="number">64</span>)))</span><br><span class="line">​</span><br><span class="line"><span class="comment"># the following is identical</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, input_dim=<span class="number">64</span>, input_length=<span class="number">10</span>))</span><br><span class="line"><span class="comment"># for subsequent layers, no need to specify the input size</span></span><br><span class="line">model.add(LSTM(<span class="number">16</span>))</span><br><span class="line"><span class="comment"># to stack recurrent layers, you must use return_sequences=True</span></span><br><span class="line"><span class="comment"># on any recurrent layer that feeds into another recurrent layer.</span></span><br><span class="line"><span class="comment"># note that you only need to specify the input size on the first layer.</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">64</span>, input_dim=<span class="number">64</span>, input_length=<span class="number">10</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(LSTM(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h4 id="屏蔽覆盖"><a href="#屏蔽覆盖" class="headerlink" title="屏蔽覆盖"></a>屏蔽覆盖</h4><p>&emsp;&emsp;循环层支持通过时间步变量对输入数据进行<code>Masking</code>，如果想将输入数据的一部分屏蔽掉，请使用<code>Embedding</code>层并将参数<code>mask_zero</code>设为<code>True</code>。</p>
<h4 id="关于在RNN中使用状态的注意事项"><a href="#关于在RNN中使用状态的注意事项" class="headerlink" title="关于在RNN中使用状态的注意事项"></a>关于在RNN中使用状态的注意事项</h4><p>&emsp;&emsp;你可以将<code>RNN</code>层设置为<code>stateful</code>(有状态的)，这意味着针对一批中的样本计算的状态将被重新用作下一批样品的初始状态。这假定在不同连续批次的样品之间有一对一的映射。<br>&emsp;&emsp;为了启用状态<code>RNN</code>，请在实例化层对象时指定参数<code>stateful = True</code>，并在<code>Sequential</code>模型使用固定大小的<code>batch</code>：通过在模型的第一层传入<code>batch_size = (...)</code>和<code>input_shape</code>来实现。在函数式模型中，对所有的输入都要指定相同的<code>batch_size</code>。<br>&emsp;&emsp;如果要将循环层的状态重置，请调用<code>reset_states</code>。对模型调用将重置模型中所有状态<code>RNN</code>的状态；对单个层调用则只重置该层的状态。</p>
<h4 id="关于指定RNN初始状态的注意事项"><a href="#关于指定RNN初始状态的注意事项" class="headerlink" title="关于指定RNN初始状态的注意事项"></a>关于指定RNN初始状态的注意事项</h4><p>&emsp;&emsp;可以通过设置<code>initial_state</code>用符号式的方式指定<code>RNN</code>层的初始状态，<code>initial_stat</code>的值应该为一个<code>tensor</code>或一个<code>tensor</code>列表，代表<code>RNN</code>层的初始状态。<br>&emsp;&emsp;也可以通过设置<code>reset_states</code>参数用数值的方法设置<code>RNN</code>的初始状态，状态的值应该为<code>numpy</code>数组或<code>numpy</code>数组的列表，代表<code>RNN</code>层的初始状态。</p>
<h3 id="SimpleRNN"><a href="#SimpleRNN" class="headerlink" title="SimpleRNN"></a>SimpleRNN</h3><p>&emsp;&emsp;该函数是完全连接的<code>RNN</code>，其输出将被反馈到输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.SimpleRNN(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>, bias_initializer=<span class="string">'zeros'</span>,</span><br><span class="line">    kernel_regularizer=<span class="keyword">None</span>, recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>,</span><br><span class="line">    bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, return_sequences=<span class="keyword">False</span>,</span><br><span class="line">    return_state=<span class="keyword">False</span>, go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>units</code>：正整数，输出空间的维度。</li>
<li><code>activation</code>：要使用的激活函数。如果传入<code>None</code>，则不使用激活函数(即线性激活<code>a(x) = x</code>)。</li>
<li><code>use_bias</code>：布尔值，该层是否使用偏置向量。</li>
<li><code>kernel_initializer</code>：<code>kernel</code>权值矩阵的初始化器，用于输入的线性转换。</li>
<li><code>recurrent_initializer</code>：<code>recurrent_kernel</code>权值矩阵的初始化器，用于循环层状态的线性转换。</li>
<li><code>bias_initializer</code>：偏置向量的初始化器。</li>
<li><code>kernel_regularizer</code>：运用到<code>kernel</code>权值矩阵的正则化函数。</li>
<li><code>recurrent_regularizer</code>：运用到<code>recurrent_kernel</code>权值矩阵的正则化函数。</li>
<li><code>bias_regularizer</code>：运用到偏置向量的正则化函数。</li>
<li><code>activity_regularizer</code>：运用到层输出的正则化函数。</li>
<li><code>kernel_constraint</code>：运用到<code>kernel</code>权值矩阵的约束函数。</li>
<li><code>recurrent_constraint</code>：运用到<code>recurrent_kernel</code>权值矩阵的约束函数。</li>
<li><code>bias_constraint</code>：运用到偏置向量的约束函数。</li>
<li><code>dropout</code>：在<code>0</code>和<code>1</code>之间的浮点数。单元的丢弃比例，用于输入的线性转换。</li>
<li><code>recurrent_dropout</code>：在<code>0</code>和<code>1</code>之间的浮点数，控制输入线性变换的神经元断开比例。</li>
</ul>
<h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>&emsp;&emsp;该函数是门限循环单元网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GRU(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, recurrent_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>,</span><br><span class="line">    implementation=<span class="number">1</span>, return_sequences=<span class="keyword">False</span>, return_state=<span class="keyword">False</span>,</span><br><span class="line">    go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>&emsp;&emsp;该函数是长短期记忆网络层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.LSTM(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="keyword">True</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>,</span><br><span class="line">    dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, implementation=<span class="number">1</span>, return_sequences=<span class="keyword">False</span>,</span><br><span class="line">    return_state=<span class="keyword">False</span>, go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>, unroll=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="ConvLSTM2D"><a href="#ConvLSTM2D" class="headerlink" title="ConvLSTM2D"></a>ConvLSTM2D</h3><p>&emsp;&emsp;该函数是卷积<code>LSTM</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ConvLSTM2D(</span><br><span class="line">    filters, kernel_size, strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>,</span><br><span class="line">    use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="keyword">True</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>,</span><br><span class="line">    return_sequences=<span class="keyword">False</span>, go_backwards=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>,</span><br><span class="line">    dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>它类似于<code>LSTM</code>层，但输入变换和循环变换都是卷积的。</p>
<ul>
<li><code>filters</code>：整数，输出空间的维度(即卷积中滤波器的输出数量)。</li>
<li><code>kernel_size</code>：一个整数，或者单个整数表示的元组或列表，指明<code>1D</code>卷积窗口的长度。</li>
<li><code>strides</code>：一个整数，或者单个整数表示的元组或列表，指明卷积的步长。当不等于<code>1</code>时，无法使用<code>dilation</code>功能，即<code>dialation_rate</code>必须为<code>1</code>。</li>
<li><code>padding</code>：<code>valid</code>或<code>same</code>之一。</li>
<li><code>data_format</code>：字符串，<code>channels_last</code>(默认)或<code>channels_first</code>之一，代表图像的通道维的位置。<code>channels_last</code>对应输入尺寸为(<code>batch, height, width, channels</code>)，<code>channels_first</code>对应输入尺寸为(<code>batch, channels, height, width</code>)。</li>
<li><code>dilation_rate</code>：一个整数，或<code>n</code>个整数的元组/列表，指定用于膨胀卷积的膨胀率。</li>
<li><code>recurrent_activation</code>：用在<code>recurrent</code>部分的激活函数，为预定义的激活函数名(参考激活函数)，或逐元素(<code>element-wise</code>)的<code>Theano</code>函数。如果不指定该参数，将不会使用任何激活函数(即使用线性激活函数<code>“a(x) = x”</code>)。</li>
<li><code>unit_forget_bias</code>：布尔值。如果为<code>True</code>，则初始化时，将忘记门的偏置加<code>1</code>。将其设置为<code>True</code>同时还会强制<code>bias_initializer=&quot;zeros&quot;</code>。。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，返回<code>5D</code>张量，尺寸为(<code>samples, time, channels, rows, cols</code>)。</li>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，返回<code>5D</code>张量，尺寸为(<code>samples, time, rows, cols, channels</code>)。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：如果<code>return_sequences</code>为<code>True</code>：</p>
<ul>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，返回<code>5D</code>张量，尺寸为(<code>samples, time, filters, output_row, output_col</code>)。</li>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，返回<code>5D</code>张量，尺寸为(<code>samples, time, output_row, output_col, filters</code>)。</li>
</ul>
<p>否则：</p>
<ul>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，返回<code>4D</code>张量，尺寸为(<code>samples, filters, output_row, output_col</code>)。</li>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，返回<code>4D</code>张量，尺寸为(<code>samples, output_row, output_col, filters</code>)。<code>o_row</code>和<code>o_col</code>依赖于过滤器的尺寸和填充。</li>
</ul>
<h3 id="SimpleRNNCell"><a href="#SimpleRNNCell" class="headerlink" title="SimpleRNNCell"></a>SimpleRNNCell</h3><p>&emsp;&emsp;该函数是<code>SimpleRNN</code>的单元类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.SimpleRNNCell(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">'orthogonal'</span>, bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="GRUCell"><a href="#GRUCell" class="headerlink" title="GRUCell"></a>GRUCell</h3><p>&emsp;&emsp;该函数是<code>GRU</code>层的单元类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GRUCell(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, recurrent_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    bias_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>,</span><br><span class="line">    bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, implementation=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="LSTMCell"><a href="#LSTMCell" class="headerlink" title="LSTMCell"></a>LSTMCell</h3><p>&emsp;&emsp;该函数是<code>LSTM</code>层的单元类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.LSTMCell(</span><br><span class="line">    units, activation=<span class="string">'tanh'</span>, recurrent_activation=<span class="string">'hard_sigmoid'</span>, use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="keyword">True</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>, dropout=<span class="number">0.0</span>,</span><br><span class="line">    recurrent_dropout=<span class="number">0.0</span>, implementation=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="StackedRNNCells"><a href="#StackedRNNCells" class="headerlink" title="StackedRNNCells"></a>StackedRNNCells</h3><p>&emsp;&emsp;该函数允许将一堆<code>RNN</code>单元包装为一个单元的封装器，用于实现高效堆叠的<code>RNN</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.StackedRNNCells(cells)</span><br></pre></td></tr></table></figure>
<p>参数<code>cells</code>是<code>RNN</code>单元实例的列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cells = [keras.layers.LSTMCell(output_dim),</span><br><span class="line">         keras.layers.LSTMCell(output_dim),</span><br><span class="line">         keras.layers.LSTMCell(output_dim),]</span><br><span class="line">inputs = keras.Input((timesteps, input_dim))</span><br><span class="line">x = keras.layers.RNN(cells)(inputs)</span><br></pre></td></tr></table></figure>
<h3 id="CuDNNGRU"><a href="#CuDNNGRU" class="headerlink" title="CuDNNGRU"></a>CuDNNGRU</h3><p>&emsp;&emsp;该函数是由<code>CuDNN</code>支持的快速<code>GRU</code>实现，只能以<code>TensorFlow</code>后端运行在<code>GPU</code>上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.CuDNNGRU(</span><br><span class="line">    units, kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, recurrent_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>, return_sequences=<span class="keyword">False</span>,</span><br><span class="line">    return_state=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="CuDNNLSTM"><a href="#CuDNNLSTM" class="headerlink" title="CuDNNLSTM"></a>CuDNNLSTM</h3><p>&emsp;&emsp;该函数是由<code>CuDNN</code>支持的快速<code>LSTM</code>实现，只能以<code>TensorFlow</code>后端运行在<code>GPU</code>上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.CuDNNLSTM(</span><br><span class="line">    units, kernel_initializer=<span class="string">'glorot_uniform'</span>, recurrent_initializer=<span class="string">'orthogonal'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, unit_forget_bias=<span class="keyword">True</span>, kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>, activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    kernel_constraint=<span class="keyword">None</span>, recurrent_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>,</span><br><span class="line">    return_sequences=<span class="keyword">False</span>, return_state=<span class="keyword">False</span>, stateful=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/Kears之核心网络层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/Kears之核心网络层/" itemprop="url">Kears之核心网络层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T14:59:09+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Dense"><a href="#Dense" class="headerlink" title="Dense"></a>Dense</h3><p>&emsp;&emsp;该函数就是常用的的全连接层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dense(</span><br><span class="line">    units, activation=<span class="keyword">None</span>, use_bias=<span class="keyword">True</span>, kernel_initializer=<span class="string">'glorot_uniform'</span>,</span><br><span class="line">    bias_initializer=<span class="string">'zeros'</span>, kernel_regularizer=<span class="keyword">None</span>, bias_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    activity_regularizer=<span class="keyword">None</span>, kernel_constraint=<span class="keyword">None</span>, bias_constraint=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p><code>Dense</code>实现以下操作：<code>output = activation(dot(input, kernel) + bias)</code>，其中<code>activation</code>是按逐个元素计算的激活函数，<code>kernel</code>是由网络层创建的权值矩阵，以及<code>bias</code>是其创建的偏置向量(只在<code>use_bias</code>为<code>True</code>时才有用)。如果本层的输入数据的维度大于<code>2</code>，则会先被压为与<code>kernel</code>相匹配的大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 现在模型就会以尺寸为(*, 16)的数组作为输入，其输出数组的尺寸为(*, 32)</span></span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_shape=(<span class="number">16</span>,)))</span><br><span class="line">model.add(Dense(<span class="number">32</span>))  <span class="comment"># 在第一层之后，你就不再需要指定输入的尺寸了</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>units</code>：正整数，输出空间维度。</li>
<li><code>activation</code>：激活函数。若不指定，则不使用激活函数(即线性激活<code>a(x) = x</code>)。</li>
<li><code>use_bias</code>：布尔值，该层是否使用偏置向量。</li>
<li><code>kernel_initializer</code>：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。</li>
<li><code>bias_initializer</code>：偏置向量初始化方法，为预定义初始化方法名的字符串，或用于初始化偏置向量的初始化器。</li>
<li><code>kernel_regularizer</code>：运用到<code>kernel</code>权值矩阵的正则化函数。</li>
<li><code>bias_regularizer</code>：运用到偏置向量的的正则化函数。</li>
<li><code>activity_regularizer</code>：运用到层的输出的正则化函数。</li>
<li><code>kernel_constraint</code>：运用到<code>kernel</code>权值矩阵的约束函数。</li>
<li><code>bias_constraint</code>：运用到偏置向量的约束函数。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：<code>nD</code>张量，尺寸为(<code>batch_size, ..., input_dim</code>)。最常见的情况是一个尺寸为(<code>batch_size, input_dim</code>)的<code>2D</code>输入。<br>&emsp;&emsp;输出尺寸：<code>nD</code>张量，尺寸为(<code>batch_size, ..., units</code>)。例如，对于尺寸为(<code>batch_size, input_dim</code>)的<code>2D</code>输入，输出的尺寸为(<code>batch_size, units</code>)。</p>
<h3 id="Activation"><a href="#Activation" class="headerlink" title="Activation"></a>Activation</h3><p>&emsp;&emsp;该函数将激活函数应用于输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Activation(activation)</span><br></pre></td></tr></table></figure>
<p>参数<code>activation</code>是要使用的激活函数的名称，或者选择一个<code>Theano</code>或<code>TensorFlow</code>操作。<br>&emsp;&emsp;输入尺寸：任意尺寸。当使用此层作为模型中的第一层时，使用参数<code>input_shape</code>(整数元组，不包括样本数的轴)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>&emsp;&emsp;该函数将<code>Dropout</code>应用于输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Dropout(rate, noise_shape=<span class="keyword">None</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p><code>Dropout</code>将在训练过程中每次更新参数时，按一定概率(<code>rate</code>)随机断开输入神经元，用于防止过拟合。</p>
<ul>
<li><code>rate</code>：在<code>0</code>和<code>1</code>之间浮动，控制需要断开的神经元的比例。</li>
<li><code>noise_shape</code>：<code>1D</code>整数张量，为将要应用在输入上的二值<code>Dropout mask</code>的<code>shape</code>，例如你的输入为(<code>batch_size, timesteps, features</code>)，并且你希望在各个时间步上的<code>Dropout mask</code>都相同，则可传入<code>noise_shape = (batch_size, 1, features)</code>。</li>
<li><code>seed</code>：一个作为随机种子的<code>Python</code>整数。</li>
</ul>
<h3 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h3><p>&emsp;&emsp;<code>Flatten</code>层用来将输入<code>压平</code>，也就是把多维的输入一维化，常用在从卷积层到全连接层的过渡，不影响<code>batch</code>的大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Flatten()</span><br></pre></td></tr></table></figure>
<p>使用示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 现在“model.output_shape == (None, 64, 32, 32)”</span></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">'same'</span>, input_shape=(<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)))</span><br><span class="line">model.add(Flatten())  <span class="comment"># 现在“model.output_shape == (None, 65536)”</span></span><br></pre></td></tr></table></figure>
<h3 id="Reshape"><a href="#Reshape" class="headerlink" title="Reshape"></a>Reshape</h3><p>&emsp;&emsp;该函数将输入重新调整为特定的尺寸：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Reshape(target_shape)</span><br></pre></td></tr></table></figure>
<p>参数<code>target_shape</code>是目标尺寸，为整数元组，不包含样本数目的维度(即<code>batch</code>大小)。<br>&emsp;&emsp;输入尺寸：任意，尽管输入尺寸中的所有维度必须是固定的。当使用此层作为模型中的第一层时，使用参数<code>input_shape</code>(整数元组，不包括样本数的轴)。<br>&emsp;&emsp;输出尺寸：<code>(batch_size,) + target_shape</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 现在“model.output_shape == (None, 3, 4)”，None是批表示的维度</span></span><br><span class="line">model.add(Reshape((<span class="number">3</span>, <span class="number">4</span>), input_shape=(<span class="number">12</span>,)))</span><br><span class="line">model.add(Reshape((<span class="number">6</span>, <span class="number">2</span>)))  <span class="comment"># 现在“model.output_shape == (None, 6, 2)”</span></span><br><span class="line"><span class="comment"># 还支持使用“-1”表示维度的尺寸推断，现在“model.output_shape == (None, 3, 2, 2)”</span></span><br><span class="line">model.add(Reshape((<span class="number">-1</span>, <span class="number">2</span>, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="Permute"><a href="#Permute" class="headerlink" title="Permute"></a>Permute</h3><p>&emsp;&emsp;<code>Permute</code>层将输入的维度按照给定模式进行重排，例如当需要将<code>RNN</code>和<code>CNN</code>网络连接时，可能会用到该层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Permute(dims)</span><br></pre></td></tr></table></figure>
<p>参数<code>dims</code>是整数元组，指定重排的模式，不包含样本数的维度。重排模式的下标从<code>1</code>开始，例如(<code>2, 1</code>)代表将输入的第二个维度重排到输出的第一个维度，而将输入的第一个维度重排到第二个维度。<br>&emsp;&emsp;输入尺寸：任意。当使用此层作为模型中的第一层时，使用参数<code>input_shape</code>(整数元组，不包括样本数的轴)。<br>&emsp;&emsp;输出尺寸：与输入尺寸相同，但是维度根据指定的模式重新排列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 现在“model.output_shape == (None, 64, 10)”，None是批表示的维度</span></span><br><span class="line">model.add(Permute((<span class="number">2</span>, <span class="number">1</span>), input_shape=(<span class="number">10</span>, <span class="number">64</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="RepeatVector"><a href="#RepeatVector" class="headerlink" title="RepeatVector"></a>RepeatVector</h3><p>&emsp;&emsp;该函数将输入重复<code>n</code>次：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.RepeatVector(n)</span><br></pre></td></tr></table></figure>
<p>参数<code>n</code>是整数，即重复次数。<br>&emsp;&emsp;输入尺寸：<code>2D</code>张量，尺寸为(<code>num_samples, features</code>)。<br>&emsp;&emsp;输出尺寸：<code>3D</code>张量，尺寸为(<code>num_samples, n, features</code>)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 现在“model.output_shape == (None, 32)”，None是批表示的维度</span></span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">32</span>))</span><br><span class="line">model.add(RepeatVector(<span class="number">3</span>))  <span class="comment"># 现在“model.output_shape == (None, 3, 32)”</span></span><br></pre></td></tr></table></figure>
<h3 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h3><p>&emsp;&emsp;该函数将上一层的输出封装为<code>Layer</code>对象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Lambda(function, output_shape=<span class="keyword">None</span>, mask=<span class="keyword">None</span>, arguments=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>function</code>：需要封装的函数，将输入张量作为第一个参数，即上一层的输出。</li>
<li><code>output_shape</code>：预期的函数输出尺寸，只在使用<code>Theano</code>时有意义，可以是一个<code>tuple</code>，也可以是一个根据输入<code>shape</code>计算输出<code>shape</code>的函数。</li>
<li><code>arguments</code>：需要传递给函数的关键字参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">model.add(Lambda(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>))  <span class="comment"># 添加一个“x -&gt; x^2”层</span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">antirectifier</span><span class="params">(x)</span>:</span>  <span class="comment"># 添加一个网络层，返回输入的正数部分与负数部分的反面的连接</span></span><br><span class="line">    x -= K.mean(x, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">    x = K.l2_normalize(x, axis=<span class="number">1</span>)</span><br><span class="line">    pos = K.relu(x)</span><br><span class="line">    neg = K.relu(-x)</span><br><span class="line">    <span class="keyword">return</span> K.concatenate([pos, neg], axis=<span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">antirectifier_output_shape</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    shape = list(input_shape)</span><br><span class="line">    <span class="keyword">assert</span> len(shape) == <span class="number">2</span>  <span class="comment"># only valid for 2D tensors</span></span><br><span class="line">    shape[<span class="number">-1</span>] *= <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> tuple(shape)</span><br><span class="line">​</span><br><span class="line">model.add(Lambda(antirectifier, output_shape=antirectifier_output_shape))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：任意，当使用此层作为模型中的第一层时，使用参数<code>input_shape</code>(整数元组，不包括样本数的轴)。<br>&emsp;&emsp;输出尺寸：由<code>output_shape</code>参数指定(或者在使用<code>TensorFlow</code>时，自动推理得到)。</p>
<h3 id="ActivityRegularization"><a href="#ActivityRegularization" class="headerlink" title="ActivityRegularization"></a>ActivityRegularization</h3><p>&emsp;&emsp;经过本层的数据不会有任何变化，但会基于其激活值更新损失函数值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ActivityRegularization(l1=<span class="number">0.0</span>, l2=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>l1</code>是<code>L1</code>范数正则化因子(正数浮点型)；<code>l2</code>是<code>L2</code>范数正则化因子(正数浮点型)。<br>&emsp;&emsp;输入尺寸：任意，当使用此层作为模型中的第一层时，使用参数<code>input_shape</code>(整数元组，不包括样本数的轴)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="Masking"><a href="#Masking" class="headerlink" title="Masking"></a>Masking</h3><p>&emsp;&emsp;使用给定的值对输入的序列信号进行<code>屏蔽</code>，用以定位需要跳过的时间步：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Masking(mask_value=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>对于输入张量的时间步，即输入张量的第<code>1</code>维度(维度从<code>0</code>开始算)，如果输入张量在该时间步上都等于<code>mask_value</code>，则该时间步将在模型接下来的所有层(只要支持<code>masking</code>)被跳过(即<code>屏蔽</code>)。<br>&emsp;&emsp;考虑将要喂入一个<code>LSTM</code>层的<code>Numpy</code>矩阵<code>x</code>，尺寸为(<code>samples, timesteps, features</code>)，现将其送入<code>LSTM</code>层。因为你缺少时间步为<code>3</code>和<code>5</code>的信号，所以你希望将其掩盖，这时候应该：</p>
<ul>
<li>设置<code>x[:, 3, :] = 0</code>以及<code>x[:, 5, :] = 0</code>。</li>
<li>在<code>LSTM</code>层之前，插入一个<code>mask_value = 0</code>的<code>Masking</code>层：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Masking(mask_value=<span class="number">0.</span>, input_shape=(timesteps, features)))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/Keras之MNIST识别/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/Keras之MNIST识别/" itemprop="url">Keras之MNIST识别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T14:38:35+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>&emsp;&emsp;<code>Keras</code>自身就有<code>MNIST</code>这个数据包，再分成训练集和测试集。<code>x</code>是一张张图片，<code>y</code>是每张图片对应的标签，即它是哪个数字。<br>&emsp;&emsp;输入的<code>x</code>变成(<code>60000 * 784</code>)的数据(即训练集有<code>6</code>万张图片，每张图片的大小是<code>28 * 28</code>)，然后除以<code>255</code>进行标准化，因为每个像素都是在<code>0</code>到<code>255</code>之间，标准化之后就变成了<code>0</code>到<code>1</code>之间。<br>&emsp;&emsp;对于<code>y</code>，要用到<code>Keras</code>改造的<code>numpy</code>的一个函数<code>np_utils.to_categorical</code>，把y变成了<code>one-hot</code>的形式，即之前<code>y</code>是一个数值(在<code>0</code>至<code>9</code>之间)，现在是一个大小为<code>10</code>的向量，它属于哪个数字，就在哪个位置为<code>1</code>，其他位置都是<code>0</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line">​</span><br><span class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line"><span class="comment"># data pre-processing</span></span><br><span class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">-1</span>) / <span class="number">255.</span>  <span class="comment"># normalize</span></span><br><span class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">-1</span>) / <span class="number">255.</span>  <span class="comment"># normalize</span></span><br><span class="line">y_train = np_utils.to_categorical(y_train, num_classes=<span class="number">10</span>)</span><br><span class="line">y_test = np_utils.to_categorical(y_test, num_classes=<span class="number">10</span>)</span><br><span class="line">​</span><br><span class="line">print(X_train[<span class="number">1</span>].shape)</span><br><span class="line">print(y_train[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><p>&emsp;&emsp;模型的第一段就是加入<code>Dense</code>神经层，<code>32</code>是输出的维度，<code>784</code>是输入的维度。第一层传出的数据有<code>32</code>个<code>feature</code>，传给激励单元，激励函数用到的是<code>relu</code>函数。经过激励函数之后，就变成了非线性的数据。然后再把这个数据传给下一个神经层，对于这个<code>Dense</code>，我们定义它有<code>10</code>个输出的<code>feature</code>。同样的，此处不需要再定义输入的维度，因为它接收的是上一层的输出。接下来再输入给下面的<code>softmax</code>函数，用来分类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    Dense(<span class="number">32</span>, input_dim=<span class="number">784</span>),</span><br><span class="line">    Activation(<span class="string">'relu'</span>),</span><br><span class="line">    Dense(<span class="number">10</span>),</span><br><span class="line">    Activation(<span class="string">'softmax'</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>接下来用<code>RMSprop</code>作为优化器，它的参数包括学习率等，可以通过修改这些参数来看一下模型的效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rmsprop = RMSprop(lr=<span class="number">0.001</span>, rho=<span class="number">0.9</span>, epsilon=<span class="number">1e-08</span>, decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="激活模型"><a href="#激活模型" class="headerlink" title="激活模型"></a>激活模型</h3><p>&emsp;&emsp;接下来用<code>model.compile</code>激励神经网络。优化器可以选择默认的，也可以是我们在上一步定义的。对于损失函数，分类和回归问题的不一样，用的是交叉熵。<code>metrics</code>里面可以放入需要计算的<code>cost</code>、<code>accuracy</code>、<code>score</code>等：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We add metrics to get more results you want to see</span></span><br><span class="line">model.compile(optimizer=rmsprop, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<h3 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h3><p>&emsp;&emsp;这里用到的是<code>fit</code>函数，<code>nb_epoch</code>表示把整个数据训练多少次，<code>batch_size</code>显示每批处理<code>32</code>个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Training ------------'</span>)</span><br><span class="line">model.fit(X_train, y_train, epochs=<span class="number">2</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>
<h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><p>&emsp;&emsp;接下来就是用测试集来检验一下模型，方法和回归网络中是一样的。运行代码之后，可以输出<code>accuracy</code>和<code>loss</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'\nTesting ------------'</span>)</span><br><span class="line"><span class="comment"># Evaluate the model with the metrics we defined earlier</span></span><br><span class="line">loss, accuracy = model.evaluate(X_test, y_test)</span><br><span class="line">print(<span class="string">'test loss: '</span>, loss)</span><br><span class="line">print(<span class="string">'test accuracy: '</span>, accuracy)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="CNN的MNIST实验"><a href="#CNN的MNIST实验" class="headerlink" title="CNN的MNIST实验"></a>CNN的MNIST实验</h3><p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Activation, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Convolution2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">​</span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">nb_classes = <span class="number">10</span></span><br><span class="line">epochs = <span class="number">12</span></span><br><span class="line">img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span>  <span class="comment"># input image dimensions</span></span><br><span class="line">nb_filters = <span class="number">32</span>  <span class="comment"># number of convolutional filters to use</span></span><br><span class="line">pool_size = (<span class="number">2</span>, <span class="number">2</span>)  <span class="comment"># size of pooling area for max pooling</span></span><br><span class="line">kernel_size = (<span class="number">3</span>, <span class="number">3</span>)  <span class="comment"># convolution kernel size</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># the data, shuffled and split between train and test sets</span></span><br><span class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> K.image_dim_ordering() == <span class="string">'th'</span>:  <span class="comment"># 根据不同的backend，决定不同的格式</span></span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">    input_shape = (<span class="number">1</span>, img_rows, img_cols)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">    input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line">X_train = X_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_test = X_test.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_train /= <span class="number">255</span></span><br><span class="line">X_test /= <span class="number">255</span></span><br><span class="line">print(<span class="string">'X_train shape:'</span>, X_train.shape)</span><br><span class="line">print(X_train.shape[<span class="number">0</span>], <span class="string">'train samples'</span>)</span><br><span class="line">print(X_test.shape[<span class="number">0</span>], <span class="string">'test samples'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 转换为one_hot类型  </span></span><br><span class="line">Y_train = np_utils.to_categorical(y_train, nb_classes)</span><br><span class="line">Y_test = np_utils.to_categorical(y_test, nb_classes)</span><br><span class="line">​</span><br><span class="line">model = Sequential()  <span class="comment"># 构建模型</span></span><br><span class="line">model.add(  <span class="comment"># 卷积层1</span></span><br><span class="line">    Convolution2D(nb_filters, (kernel_size[<span class="number">0</span>], kernel_size[<span class="number">1</span>]),</span><br><span class="line">                  padding=<span class="string">'same'</span>, input_shape=input_shape)</span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))  <span class="comment"># 激活层</span></span><br><span class="line">model.add(Convolution2D(nb_filters, (kernel_size[<span class="number">0</span>], kernel_size[<span class="number">1</span>])))  <span class="comment"># 卷积层2</span></span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))  <span class="comment"># 激活层</span></span><br><span class="line">model.add(MaxPooling2D(pool_size=pool_size))  <span class="comment"># 池化层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))  <span class="comment"># 神经元随机失活</span></span><br><span class="line">model.add(Flatten())  <span class="comment"># 拉成一维数据</span></span><br><span class="line">model.add(Dense(<span class="number">128</span>))  <span class="comment"># 全连接层1</span></span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))  <span class="comment"># 激活层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))  <span class="comment"># 随机失活</span></span><br><span class="line">model.add(Dense(nb_classes))  <span class="comment"># 全连接层2</span></span><br><span class="line">model.add(Activation(<span class="string">'softmax'</span>))  <span class="comment"># Softmax评分</span></span><br><span class="line">​</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=<span class="string">'adadelta'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,</span><br><span class="line">          verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)  <span class="comment"># 评估模型</span></span><br><span class="line">print(<span class="string">'Test score:'</span>, score[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">'Test accuracy:'</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/TensorFlow的运行方式/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/TensorFlow的运行方式/" itemprop="url">TensorFlow的运行方式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T14:05:11+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>TensorFlow</code>的运行方式分如下<code>4</code>步：</p>
<ul>
<li>加载数据以及定义超参数。</li>
<li>构建网络。</li>
<li>训练模型。</li>
<li>评估模型和进行预测。</li>
</ul>
<p>下面以一个神经网络为例，讲解<code>TensorFlow</code>的运行方式。在这个例子中，我们构造一个满足一元二次函数<code>y = ax^2 + b</code>的原始数据，然后构造一个最简单的神经网络(仅包含一个输入层、一个隐藏层和一个输出层)。通过<code>TensorFlow</code>将隐藏层和输出层的<code>weights</code>和<code>biases</code>的值学习出来，看看随着训练的增加，损失值是不是在不断地减小。</p>
<h3 id="生成以及加载数据"><a href="#生成以及加载数据" class="headerlink" title="生成以及加载数据"></a>生成以及加载数据</h3><p>&emsp;&emsp;首先来生成输入数据，假设最后要学习的方程为<code>y = x^2 - 0.5</code>，我们来构造满足这个方程的一堆<code>x</code>和<code>y</code>，同时加上一些不满足方程的噪声点：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 为了使点更密集一些，我们构建了300个点，分布在“-1”到1区间，直接采用np生成</span></span><br><span class="line"><span class="comment"># 等差数列的方法，并将结果为300个点的一维数组，转换为“300 * 1”的二维数组</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:, np.newaxis]</span><br><span class="line"><span class="comment"># 加入一些噪声点，使它与x_data的维度一致，并且均为均值为0，方差为0.05的正态分布</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise  <span class="comment"># y = x^2 - 0.5 + 噪声</span></span><br></pre></td></tr></table></figure>
<p>接下来定义<code>x</code>和<code>y</code>的占位符来作为将要输入神经网络的变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h3 id="构建网络模型"><a href="#构建网络模型" class="headerlink" title="构建网络模型"></a>构建网络模型</h3><p>&emsp;&emsp;我们这里需要构建一个隐藏层和一个输出层。作为神经网络中的层，输入的参数应该有<code>4</code>个变量：输入数据、输入数据的维度、输出数据的维度和激活函数。每一层经过向量化(<code>y = weights * x + biases</code>)的处理，并且经过激活函数的非线性处理后，最终得到输出数据。<br>&emsp;&emsp;接下来定义隐藏层和输出层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    <span class="comment"># 构建权重：“in_size * out_size”大小的矩阵</span></span><br><span class="line">    weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    <span class="comment"># 构建偏置：“1 * out_size”的矩阵</span></span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, weights) + biases  <span class="comment"># 矩阵相乘</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        out_puts = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        out_puts = activation_function(Wx_plus_b)</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> out_puts  <span class="comment"># 输出得到的数据</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 构建隐藏层，假设隐藏层有20个神经元</span></span><br><span class="line">h1 = add_layer(xs, <span class="number">1</span>, <span class="number">20</span>, activation_function=tf.nn.relu)</span><br><span class="line"><span class="comment"># 构建输出层，假设输出层和输入层一样，有一个神经元</span></span><br><span class="line">prediction = add_layer(h1, <span class="number">20</span>, <span class="number">1</span>, activation_function=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;接下来需要构建损失函数：计算输出层的预测值和真实值间的误差，对二者差的平方求和，然后再取平均，得到损失函数。运用梯度下降法，以<code>0.1</code>的效率最小化损失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 计算预测值和真实值间的误差</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br></pre></td></tr></table></figure>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>&emsp;&emsp;我们让<code>TensorFlow</code>训练<code>1000</code>次，每<code>50</code>次输出训练的损失值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:  <span class="comment"># 每50次打印出一次损失值</span></span><br><span class="line">        print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;以上就是最简单的利用<code>TensorFlow</code>的神经网络训练一个模型的过程，目标就是要训练出权重值来使模型拟合<code>y = x^2 - 0.5</code>的系数<code>1</code>和<code>-0.5</code>。通过损失值越来越小的现象，可以看出训练的参数越来越逼近目标结果。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/Keras之预训练模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/Keras之预训练模型/" itemprop="url">Keras之预训练模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T11:39:13+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>Keras</code>的<code>Application</code>模块提供了带有预训练权重的<code>Keras</code>模型，这些模型可以用来进行预测、特征提取和<code>finetune</code>。模型的预训练权重将下载到<code>~/.keras/models/</code>，并在载入模型时自动载入。<br>&emsp;&emsp;在<code>ImageNet</code>上预训练过的用于图像分类的模型主要有：<code>Xception</code>、<code>VGG16</code>、<code>VGG19</code>、<code>ResNet50</code>、<code>InceptionV3</code>、<code>InceptionResNetV2</code>、<code>MobileNet</code>、<code>DenseNet</code>和<code>NASNet</code>。所有的这些模型(除了<code>Xception</code>和<code>MobileNet</code>)都兼容<code>Theano</code>和<code>Tensorflow</code>，并会基于<code>~/.keras/keras.json</code>自动设置<code>Keras</code>的图像维度。例如，如果你设置<code>data_format=&quot;channel_last&quot;</code>，则加载的模型将按照<code>TensorFlow</code>的维度顺序来构造，即<code>Width Height Depth</code>的顺序<br>&emsp;&emsp;<code>Xception</code>模型仅在<code>TensorFlow</code>下可用，因为它依赖的<code>SeparableConvolution</code>层仅在<code>TensorFlow</code>可用。<code>MobileNet</code>仅在<code>TensorFlow</code>下可用，因为它依赖的<code>DepethwiseConvolution</code>层仅在<code>TensorFlow</code>下可用。模型信息如下所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>模型</th>
<th>大小</th>
<th>Top1准确率</th>
<th>Top5准确率</th>
<th>参数数目</th>
<th>深度</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Xception</code></td>
<td><code>88MB</code></td>
<td><code>0.790</code></td>
<td><code>0.945</code></td>
<td><code>22,910,480</code></td>
<td><code>126</code></td>
</tr>
<tr>
<td><code>VGG16</code></td>
<td><code>528MB</code></td>
<td><code>0.715</code></td>
<td><code>0.901</code></td>
<td><code>138,357,544</code></td>
<td><code>23</code></td>
</tr>
<tr>
<td><code>VGG19</code></td>
<td><code>549MB</code></td>
<td><code>0.727</code></td>
<td><code>0.910</code></td>
<td><code>143,667,240</code></td>
<td><code>26</code></td>
</tr>
<tr>
<td><code>ResNet50</code></td>
<td><code>99MB</code></td>
<td><code>0.759</code></td>
<td><code>0.929</code></td>
<td><code>25,636,712</code></td>
<td><code>168</code></td>
</tr>
<tr>
<td><code>InceptionV3</code></td>
<td><code>92MB</code></td>
<td><code>0.788</code></td>
<td><code>0.944</code></td>
<td><code>23,851,784</code></td>
<td><code>159</code></td>
</tr>
<tr>
<td><code>IncetionResNetV2</code></td>
<td><code>215MB</code></td>
<td><code>0.804</code></td>
<td><code>0.953</code></td>
<td><code>55,873,736</code></td>
<td><code>572</code></td>
</tr>
<tr>
<td><code>MobileNet</code></td>
<td><code>17MB</code></td>
<td><code>0.665</code></td>
<td><code>0.871</code></td>
<td><code>4,253,864</code></td>
<td><code>88</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Xception模型"><a href="#Xception模型" class="headerlink" title="Xception模型"></a>Xception模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.xception.Xception(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>这是在<code>ImageNet</code>上预训练的<code>Xception V1</code>模型。注意，该模型目前仅能以<code>TensorFlow</code>为后端使用，因为它依赖于<code>SeparableConvolution</code>层。目前该模型只支持<code>channels_last</code>的维度顺序(<code>width, height, channels</code>)。默认输入图片大小为<code>299 * 299</code>。</p>
<ul>
<li><code>include_top</code>：是否保留顶层的全连接网络。</li>
<li><code>weights</code>：<code>None</code>代表随机初始化，即不加载预训练权重；<code>imagenet</code>代表加载预训练权重。</li>
<li><code>input_tensor</code>：可填入<code>Keras tensor</code>作为模型的输入(比如<code>layers.Input</code>输出的<code>tensor</code>)。</li>
<li><code>input_shape</code>：可选，仅当<code>include_top = False</code>有效，不然输入形状必须是(<code>299, 299, 3</code>)，因为预训练模型是以这个大小训练的。输入尺寸必须是三个数字，且宽高必须不小于<code>71</code>，比如(<code>150, 150, 3</code>)是一个合法的输入尺寸。</li>
<li><code>pooling</code>：当<code>include_top = False</code>时，该参数指定了特征提取时的池化方式：</li>
</ul>
<ol>
<li><code>None</code>：代表不池化，直接输出最后一层卷积层的输出，该输出是一个四维张量。</li>
<li><code>avg</code>：代表全局平均池化(<code>GLobalAveragePool2D</code>)，相当于在最后一层卷积层后面再加一层全局平均池化层，输出是一个二维张量。</li>
<li><code>max</code>：代表全局最大池化。</li>
</ol>
<ul>
<li><code>classes</code>：可选，图片分类的类别数，仅当<code>include_top = True</code>并且不加载预训练权重时可用。</li>
</ul>
<h3 id="VGG16模型"><a href="#VGG16模型" class="headerlink" title="VGG16模型"></a>VGG16模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.vgg16.VGG16(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>VGG16</code>模型，权重由<code>ImageNet</code>训练而来。该模型在<code>Theano</code>和<code>TensorFlow</code>后端均可使用，并接受<code>channels_first</code>和<code>channels_last</code>两种输入维度顺序。模型的默认输入尺寸是<code>224 * 224</code>。</p>
<ul>
<li><code>input_shape</code>：可选，仅当<code>include_top = False</code>有效，不然输入形状必须是(<code>224, 224, 3</code>)，因为预训练模型是以这个大小训练的。输入尺寸必须是三个数字，且宽高必须不小于<code>48</code>，比如(<code>200, 200, 3</code>)是一个合法的输入尺寸。</li>
</ul>
<h3 id="VGG19模型"><a href="#VGG19模型" class="headerlink" title="VGG19模型"></a>VGG19模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.vgg19.VGG19(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>VGG19</code>模型，权重由<code>ImageNet</code>训练而来。该模型在<code>Theano</code>和<code>TensorFlow</code>后端均可使用，并接受<code>channels_first</code>和<code>channels_last</code>两种输入维度顺序。模型的默认输入尺寸是<code>224 * 224</code>。</p>
<h3 id="ResNet50模型"><a href="#ResNet50模型" class="headerlink" title="ResNet50模型"></a>ResNet50模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.resnet50.ResNet50(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>50</code>层残差网络模型，权重训练自<code>ImageNet</code>。该模型在<code>Theano</code>和<code>TensorFlow</code>后端均可使用，并接受<code>channels_first</code>和<code>channels_last</code>两种输入维度顺序。模型的默认输入尺寸是<code>224 * 224</code>。</p>
<h3 id="InceptionV3模型"><a href="#InceptionV3模型" class="headerlink" title="InceptionV3模型"></a>InceptionV3模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.inception_v3.InceptionV3(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>InceptionV3</code>网络，权重训练自<code>ImageNet</code>。该模型在<code>Theano</code>和<code>TensorFlow</code>后端均可使用，并接受<code>channels_first</code>和<code>channels_last</code>两种输入维度顺序。模型的默认输入尺寸是<code>299 * 299</code>。</p>
<h3 id="InceptionResNetV2模型"><a href="#InceptionResNetV2模型" class="headerlink" title="InceptionResNetV2模型"></a>InceptionResNetV2模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.inception_resnet_v2.InceptionResNetV2(</span><br><span class="line">    include_top=<span class="keyword">True</span>, weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>,</span><br><span class="line">    input_shape=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>InceptionResNetV2</code>网络，权重训练自<code>ImageNet</code>。该模型在<code>Theano</code>、<code>TensorFlow</code>和<code>CNTK</code>后端均可使用，并接受<code>channels_first</code>和<code>channels_last</code>两种输入维度顺序。模型的默认输入尺寸是<code>299 * 299</code>。</p>
<h3 id="MobileNet模型"><a href="#MobileNet模型" class="headerlink" title="MobileNet模型"></a>MobileNet模型</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.applications.mobilenet.MobileNet(</span><br><span class="line">    input_shape=<span class="keyword">None</span>, alpha=<span class="number">1.0</span>, depth_multiplier=<span class="number">1</span>, dropout=<span class="number">1e-3</span>, include_top=<span class="keyword">True</span>,</span><br><span class="line">    weights=<span class="string">'imagenet'</span>, input_tensor=<span class="keyword">None</span>, pooling=<span class="keyword">None</span>, classes=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><code>MobileNet</code>网络，权重训练自<code>ImageNet</code>。该模型仅在<code>TensorFlow</code>后端均可使用，因此仅<code>channels_last</code>维度顺序可用。当需要以<code>load_model</code>加载<code>MobileNet</code>时，需要在<code>custom_object</code>中传入<code>relu6</code>和<code>DepthwiseConv2D</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = load_model(</span><br><span class="line">    <span class="string">'mobilenet.h5'</span>,</span><br><span class="line">    custom_objects=&#123;<span class="string">'relu6'</span>: mobilenet.relu6,</span><br><span class="line">                    <span class="string">'DepthwiseConv2D'</span>: mobilenet.DepthwiseConv2D&#125;)</span><br></pre></td></tr></table></figure>
<p>模型的默认输入尺寸是<code>224 * 224</code>。</p>
<ul>
<li><code>input_shape</code>：可选，仅当<code>include_top = False</code>有效，不然输入形状必须是(<code>224, 224, 3</code>)，因为预训练模型是以这个大小训练的。输入尺寸必须是三个数字，且宽高必须不小于<code>32</code>，比如(<code>200, 200, 3</code>)是一个合法的输入尺寸。</li>
<li><code>alpha</code>：控制网络的宽度：</li>
</ul>
<ol>
<li>如果<code>alpha &lt; 1</code>，则同比例的减少每层的滤波器个数。</li>
<li>如果<code>alpha &gt; 1</code>，则同比例增加每层的滤波器个数。</li>
<li>如果<code>alpha = 1</code>，使用默认的滤波器个数。</li>
</ol>
<ul>
<li><code>depth_multiplier</code>：<code>depthwise</code>卷积的深度乘子，也称为分辨率乘子。</li>
<li><code>dropout</code>：<code>dropout</code>比例。</li>
</ul>
<hr>
<h3 id="如何“冻结”网络的层？"><a href="#如何“冻结”网络的层？" class="headerlink" title="如何“冻结”网络的层？"></a>如何“冻结”网络的层？</h3><p>&emsp;&emsp;<code>冻结</code>一个层指的是该层将不参加网络训练，即该层的权重永不会更新，在进行<code>fine-tune</code>时经常会需要这项操作。在使用固定的<code>embedding</code>层处理文本输入时，也需要这个技术。<br>&emsp;&emsp;可以通过向层的构造函数传递<code>trainable</code>参数来指定一个层是不是可训练的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frozen_layer = Dense(<span class="number">32</span>, trainable=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>此外，也可以通过将层对象的<code>trainable</code>属性设为<code>True</code>或<code>False</code>来为已经搭建好的模型设置要冻结的层。在设置完后，需要运行<code>compile</code>来使设置生效：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x = Input(shape=(<span class="number">32</span>,))</span><br><span class="line">layer = Dense(<span class="number">32</span>)</span><br><span class="line">layer.trainable = <span class="keyword">False</span></span><br><span class="line">y = layer(x)</span><br><span class="line">​</span><br><span class="line">frozen_model = Model(x, y)</span><br><span class="line"><span class="comment"># in the model below, the weights of layer will not be updated during training</span></span><br><span class="line">frozen_model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line">​</span><br><span class="line">layer.trainable = <span class="keyword">True</span></span><br><span class="line">trainable_model = Model(x, y)</span><br><span class="line"><span class="comment"># with this model the weights of the layer will be updated during training</span></span><br><span class="line"><span class="comment"># (which will also affect the above model since it uses the same layer instance)</span></span><br><span class="line">trainable_model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line">​</span><br><span class="line">frozen_model.fit(data, labels)  <span class="comment"># this does NOT update the weights of layer</span></span><br><span class="line">trainable_model.fit(data, labels)  <span class="comment"># this updates the weights of layer</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/pytorch之卷积神经网络/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/pytorch之卷积神经网络/" itemprop="url">pytorch之卷积神经网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T10:55:19+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;这是使用<code>MNIST</code>手写数据来演示<code>pytorch</code>的卷积神经网络功能。首先加载数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torchvision  <span class="comment"># 数据库模块</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Hyper Parameters</span></span><br><span class="line">EPOCH = <span class="number">1</span></span><br><span class="line">BATCH_SIZE = <span class="number">50</span></span><br><span class="line">LR = <span class="number">0.001</span>  <span class="comment"># learning rate</span></span><br><span class="line">DOWNLOAD_MNIST = <span class="keyword">False</span>  <span class="comment"># 如果你已经下载好了mnist数据，就写上False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (os.path.exists(<span class="string">'./mnist/'</span>)) <span class="keyword">or</span> <span class="keyword">not</span> os.listdir(<span class="string">'./mnist/'</span>):</span><br><span class="line">    <span class="comment"># not mnist dir or mnist is empyt dir</span></span><br><span class="line">    DOWNLOAD_MNIST = <span class="keyword">True</span></span><br><span class="line">​</span><br><span class="line">train_data = torchvision.datasets.MNIST(  <span class="comment"># Mnist手写数字</span></span><br><span class="line">    root=<span class="string">'./mnist/'</span>,  <span class="comment"># 保存或者提取位置</span></span><br><span class="line">    train=<span class="keyword">True</span>,  <span class="comment"># this is training data</span></span><br><span class="line">    <span class="comment"># 转换“PIL.Image”或“numpy.ndarray”成“torch.FloatTensor(C * H * W)”，</span></span><br><span class="line">    <span class="comment"># 训练的时候normalize成[0.0, 1.0]区间</span></span><br><span class="line">    transform=torchvision.transforms.ToTensor(),</span><br><span class="line">    download=DOWNLOAD_MNIST,  <span class="comment"># 没下载mnist数据集就进行下载，下载了就不用再下了</span></span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># plot one example</span></span><br><span class="line">print(train_data.train_data.size())  <span class="comment"># (60000, 28, 28)</span></span><br><span class="line">print(train_data.train_labels.size())  <span class="comment"># (60000)</span></span><br><span class="line">plt.imshow(train_data.train_data[<span class="number">0</span>].numpy(), cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'%i'</span> % train_data.train_labels[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/15/深度学习/pytorch之卷积神经网络/1.png" height="278" width="270"></p>
<p>黑色的地方的值都是<code>0</code>，白色的地方值大于<code>0</code>。除了给出训练数据，还需要给一些测试数据，测试一下训练效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data Loader for easy mini-batch return in training,</span></span><br><span class="line"><span class="comment"># the image batch shape will be (50, 1, 28, 28)</span></span><br><span class="line">train_loader = Data.DataLoader(dataset=train_data,</span><br><span class="line">                               batch_size=BATCH_SIZE, shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pick 2000 samples to speed up testing</span></span><br><span class="line">test_data = torchvision.datasets.MNIST(root=<span class="string">'./mnist/'</span>, train=<span class="keyword">False</span>)</span><br><span class="line"><span class="comment"># shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)</span></span><br><span class="line">test_x = torch.unsqueeze(test_data.test_data, dim=<span class="number">1</span>).type(torch.FloatTensor)[:<span class="number">2000</span>] / <span class="number">255.</span></span><br><span class="line">test_y = test_data.test_labels[:<span class="number">2000</span>]</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;我们使用一个<code>class</code>来建立<code>CNN</code>模型，这个<code>CNN</code>整体流程是<code>卷积(Conv2d)</code>-&gt;<code>激励函数(ReLU)</code>-&gt;<code>池化(MaxPooling)</code>-&gt;<code>再来一遍</code>-&gt;<code>展平多维的卷积成的特征图</code>-&gt;<code>接入全连接层(Linear)</code>-&gt;<code>输出</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(  <span class="comment"># input shape (1, 28, 28)</span></span><br><span class="line">            nn.Conv2d(</span><br><span class="line">                in_channels=<span class="number">1</span>,  <span class="comment"># input height</span></span><br><span class="line">                out_channels=<span class="number">16</span>,  <span class="comment"># n_filters</span></span><br><span class="line">                kernel_size=<span class="number">5</span>,  <span class="comment"># filter size</span></span><br><span class="line">                stride=<span class="number">1</span>,  <span class="comment"># filter movement/step</span></span><br><span class="line">                <span class="comment"># if want same width and length of this image after con2d,</span></span><br><span class="line">                <span class="comment"># padding = (kernel_size - 1)/2 if stride = 1</span></span><br><span class="line">                padding=<span class="number">2</span>,</span><br><span class="line">            ),  <span class="comment"># output shape (16, 28, 28)</span></span><br><span class="line">            nn.ReLU(),  <span class="comment"># activation</span></span><br><span class="line">            <span class="comment"># choose max value in 2x2 area, output shape (16, 14, 14)</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential(  <span class="comment"># input shape (16, 14, 14)</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># output shape (32, 14, 14)</span></span><br><span class="line">            nn.ReLU(),  <span class="comment"># activation</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  <span class="comment"># output shape (32, 7, 7)</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># fully connected layer, output 10 classes</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="comment"># flatten the output of conv2 to (batch_size, 32 * 7 * 7)</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        output = self.out(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">​</span><br><span class="line">cnn = CNN()</span><br><span class="line">print(cnn)  <span class="comment"># net architecture</span></span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CNN(</span><br><span class="line">  (conv1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (conv2): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU()</span><br><span class="line">    (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (out): Linear(in_features=<span class="number">1568</span>, out_features=<span class="number">10</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;下面开始训练，将<code>x</code>、<code>y</code>都用<code>Variable</code>包起来，然后放入<code>cnn</code>中计算<code>output</code>，最后再计算误差：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)  <span class="comment"># optimize all cnn parameters</span></span><br><span class="line">loss_func = nn.CrossEntropyLoss()  <span class="comment"># the target label is not one-hotted</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):</span><br><span class="line">    <span class="comment"># gives batch data, normalize x when iterate train_loader</span></span><br><span class="line">    <span class="keyword">for</span> step, (b_x, b_y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        output = cnn(b_x)  <span class="comment"># cnn output</span></span><br><span class="line">        loss = loss_func(output, b_y)  <span class="comment"># cross entropy loss</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># clear gradients for this training step</span></span><br><span class="line">        loss.backward()  <span class="comment"># backpropagation, compute gradients</span></span><br><span class="line">        optimizer.step()  <span class="comment"># apply gradients</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            test_output = cnn(test_x)</span><br><span class="line">            pred_y = torch.max(test_output, <span class="number">1</span>)[<span class="number">1</span>].data.squeeze().numpy()</span><br><span class="line">            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) \</span><br><span class="line">                             / float(test_y.size(<span class="number">0</span>))</span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">'| train loss: %.4f'</span> % loss.data.numpy(),</span><br><span class="line">                  <span class="string">'| test accuracy: %.2f'</span> % accuracy)</span><br></pre></td></tr></table></figure>
<p>最后再来取<code>10</code>个数据，看看预测的值到底对不对：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_output = cnn(test_x[:<span class="number">10</span>])  <span class="comment"># print 10 predictions from test data</span></span><br><span class="line">pred_y = torch.max(test_output, <span class="number">1</span>)[<span class="number">1</span>].data.numpy().squeeze()</span><br><span class="line">print(pred_y, <span class="string">'prediction number'</span>)</span><br><span class="line">print(test_y[:<span class="number">10</span>].numpy(), <span class="string">'real number'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="“x-x-view-x-size-0-1-”的理解"><a href="#“x-x-view-x-size-0-1-”的理解" class="headerlink" title="“x = x.view(x.size(0), -1)”的理解"></a>“x = x.view(x.size(0), -1)”的理解</h3><p>&emsp;&emsp;这句话一般出现在<code>model</code>类的<code>forward</code>函数中，具体位置基本都是在调用分类器之前。分类器是一个简单的<code>nn.Linear</code>结构，输入输出都是维度为一的值，<code>x = x.view(x.size(0), -1)</code>这句话就是为了将前面多维度的<code>tensor</code>展平成一维：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NET</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        super(NET, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(outchannels=<span class="number">3</span>, in_channels=<span class="number">64</span>,</span><br><span class="line">                              kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">64</span> * batch_size, <span class="number">10</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out = self.fc(x)</span><br></pre></td></tr></table></figure>
<p>上面是个简单的网络结构，包含一个卷积层和一个线性层。在<code>forward</code>函数中，<code>input</code>首先经过卷积层，此时的输出<code>x</code>是包含<code>batch size</code>维度为<code>4</code>的<code>tensor</code>，即<code>(batchsize, channels, height, width)</code>，<code>x.size(0)</code>指的是<code>batch size</code>的值，<code>x = x.view(x.size(0), -1)</code>可以简化为<code>x = x.view(batchsize, -1)</code>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/15/深度学习/pytorch训练集的读取/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/15/深度学习/pytorch训练集的读取/" itemprop="url">pytorch训练集的读取</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-15T09:27:12+08:00">
                2019-01-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>pytorch</code>读取训练集是非常便捷的，只需要使用到<code>2</code>个类，即<code>torch.utils.data.Dataset</code>和<code>torch.utils.data.DataLoader</code>。</p>
<h3 id="torchvision-datasets的使用"><a href="#torchvision-datasets的使用" class="headerlink" title="torchvision.datasets的使用"></a>torchvision.datasets的使用</h3><p>&emsp;&emsp;对于常用数据集，可以使用<code>torchvision.datasets</code>直接进行读取。<code>torchvision.dataset</code>是<code>torch.utils.data.Dataset</code>的实现，该包提供了以下数据集的读取：<code>MNIST</code>、<code>COCO(Captioning and Detection)</code>、<code>LSUN Classification</code>、<code>ImageFolder</code>、<code>Imagenet-12</code>、<code>CIFAR10 and CIFAR100</code>以及<code>STL10</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">​</span><br><span class="line">cifarSet = torchvision.datasets.CIFAR10(root=<span class="string">"./cifar/"</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>)</span><br><span class="line">print(cifarSet[<span class="number">0</span>])</span><br><span class="line">img, label = cifarSet[<span class="number">0</span>]</span><br><span class="line">print(img)</span><br><span class="line">print(label)</span><br><span class="line">print(img.format, img.size, img.mode)</span><br><span class="line">img.show()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(&lt;PIL.Image.Image image mode=RGB size=<span class="number">32</span>x32 at <span class="number">0x1726952ADA0</span>&gt;, <span class="number">6</span>)</span><br><span class="line">&lt;PIL.Image.Image image mode=RGB size=<span class="number">32</span>x32 at <span class="number">0x1726952ACF8</span>&gt;</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="keyword">None</span> (<span class="number">32</span>, <span class="number">32</span>) RGB</span><br></pre></td></tr></table></figure>
<h3 id="自定义数据集基础方法"><a href="#自定义数据集基础方法" class="headerlink" title="自定义数据集基础方法"></a>自定义数据集基础方法</h3><p>&emsp;&emsp;首先要创建一个<code>Dataset</code>类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCustomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ...)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">        <span class="keyword">return</span> (img, label)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p>在这个代码中，<code>__init__()</code>用于一些初始化过程，<code>__len__()</code>返回所有数据的数量，<code>__getitem__()</code>返回数据和标签，可以这样显式调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img, label = MyCustomDataset.__getitem__(<span class="number">99</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>Transform</code>最常见的使用方法是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCustomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ..., transforms=None)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">        ...</span><br><span class="line">        self.transforms = transforms</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">        ...</span><br><span class="line">        data =  <span class="comment"># 一些读取的数据</span></span><br><span class="line">        <span class="comment"># 如果transform不为None，则进行transform操作</span></span><br><span class="line">        <span class="keyword">if</span> self.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            data = self.transforms(data)</span><br><span class="line">        <span class="keyword">return</span> (img, label)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 定义我们的transforms(1)</span></span><br><span class="line">    transformations = transforms.Compose([transforms.CenterCrop(<span class="number">100</span>),</span><br><span class="line">                                          transforms.ToTensor()])</span><br><span class="line">    custom_dataset = MyCustomDataset(..., transformations)  <span class="comment"># 创建dataset</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;有些人不喜欢把<code>transform</code>操作写在<code>Dataset</code>外面(上面代码里的注释<code>1</code>)，所以还有一种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCustomDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ...)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># (2) 一种方法是单独定义transform</span></span><br><span class="line">        self.center_crop = transforms.CenterCrop(<span class="number">100</span>)</span><br><span class="line">        self.to_tensor = transforms.ToTensor()</span><br><span class="line">        <span class="comment"># (3) 或者写成下面这样</span></span><br><span class="line">        self.transformations = transforms.Compose([transforms.CenterCrop(<span class="number">100</span>),</span><br><span class="line">                                                   transforms.ToTensor()])</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># stuff</span></span><br><span class="line">        ...</span><br><span class="line">        data =  <span class="comment"># 一些读取的数据</span></span><br><span class="line">        <span class="comment"># 当第二次调用transform时，调用的是“__call__()”</span></span><br><span class="line">        data = self.center_crop(data)  <span class="comment"># (2)</span></span><br><span class="line">        data = self.to_tensor(data)  <span class="comment"># (2)</span></span><br><span class="line">        <span class="comment"># 或者写成下面这样</span></span><br><span class="line">        data = self.trasnformations(data)  <span class="comment"># (3)</span></span><br><span class="line">        <span class="comment"># 注意(2)和(3)中只需要实现一种</span></span><br><span class="line">        <span class="keyword">return</span> (img, label)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    custom_dataset = MyCustomDataset(...)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;假如说我们想从一个<code>csv</code>文件中读取数据，一个<code>csv</code>示例如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>File Name</th>
<th>Label</th>
<th>Extra Operation</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tr_0.png</code></td>
<td><code>5</code></td>
<td><code>TRUE</code></td>
</tr>
<tr>
<td><code>tr_1.png</code></td>
<td><code>0</code></td>
<td><code>FALSE</code></td>
</tr>
<tr>
<td><code>tr_1.png</code></td>
<td><code>4</code></td>
<td><code>FALSE</code></td>
</tr>
</tbody>
</table>
</div>
<p>如果我们需要在自定义数据集里从这个<code>csv</code>文件读取文件名，可以这样做：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDatasetFromImages</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, csv_path)</span>:</span></span><br><span class="line">        <span class="string">""" 参数csv_path是csv文件路径 """</span></span><br><span class="line">        self.to_tensor = transforms.ToTensor()  <span class="comment"># Transforms</span></span><br><span class="line">        self.data_info = pd.read_csv(csv_path, header=<span class="keyword">None</span>)  <span class="comment"># 读取csv文件</span></span><br><span class="line">        self.image_arr = np.asarray(self.data_info.iloc[:, <span class="number">0</span>])  <span class="comment"># 文件第一列包含图像文件的名称</span></span><br><span class="line">        self.label_arr = np.asarray(self.data_info.iloc[:, <span class="number">1</span>])  <span class="comment"># 第二列是图像的label</span></span><br><span class="line">        self.operation_arr = np.asarray(self.data_info.iloc[:, <span class="number">2</span>])  <span class="comment"># 第三列是决定是否进行额外操作</span></span><br><span class="line">        self.data_len = len(self.data_info.index)  <span class="comment"># 计算length</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        single_image_name = self.image_arr[index]  <span class="comment"># 得到文件名</span></span><br><span class="line">        img_as_img = Image.open(single_image_name)  <span class="comment"># 读取图像文件</span></span><br><span class="line">        some_operation = self.operation_arr[index]  <span class="comment"># 检查需不需要额外操作</span></span><br><span class="line">        <span class="keyword">if</span> some_operation:  <span class="comment"># 如果需要额外操作</span></span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        img_as_tensor = self.to_tensor(img_as_img)  <span class="comment"># 把图像转换成tensor</span></span><br><span class="line">        single_image_label = self.label_arr[index]  <span class="comment"># 得到图像的label</span></span><br><span class="line">        <span class="keyword">return</span> (img_as_tensor, single_image_label)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data_len</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    custom_mnist_from_images = CustomDatasetFromImages(<span class="string">'../data/mnist_labels.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;另一种情况是<code>csv</code>文件中保存了我们需要的图像文件的像素值，这里需要改动一下<code>__getitem__()</code>函数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Label</th>
<th>pixel_1</th>
<th>pixel_2</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>1</code></td>
<td><code>50</code></td>
<td><code>99</code></td>
<td><code>...</code></td>
</tr>
<tr>
<td><code>0</code></td>
<td><code>21</code></td>
<td><code>223</code></td>
<td><code>...</code></td>
</tr>
<tr>
<td><code>9</code></td>
<td><code>44</code></td>
<td><code>112</code></td>
<td><code>...</code></td>
</tr>
</tbody>
</table>
</div>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDatasetFromCSV</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, csv_path, height, width, transforms=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        参数csv_path是csv文件路径，height是图像高度，width是图像宽度，transform是transform操作</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.data = pd.read_csv(csv_path)</span><br><span class="line">        self.labels = np.asarray(self.data.iloc[:, <span class="number">0</span>])</span><br><span class="line">        self.height = height</span><br><span class="line">        self.width = width</span><br><span class="line">        self.transforms = transform</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        single_image_label = self.labels[index]</span><br><span class="line">        <span class="comment"># 读取所有像素值，并将“1D array ([784])”reshape成为“2D array ([28,28])”</span></span><br><span class="line">        img_as_np = np.asarray(self.data.iloc[index][<span class="number">1</span>:]).reshape(<span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">        <span class="comment"># 把“numpy array”格式的图像转换成灰度“PIL image”</span></span><br><span class="line">        img_as_img = Image.fromarray(img_as_np)</span><br><span class="line">        img_as_img = img_as_img.convert(<span class="string">'L'</span>)</span><br><span class="line">        <span class="keyword">if</span> self.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            img_as_tensor = self.transforms(img_as_img)  <span class="comment"># 将图像转换成tensor</span></span><br><span class="line">        <span class="keyword">return</span> (img_as_tensor, single_image_label)  <span class="comment"># 返回图像及其label</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data.index)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    transformations = transforms.Compose([transforms.ToTensor()])</span><br><span class="line">    custom_mnist_from_csv = CustomDatasetFromCSV(<span class="string">'./data/mnist_in_csv.csv'</span>, <span class="number">28</span>, <span class="number">28</span>, transformations)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>PyTorch</code>中的<code>Dataloader</code>只是调用<code>__getitem__()</code>方法并组合成<code>batch</code>，我们可以这样调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    transformations = transforms.Compose([transforms.ToTensor()])  <span class="comment"># 定义transforms</span></span><br><span class="line">    <span class="comment"># 自定义数据集</span></span><br><span class="line">    custom_mnist_from_csv = CustomDatasetFromCSV(<span class="string">'./data/mnist_in_csv.csv'</span>,</span><br><span class="line">                                                 <span class="number">28</span>, <span class="number">28</span>, transformations)</span><br><span class="line">    <span class="comment"># 定义“data loader”</span></span><br><span class="line">    mn_dataset_loader = torch.utils.data.DataLoader(dataset=custom_mnist_from_csv,</span><br><span class="line">                                                    batch_size=<span class="number">10</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> mn_dataset_loader:</span><br><span class="line">        <span class="comment"># 将数据传给网络模型</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是使用多<code>GPU</code>训练时，<code>PyTorch</code>的<code>dataloader</code>会将每个<code>batch</code>平均分配到各个<code>GPU</code>。所以如果<code>batch size</code>过小，可能发挥不了多<code>GPU</code>的效果。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/14/办公/Markdown教程/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/14/办公/Markdown教程/" itemprop="url">Markdown教程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-14T15:25:43+08:00">
                2019-01-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>Markdown</code>的优点主要有：纯文本，所以兼容性极强，可以用所有文本编辑器打开；让你专注于文字而不是排版；格式转换方便，<code>Markdown</code>的文本你可以轻松转换为<code>html</code>、电子书等；<code>Markdown</code>的标记语法有极好的可读性。</p>
<h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><p>&emsp;&emsp;在<code>word</code>中，插入标题的步骤是：<code>输入文本</code>-&gt;<code>选中文本</code>-&gt;<code>设置标题格式</code>。而在<code>Markdown</code>中，只需要在文本前面加上<code>#</code>即可。同理，你还可以增加二级标题至六级标题，只需要增加<code>#</code>即可，标题字号相应降低。注意，<code>#</code>和标题之间建议保留一个字符的空格，这是最标准的<code>Markdown</code>写法。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 一级标题</span></span><br><span class="line"><span class="section">## 二级标题</span></span><br><span class="line"><span class="section">### 三级标题</span></span><br><span class="line"><span class="section">#### 四级标题</span></span><br><span class="line"><span class="section">##### 五级标题</span></span><br><span class="line"><span class="section">###### 六级标题</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/办公/Markdown教程/1.png" height="159" width="75"></p>
<h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>&emsp;&emsp;列表格式在文字排版中也很常用，使用<code>Markdown</code>只需要在文字前面加上<code>-</code>就可以了：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">- </span>文本1</span><br><span class="line"><span class="bullet">- </span>文本2</span><br><span class="line"><span class="bullet">- </span>文本3</span><br></pre></td></tr></table></figure>
<ul>
<li>文本1</li>
<li>文本2</li>
<li>文本3</li>
</ul>
<p>对于有序列表，在文字前面加上<code>1.</code>、<code>2.</code>、<code>3.</code>就可以了：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1. </span>文本1</span><br><span class="line"><span class="bullet">2. </span>文本2</span><br><span class="line"><span class="bullet">3. </span>文本3</span><br></pre></td></tr></table></figure>
<ol>
<li>文本1</li>
<li>文本2</li>
<li>文本3</li>
</ol>
<h3 id="链接和图片"><a href="#链接和图片" class="headerlink" title="链接和图片"></a>链接和图片</h3><p>&emsp;&emsp;在<code>Markdown</code>中，插入链接不需要其他按钮，只需要使用<code>[显示文本](链接地址)</code>这样的语法即可：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">简书</span>](<span class="link">http://www.jianshu.com</span>)</span><br></pre></td></tr></table></figure>
<p>也可以把链接放在文章的末尾，注意中间必须要有空行：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[简书]</span><br><span class="line">​</span><br><span class="line">[<span class="symbol">简书</span>]:<span class="link">(http://www.jianshu.com)</span></span><br></pre></td></tr></table></figure>
<p>插入图片只需要使用<code>![](图片链接地址)</code>这样的语法即可(此方法也可以插入本地图片)：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![](https://www.google.com/images/branding/googlelogo/1x/googlelogo<span class="emphasis">_color_</span>272x92dp.png)</span><br></pre></td></tr></table></figure>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>&emsp;&emsp;在写作时经常需要引用他人的文字，于是引用这个格式就很有必要了。在<code>Markdown</code>中，只需要在希望引用的文字前面加上<code>&gt;</code>就好了：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="quote">&gt; 一盏灯，一片昏黄；一简书，一杯淡茶。守着那一份淡定，品读属于自己的寂寞。</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>一盏灯，一片昏黄；一简书，一杯淡茶。守着那一份淡定，品读属于自己的寂寞。</p>
</blockquote>
<p>对于诗句的引用，在每一行前面加上<code>&gt;</code>即可：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="quote">&gt; 保持淡定，才能欣赏到最美丽的风景！</span></span><br><span class="line"><span class="quote">&gt; 保持淡定，人生从此不再寂寞。</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>保持淡定，才能欣赏到最美丽的风景！<br>保持淡定，人生从此不再寂寞。</p>
</blockquote>
<h3 id="粗体和斜体"><a href="#粗体和斜体" class="headerlink" title="粗体和斜体"></a>粗体和斜体</h3><p>&emsp;&emsp;用两个<code>*</code>包含一段文本就是粗体的语法，用一个<code>*</code>包含一段文本就是斜体的语法：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="emphasis">*一盏灯*</span>，一片昏黄；<span class="strong">**一简书**</span></span><br></pre></td></tr></table></figure>
<p><em>一盏灯</em>，一片昏黄；<strong>一简书</strong></p>
<h3 id="代码引用"><a href="#代码引用" class="headerlink" title="代码引用"></a>代码引用</h3><p>&emsp;&emsp;在引用代码时，如果引用的语句只有一段，且不分行，可以用<code>`</code>将语句括起来。如果引用的语句为多行，可以将<code>```</code>置于这段代码的首行和末行。</p>
<p><img src="/2019/01/14/办公/Markdown教程/2.png" height="112" width="153"></p>
<p><code>hello world</code><br>I am <code>Fukangwei</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"hello"</span>)</span><br><span class="line">print(<span class="string">"world"</span>)</span><br></pre></td></tr></table></figure>
<p>如果需要对代码进行高亮处理，可以使用如下格式：<br><img src="/2019/01/14/办公/Markdown教程/3.png" height="78" width="155"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (condition) &#123;</span><br><span class="line">    return true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>language_key</code>可以是如下选项：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Language</th>
<th>key</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>C</code></td>
<td><code>c</code></td>
</tr>
<tr>
<td><code>ActionScript</code></td>
<td><code>actionscript</code></td>
</tr>
<tr>
<td><code>Apache</code></td>
<td><code>apache</code></td>
</tr>
<tr>
<td><code>AppleScript</code></td>
<td><code>applescript</code></td>
</tr>
<tr>
<td><code>AsciiDoc</code></td>
<td><code>asciidoc</code></td>
</tr>
<tr>
<td><code>AspectJ</code></td>
<td><code>asciidoc</code></td>
</tr>
<tr>
<td><code>AutoHotkey</code></td>
<td><code>autohotkey</code></td>
</tr>
<tr>
<td><code>AVR Assembler</code></td>
<td><code>avrasm</code></td>
</tr>
<tr>
<td><code>Axapta</code></td>
<td><code>axapta</code></td>
</tr>
<tr>
<td><code>Bash</code></td>
<td><code>bash</code></td>
</tr>
<tr>
<td><code>BrainFuck</code></td>
<td><code>brainfuck</code></td>
</tr>
<tr>
<td><code>Cap&#39;n Proto</code></td>
<td><code>capnproto</code></td>
</tr>
<tr>
<td><code>Clojure REPL</code></td>
<td><code>clojure</code></td>
</tr>
<tr>
<td><code>Clojure</code></td>
<td><code>clojure</code></td>
</tr>
<tr>
<td><code>CMake</code></td>
<td><code>cmake</code></td>
</tr>
<tr>
<td><code>CoffeeScript</code></td>
<td><code>coffeescript</code></td>
</tr>
<tr>
<td><code>C++</code></td>
<td><code>cpp</code></td>
</tr>
<tr>
<td><code>C#</code></td>
<td><code>cs</code></td>
</tr>
<tr>
<td><code>CSS</code></td>
<td><code>css</code></td>
</tr>
<tr>
<td><code>D</code></td>
<td><code>d</code></td>
</tr>
<tr>
<td><code>Dart</code></td>
<td><code>d</code></td>
</tr>
<tr>
<td><code>Delphi</code></td>
<td><code>delphi</code></td>
</tr>
<tr>
<td><code>Diff</code></td>
<td><code>diff</code></td>
</tr>
<tr>
<td><code>Django</code></td>
<td><code>django</code></td>
</tr>
<tr>
<td><code>DOS .bat</code></td>
<td><code>dos</code></td>
</tr>
<tr>
<td><code>Dust</code></td>
<td><code>dust</code></td>
</tr>
<tr>
<td><code>Elixir</code></td>
<td><code>elixir</code></td>
</tr>
<tr>
<td><code>ERB (Embedded Ruby)</code></td>
<td><code>erb</code></td>
</tr>
<tr>
<td><code>Erlang REPL</code></td>
<td><code>erlang-repl</code></td>
</tr>
<tr>
<td><code>Erlang</code></td>
<td><code>erlang</code></td>
</tr>
<tr>
<td><code>FIX</code></td>
<td><code>fix</code></td>
</tr>
<tr>
<td><code>F#</code></td>
<td><code>fsharp</code></td>
</tr>
<tr>
<td><code>G-code (ISO 6983)</code></td>
<td><code>gcode</code></td>
</tr>
<tr>
<td><code>Gherkin</code></td>
<td><code>gherkin</code></td>
</tr>
<tr>
<td><code>GLSL</code></td>
<td><code>glsl</code></td>
</tr>
<tr>
<td><code>Go</code></td>
<td><code>go</code></td>
</tr>
<tr>
<td><code>Gradle</code></td>
<td><code>gradle</code></td>
</tr>
<tr>
<td><code>Groovy</code></td>
<td><code>groovy</code></td>
</tr>
<tr>
<td><code>Haml</code></td>
<td><code>haml</code></td>
</tr>
<tr>
<td><code>Handlebars</code></td>
<td><code>handlebars</code></td>
</tr>
<tr>
<td><code>Haskell</code></td>
<td><code>haskell</code></td>
</tr>
<tr>
<td><code>Haxe</code></td>
<td><code>haxe</code></td>
</tr>
<tr>
<td><code>HTTP</code></td>
<td><code>http</code></td>
</tr>
<tr>
<td><code>Ini file</code></td>
<td><code>ini</code></td>
</tr>
<tr>
<td><code>Java</code></td>
<td><code>java</code></td>
</tr>
<tr>
<td><code>JavaScript</code></td>
<td><code>javascript</code></td>
</tr>
<tr>
<td><code>JSON</code></td>
<td><code>json</code></td>
</tr>
<tr>
<td><code>Lasso</code></td>
<td><code>lasso</code></td>
</tr>
<tr>
<td><code>Less</code></td>
<td><code>less</code></td>
</tr>
<tr>
<td><code>Lisp</code></td>
<td><code>lisp</code></td>
</tr>
<tr>
<td><code>LiveCode</code></td>
<td><code>livecodeserver</code></td>
</tr>
<tr>
<td><code>LiveScript</code></td>
<td><code>livescript</code></td>
</tr>
<tr>
<td><code>Lua</code></td>
<td><code>lua</code></td>
</tr>
<tr>
<td><code>Makefile</code></td>
<td><code>makefile</code></td>
</tr>
<tr>
<td><code>Markdown</code></td>
<td><code>markdown</code></td>
</tr>
<tr>
<td><code>Mathematica</code></td>
<td><code>mathematica</code></td>
</tr>
<tr>
<td><code>Matlab</code></td>
<td><code>matlab</code></td>
</tr>
<tr>
<td><code>MEL (Maya Embedded Language)</code></td>
<td><code>mel</code></td>
</tr>
<tr>
<td><code>Mercury</code></td>
<td><code>mercury</code></td>
</tr>
<tr>
<td><code>Mizar</code></td>
<td><code>mizar</code></td>
</tr>
<tr>
<td><code>Monkey</code></td>
<td><code>monkey</code></td>
</tr>
<tr>
<td><code>nginx</code></td>
<td><code>nginx</code></td>
</tr>
<tr>
<td><code>Nimrod</code></td>
<td><code>nimrod</code></td>
</tr>
<tr>
<td><code>Nix</code></td>
<td><code>nix</code></td>
</tr>
<tr>
<td><code>NSIS</code></td>
<td><code>nsis</code></td>
</tr>
<tr>
<td><code>Objective C</code></td>
<td><code>objectivec</code></td>
</tr>
<tr>
<td><code>OCaml</code></td>
<td><code>ocaml</code></td>
</tr>
<tr>
<td><code>Oxygene</code></td>
<td><code>oxygene</code></td>
</tr>
<tr>
<td><code>Parser 3</code></td>
<td><code>parser3</code></td>
</tr>
<tr>
<td><code>Perl</code></td>
<td><code>perl</code></td>
</tr>
<tr>
<td><code>PHP</code></td>
<td><code>php</code></td>
</tr>
<tr>
<td><code>PowerShell</code></td>
<td><code>powershell</code></td>
</tr>
<tr>
<td><code>Processing</code></td>
<td><code>processing</code></td>
</tr>
<tr>
<td><code>Python&#39;s profiler output</code></td>
<td><code>profile</code></td>
</tr>
<tr>
<td><code>Protocol Buffers</code></td>
<td><code>protobuf</code></td>
</tr>
<tr>
<td><code>Puppet</code></td>
<td><code>puppet</code></td>
</tr>
<tr>
<td><code>Python</code></td>
<td><code>python</code></td>
</tr>
<tr>
<td><code>Q</code></td>
<td><code>q</code></td>
</tr>
<tr>
<td><code>R</code></td>
<td><code>r</code></td>
</tr>
<tr>
<td><code>RenderMan RIB</code></td>
<td><code>rib</code></td>
</tr>
<tr>
<td><code>Roboconf</code></td>
<td><code>roboconf</code></td>
</tr>
<tr>
<td><code>RenderMan RSL</code></td>
<td><code>rsl</code></td>
</tr>
<tr>
<td><code>Ruby</code></td>
<td><code>ruby</code></td>
</tr>
<tr>
<td><code>Oracle Rules Language</code></td>
<td><code>ruleslanguage</code></td>
</tr>
<tr>
<td><code>Rust</code></td>
<td><code>rust</code></td>
</tr>
<tr>
<td><code>Scala</code></td>
<td><code>scala</code></td>
</tr>
<tr>
<td><code>Scheme</code></td>
<td><code>scheme</code></td>
</tr>
<tr>
<td><code>Scilab</code></td>
<td><code>scilab</code></td>
</tr>
<tr>
<td><code>SCSS</code></td>
<td><code>scss</code></td>
</tr>
<tr>
<td><code>Smali</code></td>
<td><code>smali</code></td>
</tr>
<tr>
<td><code>SmallTalk</code></td>
<td><code>smalltalk</code></td>
</tr>
<tr>
<td><code>SML</code></td>
<td><code>sml</code></td>
</tr>
<tr>
<td><code>SQL</code></td>
<td><code>sql</code></td>
</tr>
<tr>
<td><code>Stata</code></td>
<td><code>stata</code></td>
</tr>
<tr>
<td><code>STEP Part 21 (ISO 10303-21)</code></td>
<td><code>step21</code></td>
</tr>
<tr>
<td><code>Stylus</code></td>
<td><code>stylus</code></td>
</tr>
<tr>
<td><code>Swift</code></td>
<td><code>swift</code></td>
</tr>
<tr>
<td><code>Tcl</code></td>
<td><code>tcl</code></td>
</tr>
<tr>
<td><code>TeX</code></td>
<td><code>tex</code></td>
</tr>
<tr>
<td><code>Thrift</code></td>
<td><code>thrift</code></td>
</tr>
<tr>
<td><code>Twig</code></td>
<td><code>twig</code></td>
</tr>
<tr>
<td><code>TypeScript</code></td>
<td><code>typescript</code></td>
</tr>
<tr>
<td><code>Vala</code></td>
<td><code>vala</code></td>
</tr>
<tr>
<td><code>VB.NET</code></td>
<td><code>vbnet</code></td>
</tr>
<tr>
<td><code>VBScript in HTML</code></td>
<td><code>vbscript-html</code></td>
</tr>
<tr>
<td><code>VBScript</code></td>
<td><code>vbscript</code></td>
</tr>
<tr>
<td><code>Verilog</code></td>
<td><code>verilog</code></td>
</tr>
<tr>
<td><code>VHDL</code></td>
<td><code>vhdl</code></td>
</tr>
<tr>
<td><code>Vim Script</code></td>
<td><code>vim</code></td>
</tr>
<tr>
<td><code>Intel x86 Assembly</code></td>
<td><code>x86asm</code></td>
</tr>
<tr>
<td><code>XL</code></td>
<td><code>xl</code></td>
</tr>
<tr>
<td><code>XML</code>或<code>HTML</code></td>
<td><code>xml</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>&emsp;&emsp;代码如下所示，注意这<code>3</code>列之间区别：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">| Tables        | Are           | Cool  |</span><br><span class="line">| ------------- |:-------------:| -----:|</span><br><span class="line">| col 3 is      | right-aligned | $1600 |</span><br><span class="line">| col 2 is      | centered      |   $12 |</span><br><span class="line">| zebra stripes | are neat      |    $1 |</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>Tables</th>
<th style="text-align:center">Are</th>
<th style="text-align:right">Cool</th>
</tr>
</thead>
<tbody>
<tr>
<td>col 3 is</td>
<td style="text-align:center">right-aligned</td>
<td style="text-align:right">$1600</td>
</tr>
<tr>
<td>col 2 is</td>
<td style="text-align:center">centered</td>
<td style="text-align:right">$12</td>
</tr>
<tr>
<td>zebra stripes</td>
<td style="text-align:center">are neat</td>
<td style="text-align:right">$1</td>
</tr>
</tbody>
</table>
</div>
<p>另一种写法如下所示：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dog | bird | cat</span><br><span class="line">----|------|----</span><br><span class="line">foo | foo  | foo</span><br><span class="line">bar | bar  | bar</span><br><span class="line">baz | baz  | baz</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>dog</th>
<th>bird</th>
<th>cat</th>
</tr>
</thead>
<tbody>
<tr>
<td>foo</td>
<td>foo</td>
<td>foo</td>
</tr>
<tr>
<td>bar</td>
<td>bar</td>
<td>bar</td>
</tr>
<tr>
<td>baz</td>
<td>baz</td>
<td>baz</td>
</tr>
</tbody>
</table>
</div>
<h3 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h3><p>&emsp;&emsp;分割线的语法只需要三个<code>*</code>号(实际上<code>***</code>、<code>---</code>、<code>===</code>和<code>___</code>都是分割线语法)：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="emphasis">***</span></span><br><span class="line">hello, fukangwei</span><br></pre></td></tr></table></figure>
<h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>&emsp;&emsp;代码示例如下：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这是脚注一[^1]</span><br><span class="line">这是脚注二[^2]</span><br><span class="line">​</span><br><span class="line">[<span class="symbol">^1</span>]: <span class="link">脚注一</span></span><br><span class="line">[<span class="symbol">^2</span>]: <span class="link">脚注二</span></span><br></pre></td></tr></table></figure>
<p>这是脚注一<sup><a href="#fn_1" id="reffn_1">1</a></sup><br>这是脚注二<sup><a href="#fn_2" id="reffn_2">2</a></sup><br>​</p>
<blockquote id="fn_1">
<sup>1</sup>. 脚注一<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. 脚注二<a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<h3 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h3><p>&emsp;&emsp;在<code>GitHub</code>和<code>GitLab</code>等网站，除了可以使用有序列表和无序列表外，还可以使用任务列表，很适合要列出一些清单的场景。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">- </span>[ ] 一次性水杯</span><br><span class="line"><span class="bullet">- </span>[x] 西瓜</span><br><span class="line"><span class="bullet">- </span>[ ] 豆浆</span><br><span class="line"><span class="bullet">- </span>[x] 可口可乐</span><br><span class="line"><span class="bullet">- </span>[ ] 小茗同学</span><br></pre></td></tr></table></figure>
<ul>
<li>[ ] 一次性水杯</li>
<li>[x] 西瓜</li>
<li>[ ] 豆浆</li>
<li>[x] 可口可乐</li>
<li>[ ] 小茗同学</li>
</ul>
<h3 id="反斜杠"><a href="#反斜杠" class="headerlink" title="反斜杠"></a>反斜杠</h3><p>&emsp;&emsp;<code>Markdown</code>可以利用反斜杠来插入一些在语法中有其它意义的符号(也就是进行转义)，例如下面的语句用于显示<code>*literal asterisks*</code>：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\<span class="emphasis">*literal asterisks\*</span></span><br></pre></td></tr></table></figure>
<p>转义符号如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\</code></td>
<td>反斜线</td>
</tr>
<tr>
<td><code>`</code></td>
<td>反引号</td>
</tr>
<tr>
<td><code>*</code></td>
<td>星号</td>
</tr>
<tr>
<td><code>_</code></td>
<td>底线</td>
</tr>
<tr>
<td><code>{}</code></td>
<td>花括号</td>
</tr>
<tr>
<td><code>[]</code></td>
<td>方括号</td>
</tr>
<tr>
<td><code>()</code></td>
<td>括弧</td>
</tr>
<tr>
<td><code>#</code></td>
<td>井字号</td>
</tr>
<tr>
<td><code>+</code></td>
<td>加号</td>
</tr>
<tr>
<td><code>-</code></td>
<td>减号</td>
</tr>
<tr>
<td><code>.</code></td>
<td>英文句点</td>
</tr>
<tr>
<td><code>!</code></td>
<td>惊叹号</td>
</tr>
</tbody>
</table>
</div>
<h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><p>&emsp;&emsp;删除线的语法如下：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~~这是删除线~~</span><br></pre></td></tr></table></figure>
<p><del>这是删除线</del></p>
<h3 id="首行缩进"><a href="#首行缩进" class="headerlink" title="首行缩进"></a>首行缩进</h3><p>&emsp;&emsp;使用特殊占位符可以实现首行缩进：</p>
<ul>
<li><code>&amp;ensp;</code>或<code>&amp;#8194;</code>是半角。</li>
<li><code>&amp;emsp;</code>或<code>&amp;#8195;</code>是全角。</li>
</ul>
<p>代码示例：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&amp;ensp;你好</span><br><span class="line">&amp;emsp;你好</span><br><span class="line">&amp;emsp;&amp;emsp;你好</span><br><span class="line">hello, Look at me</span><br></pre></td></tr></table></figure>
<p>&ensp;你好<br>&emsp;你好<br>&emsp;&emsp;你好<br>hello, Look at me</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/14/办公/Visio使用注意事项/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/14/办公/Visio使用注意事项/" itemprop="url">Visio使用注意事项</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-14T15:04:52+08:00">
                2019-01-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>在<code>Visio</code>中输入希腊字母，步骤为：先选择<code>插入</code>，再选择<code>公式</code>。</li>
<li><code>Visio</code>画出大括号与花括号：<code>文件</code>-&gt;<code>形状</code>-&gt;<code>其他Visio方案</code>-&gt;<code>标注</code>-&gt;<code>侧边大括号</code>。</li>
<li><code>Visio</code>画出电灯：可以从<code>文件</code>-&gt;<code>形状</code>-&gt;<code>电气工程</code>-&gt;<code>基本项</code>中找到，名字叫<code>灯2</code>。</li>
<li><code>Visio</code>画出云状图：寻找路径是<code>visio2010</code>-&gt;<code>文件</code>-&gt;<code>形状</code>-&gt;<code>其他visio方案</code>-&gt;<code>批注</code>-&gt;<code>修订云形</code>。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/57/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/57/">57</a><span class="page-number current">58</span><a class="page-number" href="/page/59/">59</a><span class="space">&hellip;</span><a class="page-number" href="/page/96/">96</a><a class="extend next" rel="next" href="/page/59/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">955</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
