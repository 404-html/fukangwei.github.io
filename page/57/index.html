<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="暴徒">
<meta property="og:url" content="http://fukangwei.gitee.io/page/57/index.html">
<meta property="og:site_name" content="暴徒">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="暴徒">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/page/57/">





  <title>暴徒</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">暴徒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/14/深度学习/pytorch基础教程/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/14/深度学习/pytorch基础教程/" itemprop="url">pytorch基础教程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-14T11:37:28+08:00">
                2019-01-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Torch或Numpy"><a href="#Torch或Numpy" class="headerlink" title="Torch或Numpy"></a>Torch或Numpy</h3><p>&emsp;&emsp;<code>Torch</code>自称为神经网络界的<code>Numpy</code>，因为它能将<code>torch</code>产生的<code>tensor</code>放在<code>GPU</code>中加速运算，就像<code>Numpy</code>会把<code>array</code>放在<code>CPU</code>中加速运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line">np_data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">torch_data = torch.from_numpy(np_data)</span><br><span class="line">tensor2array = torch_data.numpy()</span><br><span class="line">​</span><br><span class="line">print(<span class="string">'numpy array:\n'</span>, np_data)</span><br><span class="line">print(<span class="string">'torch tensor:\n'</span>, torch_data)</span><br><span class="line">print(<span class="string">'tensor to array:\n'</span>, tensor2array)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">numpy array:</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]]</span><br><span class="line">torch tensor:</span><br><span class="line"> tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]], dtype=torch.int32)</span><br><span class="line">tensor to array:</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure>
<h4 id="Torch中的数学运算"><a href="#Torch中的数学运算" class="headerlink" title="Torch中的数学运算"></a>Torch中的数学运算</h4><p>&emsp;&emsp;其实<code>torch</code>中<code>tensor</code>的运算和<code>numpy</code>中<code>array</code>如出一辙：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line">data = [<span class="number">-1</span>, <span class="number">-2</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">tensor = torch.FloatTensor(data)  <span class="comment"># 转换成32位浮点tensor</span></span><br><span class="line">print(  <span class="comment"># abs绝对值计算</span></span><br><span class="line">    <span class="string">'abs'</span>,</span><br><span class="line">    <span class="string">'\nnumpy:'</span>, np.abs(data),</span><br><span class="line">    <span class="string">'\ntorch:'</span>, torch.abs(tensor)</span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line">print(  <span class="comment"># sin三角函数</span></span><br><span class="line">    <span class="string">'\nsin'</span>,</span><br><span class="line">    <span class="string">'\nnumpy:'</span>, np.sin(data),</span><br><span class="line">    <span class="string">'\ntorch:'</span>, torch.sin(tensor)</span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line">print(  <span class="comment"># mean均值</span></span><br><span class="line">    <span class="string">'\nmean'</span>,</span><br><span class="line">    <span class="string">'\nnumpy:'</span>, np.mean(data),</span><br><span class="line">    <span class="string">'\ntorch:'</span>, torch.mean(tensor)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">abs</span><br><span class="line">numpy: [<span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line">torch: tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">1.</span>, <span class="number">2.</span>])</span><br><span class="line">​</span><br><span class="line">sin</span><br><span class="line">numpy: [<span class="number">-0.84147098</span> <span class="number">-0.90929743</span>  <span class="number">0.84147098</span>  <span class="number">0.90929743</span>]</span><br><span class="line">torch: tensor([<span class="number">-0.8415</span>, <span class="number">-0.9093</span>,  <span class="number">0.8415</span>,  <span class="number">0.9093</span>])</span><br><span class="line">​</span><br><span class="line">mean</span><br><span class="line">numpy: <span class="number">0.0</span></span><br><span class="line">torch: tensor(<span class="number">0.</span>)</span><br></pre></td></tr></table></figure>
<p>除了简单的计算，矩阵运算才是神经网络中最重要的部分，所以这里演示矩阵的乘法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 矩阵点乘(matrix multiplication)</span></span><br><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">tensor = torch.FloatTensor(data)  <span class="comment"># 转换成32位浮点tensor</span></span><br><span class="line">​</span><br><span class="line">print(  <span class="comment"># correct method</span></span><br><span class="line">    <span class="string">'matrix multiplication (matmul)'</span>,</span><br><span class="line">    <span class="string">'\nnumpy:\n'</span>, np.matmul(data, data),</span><br><span class="line">    <span class="string">'\ntorch:\n'</span>, torch.mm(tensor, tensor)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">matrix multiplication (matmul)</span><br><span class="line">numpy:</span><br><span class="line"> [[ <span class="number">7</span> <span class="number">10</span>]</span><br><span class="line"> [<span class="number">15</span> <span class="number">22</span>]]</span><br><span class="line">torch:</span><br><span class="line"> tensor([[ <span class="number">7.</span>, <span class="number">10.</span>],</span><br><span class="line">        [<span class="number">15.</span>, <span class="number">22.</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="变量-Variable"><a href="#变量-Variable" class="headerlink" title="变量(Variable)"></a>变量(Variable)</h3><p>&emsp;&emsp;<code>Torch</code>中的<code>Variable</code>就是一个存放会变化的值的地理位置，里面的值会不停的变化，就像一个装鸡蛋的篮子，鸡蛋数会不停变动。那谁是里面的鸡蛋呢？自然就是<code>Torch</code>的<code>Tensor</code>。如果用一个<code>Variable</code>进行计算，那返回的也是一个同类型的<code>Variable</code>。<strong>补充说明</strong>：<code>0.4</code>版本的<code>pytorch</code>已经将<code>Tensor</code>和<code>Variable</code>合并到一起，没有区别了。<br>&emsp;&emsp;定义一个<code>Variable</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">​</span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="comment"># requires_grad控制参不参与误差反向传播，要不要计算梯度</span></span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line">print(tensor)</span><br><span class="line">print(variable)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">4.</span>]], requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Variable计算梯度"><a href="#Variable计算梯度" class="headerlink" title="Variable计算梯度"></a>Variable计算梯度</h4><p>&emsp;&emsp;再对比一下<code>tensor</code>和<code>variable</code>的计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line">t_out = torch.mean(tensor * tensor)</span><br><span class="line">v_out = torch.mean(variable * variable)</span><br><span class="line">print(t_out)</span><br><span class="line">print(v_out)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="number">7.5000</span>)</span><br><span class="line">tensor(<span class="number">7.5000</span>, grad_fn=&lt;MeanBackward1&gt;)</span><br></pre></td></tr></table></figure>
<p>到目前为止，看不出什么不同。但是时刻记住，<code>Variable</code>在计算时，它会在默默地搭建着一个叫做计算图(<code>computational graph</code>)的庞大系统。这个图的作用是将所有的计算步骤(节点)都连接起来，最后进行误差反向传递时，一次性将所有<code>variable</code>里面的修改幅度(梯度)都计算出来，而<code>tensor</code>就没有这个能力。<code>v_out = torch.mean(variable * variable)</code>就是在计算图中添加的一个计算步骤：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">​</span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line">v_out = torch.mean(variable * variable)</span><br><span class="line">v_out.backward()  <span class="comment"># 模拟v_out的误差反向传递</span></span><br><span class="line">print(variable.grad)  <span class="comment"># 初始Variable的梯度</span></span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.5000</span>, <span class="number">1.0000</span>],</span><br><span class="line">        [<span class="number">1.5000</span>, <span class="number">2.0000</span>]])</span><br></pre></td></tr></table></figure>
<h4 id="获取Variable里面的数据"><a href="#获取Variable里面的数据" class="headerlink" title="获取Variable里面的数据"></a>获取Variable里面的数据</h4><p>&emsp;&emsp;直接<code>print(variable)</code>只会输出<code>Variable</code>形式的数据，在很多时候是用不了的(比如想要用<code>plt</code>画图)，所以需要转换成<code>tensor</code>形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">​</span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line">print(variable)  <span class="comment"># Variable形式</span></span><br><span class="line">print(variable.data)  <span class="comment"># tensor形式</span></span><br><span class="line">print(variable.data.numpy())  <span class="comment"># numpy形式</span></span><br></pre></td></tr></table></figure>
<h4 id="激励函数-Activation"><a href="#激励函数-Activation" class="headerlink" title="激励函数(Activation)"></a>激励函数(Activation)</h4><p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  <span class="comment"># 激励函数都定义在这里</span></span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">x = torch.linspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">200</span>)</span><br><span class="line">x = Variable(x)</span><br><span class="line">x_np = x.data.numpy()  <span class="comment"># 转换成“numpy array”，出图时使用</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 几种常用的激励函数</span></span><br><span class="line">y_relu = F.relu(x).data.numpy()</span><br><span class="line">y_sigmoid = F.sigmoid(x).data.numpy()</span><br><span class="line">y_tanh = F.tanh(x).data.numpy()</span><br><span class="line">y_softplus = F.softplus(x).data.numpy()</span><br><span class="line"><span class="comment"># y_softmax = F.softmax(x)  # softmax比较特殊，不能直接显示</span></span><br><span class="line">​</span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x_np, y_relu, c=<span class="string">'red'</span>, label=<span class="string">'relu'</span>)</span><br><span class="line">plt.ylim((<span class="number">-1</span>, <span class="number">5</span>))</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">​</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x_np, y_sigmoid, c=<span class="string">'red'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">plt.ylim((<span class="number">-0.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">​</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x_np, y_tanh, c=<span class="string">'red'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">plt.ylim((<span class="number">-1.2</span>, <span class="number">1.2</span>))</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">​</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x_np, y_softplus, c=<span class="string">'red'</span>, label=<span class="string">'softplus'</span>)</span><br><span class="line">plt.ylim((<span class="number">-0.2</span>, <span class="number">6</span>))</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">​</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/深度学习/pytorch基础教程/1.png" height="312" width="443"></p>
<h3 id="关系拟合-回归"><a href="#关系拟合-回归" class="headerlink" title="关系拟合(回归)"></a>关系拟合(回归)</h3><p>&emsp;&emsp;这次来见证神经网络是如何通过简单的形式将一群数据用一条线条来表示，或者说是如何在数据当中找到它们的关系，然后用神经网络模型来建立一个可以代表它们关系的线条。<br>&emsp;&emsp;创建一些假数据来模拟真实的情况，比如一个一元二次函数<code>y = a * x^2 + b</code>，给<code>y</code>数据加上一点噪声来更加真实地展示它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line"><span class="comment"># x data (tensor)，shape=(100, 1)</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># noisy y data (tensor)，shape=(100, 1)</span></span><br><span class="line">y = x.pow(<span class="number">2</span>) + <span class="number">0.2</span> * torch.rand(x.size())</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;可以直接运用<code>torch</code>中的体系建立一个神经网络。先定义所有的层属性(<code>__init__()</code>)，然后再一层层搭建(<code>forward(x)</code>)层与层的关系链接。建立关系的时候，我们会用到激励函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span>  <span class="comment"># 继承torch的Module</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output)</span>:</span></span><br><span class="line">        super(Net, self).__init__()  <span class="comment"># 继承“__init__”功能</span></span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)  <span class="comment"># 隐藏层线性输出</span></span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden, n_output)  <span class="comment"># 输出层线性输出</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span>  <span class="comment"># 这同时也是Module中的forward功能</span></span><br><span class="line">        <span class="comment"># 正向传播输入值，神经网络分析出输出值</span></span><br><span class="line">        x = F.relu(self.hidden(x))  <span class="comment"># 激励函数</span></span><br><span class="line">        x = self.predict(x)  <span class="comment"># 输出值</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line">net = Net(n_feature=<span class="number">1</span>, n_hidden=<span class="number">10</span>, n_output=<span class="number">1</span>)  <span class="comment"># define the network</span></span><br><span class="line">print(net)  <span class="comment"># 打印net的结构</span></span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Net(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">1</span>, out_features=<span class="number">10</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (predict): Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;训练的步骤如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入net的所有参数以及学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.2</span>)</span><br><span class="line">loss_func = torch.nn.MSELoss()  <span class="comment"># 预测值和真实值的误差计算公式(均方差)</span></span><br><span class="line">​</span><br><span class="line">plt.ion()</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">    prediction = net(x)  <span class="comment"># 喂给net训练数据x，输出预测值</span></span><br><span class="line">    loss = loss_func(prediction, y)  <span class="comment"># 计算两者的误差</span></span><br><span class="line">​</span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># 清空上一步的残余更新参数值</span></span><br><span class="line">    loss.backward()  <span class="comment"># 误差反向传播，计算参数更新值</span></span><br><span class="line">    optimizer.step()  <span class="comment"># 将参数更新值施加到net的parameters上</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># plot and show learning process</span></span><br><span class="line">        plt.cla()</span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">        plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">        plt.text(</span><br><span class="line">            <span class="number">0.5</span>, <span class="number">0</span>, <span class="string">'Loss=%.4f'</span> % loss.data.numpy(),</span><br><span class="line">            fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'red'</span>&#125;)</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line">​</span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/深度学习/pytorch基础教程/2.png" height="266" width="386"></p>
<h3 id="区分类型-分类"><a href="#区分类型-分类" class="headerlink" title="区分类型(分类)"></a>区分类型(分类)</h3><p>&emsp;&emsp;创建一些数据来模拟真实的情况，比如两个二次分布的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line"><span class="comment"># make fake data</span></span><br><span class="line">n_data = torch.ones(<span class="number">100</span>, <span class="number">2</span>)  <span class="comment"># 数据的基本形态</span></span><br><span class="line">x0 = torch.normal(<span class="number">2</span> * n_data, <span class="number">1</span>)  <span class="comment"># 类型0，x data (tensor)，shape=(100, 2)</span></span><br><span class="line">y0 = torch.zeros(<span class="number">100</span>)  <span class="comment"># 类型0，y data (tensor)，shape=(100, 1)</span></span><br><span class="line">x1 = torch.normal(<span class="number">-2</span> * n_data, <span class="number">1</span>)  <span class="comment"># 类型1，x data (tensor)，shape=(100, 2)</span></span><br><span class="line">y1 = torch.ones(<span class="number">100</span>)  <span class="comment"># 类型1，y data (tensor)，shape=(100, 1)</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 注意x和y的数据形式是一定要像下面一样(torch.cat是在合并数据)</span></span><br><span class="line"><span class="comment"># shape (200, 2) FloatTensor = 32-bit floating</span></span><br><span class="line">x = torch.cat((x0, x1), <span class="number">0</span>).type(torch.FloatTensor)</span><br><span class="line"><span class="comment"># shape (200, 1) LongTensor = 64-bit integer</span></span><br><span class="line">y = torch.cat((y0, y1), ).type(torch.LongTensor)</span><br></pre></td></tr></table></figure>
<p>建立神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)  <span class="comment"># hidden layer</span></span><br><span class="line">        self.out = torch.nn.Linear(n_hidden, n_output)  <span class="comment"># output layer</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.hidden(x))  <span class="comment"># activation function for hidden layer</span></span><br><span class="line">        x = self.out(x)  <span class="comment"># 输出值，但是这个不是预测值，预测值还需要再另外计算</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line">net = Net(n_feature=<span class="number">2</span>, n_hidden=<span class="number">10</span>, n_output=<span class="number">2</span>)  <span class="comment"># define the network</span></span><br><span class="line">print(net)  <span class="comment"># net architecture</span></span><br></pre></td></tr></table></figure>
<p>训练步骤如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">loss_func = torch.nn.CrossEntropyLoss()  <span class="comment"># the target label is NOT an one-hotted</span></span><br><span class="line">​</span><br><span class="line">plt.ion()  <span class="comment"># something about plotting</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    out = net(x)  <span class="comment"># 喂给net训练数据x，输出分析值</span></span><br><span class="line">    <span class="comment"># must be (1. nn output, 2. target), the target label is NOT one-hotted</span></span><br><span class="line">    loss = loss_func(out, y)</span><br><span class="line">​</span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># clear gradients for next train</span></span><br><span class="line">    loss.backward()  <span class="comment"># backpropagation, compute gradients</span></span><br><span class="line">    optimizer.step()  <span class="comment"># apply gradients</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># plot and show learning process</span></span><br><span class="line">        plt.cla()</span><br><span class="line">        prediction = torch.max(out, <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        pred_y = prediction.data.numpy().squeeze()</span><br><span class="line">        target_y = y.data.numpy()</span><br><span class="line">        plt.scatter(x.data.numpy()[:, <span class="number">0</span>], x.data.numpy()[:, <span class="number">1</span>], c=pred_y, s=<span class="number">100</span>, lw=<span class="number">0</span>, cmap=<span class="string">'RdYlGn'</span>)</span><br><span class="line">        accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)</span><br><span class="line">        plt.text(<span class="number">1.5</span>, <span class="number">-4</span>, <span class="string">'Accuracy=%.2f'</span> % accuracy, fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'red'</span>&#125;)</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line">​</span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="快速搭建法"><a href="#快速搭建法" class="headerlink" title="快速搭建法"></a>快速搭建法</h3><p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)  <span class="comment"># hidden layer</span></span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden, n_output)  <span class="comment"># output layer</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.hidden(x))  <span class="comment"># activation function for hidden layer</span></span><br><span class="line">        x = self.predict(x)  <span class="comment"># linear output</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line">net1 = Net(<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line">net2 = torch.nn.Sequential(  <span class="comment"># easy and fast way to build your network</span></span><br><span class="line">    torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line">print(net1)  <span class="comment"># net1 architecture</span></span><br><span class="line">print(net2)  <span class="comment"># net2 architecture</span></span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Net(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">1</span>, out_features=<span class="number">10</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (predict): Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">1</span>, out_features=<span class="number">10</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (<span class="number">1</span>): ReLU()</span><br><span class="line">  (<span class="number">2</span>): Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>我们会发现<code>net2</code>多显示了一些内容，原来它把激励函数也一同纳入进去了。但是在<code>net1</code>中，激励函数实际上是在<code>forward</code>功能中才被调用的。这也就说明了相比于<code>net2</code>，<code>net1</code>的好处就是你可以根据个人需要，更加个性化你的前向传播过程(比如<code>RNN</code>)。</p>
<h3 id="保存提取"><a href="#保存提取" class="headerlink" title="保存提取"></a>保存提取</h3><p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line"><span class="comment"># fake data</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)  <span class="comment"># x data (tensor), shape=(100, 1)</span></span><br><span class="line">y = x.pow(<span class="number">2</span>) + <span class="number">0.2</span> * torch.rand(x.size())  <span class="comment"># noisy y data (tensor), shape=(100, 1)</span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># save net1</span></span><br><span class="line">    net1 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    optimizer = torch.optim.SGD(net1.parameters(), lr=<span class="number">0.5</span>)</span><br><span class="line">    loss_func = torch.nn.MSELoss()</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        prediction = net1(x)</span><br><span class="line">        loss = loss_func(prediction, y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.figure(<span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    plt.subplot(<span class="number">131</span>)</span><br><span class="line">    plt.title(<span class="string">'Net1'</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># 2 ways to save the net</span></span><br><span class="line">    torch.save(net1, <span class="string">'net.pkl'</span>)  <span class="comment"># 保存整个网络</span></span><br><span class="line">    torch.save(net1.state_dict(), <span class="string">'net_params.pkl'</span>)  <span class="comment"># 只保存网络中的参数(速度快，占内存少)</span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_net</span><span class="params">()</span>:</span></span><br><span class="line">    net2 = torch.load(<span class="string">'net.pkl'</span>)  <span class="comment"># restore entire net1 to net2</span></span><br><span class="line">    prediction = net2(x)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.subplot(<span class="number">132</span>)</span><br><span class="line">    plt.title(<span class="string">'Net2'</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_params</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># restore only the parameters in net1 to net3</span></span><br><span class="line">    net3 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>, <span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    net3.load_state_dict(torch.load(<span class="string">'net_params.pkl'</span>))  <span class="comment"># copy net1's parameters into net3</span></span><br><span class="line">    prediction = net3(x)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># plot result</span></span><br><span class="line">    plt.subplot(<span class="number">133</span>)</span><br><span class="line">    plt.title(<span class="string">'Net3'</span>)</span><br><span class="line">    plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">    plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">​</span><br><span class="line">save()  <span class="comment"># save net1</span></span><br><span class="line">restore_net()  <span class="comment"># restore entire net (may slow)</span></span><br><span class="line">restore_params()  <span class="comment"># restore only the net parameters</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/深度学习/pytorch基础教程/3.png" height="190" width="542"></p>
<h3 id="批训练"><a href="#批训练" class="headerlink" title="批训练"></a>批训练</h3><p>&emsp;&emsp;<code>DataLoader</code>是<code>torch</code>给你用来包装数据的工具，所以你要将自己的(<code>numpy array</code>或其他)数据形式装换成<code>Tensor</code>，然后再放进这个包装器中。使用<code>DataLoader</code>的好处就是，它们可以帮你有效地迭代数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line">​</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)  <span class="comment"># reproducible</span></span><br><span class="line">​</span><br><span class="line">BATCH_SIZE = <span class="number">5</span>  <span class="comment"># 批训练的数据个数</span></span><br><span class="line">​</span><br><span class="line">x = torch.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)  <span class="comment"># this is x data (torch tensor)</span></span><br><span class="line">y = torch.linspace(<span class="number">10</span>, <span class="number">1</span>, <span class="number">10</span>)  <span class="comment"># this is y data (torch tensor)</span></span><br><span class="line">​</span><br><span class="line">torch_dataset = Data.TensorDataset(x, y)  <span class="comment"># 先转换成torch能识别的Dataset</span></span><br><span class="line">loader = Data.DataLoader(</span><br><span class="line">    dataset=torch_dataset,  <span class="comment"># torch TensorDataset format</span></span><br><span class="line">    batch_size=BATCH_SIZE,  <span class="comment"># mini batch size</span></span><br><span class="line">    shuffle=<span class="keyword">True</span>,  <span class="comment"># random shuffle for training</span></span><br><span class="line">    num_workers=<span class="number">2</span>,  <span class="comment"># subprocesses for loading data</span></span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_batch</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">3</span>):  <span class="comment"># train entire dataset 3 times</span></span><br><span class="line">        <span class="keyword">for</span> step, (batch_x, batch_y) <span class="keyword">in</span> enumerate(loader):  <span class="comment"># for each training step</span></span><br><span class="line">            <span class="comment"># train your data...</span></span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">'| Step:'</span>, step,</span><br><span class="line">                  <span class="string">'| batch x:'</span>, batch_x.numpy(), <span class="string">'| batch y:'</span>, batch_y.numpy())</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    show_batch()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">0</span> | Step: <span class="number">0</span> | batch x: [<span class="number">5.</span> <span class="number">7.</span> <span class="number">10.</span> <span class="number">3.</span> <span class="number">4.</span>] | batch y: [<span class="number">6.</span> <span class="number">4.</span> <span class="number">1.</span> <span class="number">8.</span> <span class="number">7.</span>]</span><br><span class="line">Epoch: <span class="number">0</span> | Step: <span class="number">1</span> | batch x: [<span class="number">2.</span> <span class="number">1.</span> <span class="number">8.</span> <span class="number">9.</span> <span class="number">6.</span>] | batch y: [<span class="number">9.</span> <span class="number">10.</span> <span class="number">3.</span> <span class="number">2.</span> <span class="number">5.</span>]</span><br><span class="line">Epoch: <span class="number">1</span> | Step: <span class="number">0</span> | batch x: [<span class="number">4.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">10.</span> <span class="number">8.</span>] | batch y: [<span class="number">7.</span> <span class="number">5.</span> <span class="number">4.</span> <span class="number">1.</span> <span class="number">3.</span>]</span><br><span class="line">Epoch: <span class="number">1</span> | Step: <span class="number">1</span> | batch x: [<span class="number">5.</span> <span class="number">3.</span> <span class="number">2.</span> <span class="number">1.</span> <span class="number">9.</span>] | batch y: [<span class="number">6.</span> <span class="number">8.</span> <span class="number">9.</span> <span class="number">10.</span> <span class="number">2.</span>]</span><br><span class="line">Epoch: <span class="number">2</span> | Step: <span class="number">0</span> | batch x: [<span class="number">4.</span> <span class="number">2.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">10.</span>] | batch y: [<span class="number">7.</span> <span class="number">9.</span> <span class="number">6.</span> <span class="number">5.</span> <span class="number">1.</span>]</span><br><span class="line">Epoch: <span class="number">2</span> | Step: <span class="number">1</span> | batch x: [<span class="number">3.</span> <span class="number">9.</span> <span class="number">1.</span> <span class="number">8.</span> <span class="number">7.</span>] | batch y: [<span class="number">8.</span> <span class="number">2.</span> <span class="number">10.</span> <span class="number">3.</span> <span class="number">4.</span>]</span><br></pre></td></tr></table></figure>
<p>可以看出每步都导出了<code>5</code>个数据进行学习，然后每个<code>epoch</code>的导出数据都是先打乱了以后再导出。<br>&emsp;&emsp;真正方便的还不只是这一点，如果将<code>BATCH_SIZE</code>改为<code>8</code>，这样我们就知道<code>step = 0</code>时会导出<code>8</code>个数据。但是<code>step = 1</code>的时候数据库中的数据不够<code>8</code>个，这该怎么办呢？在<code>step = 1</code>的时候，就只给你返回这个<code>epoch</code>中剩下的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">0</span> | Step: <span class="number">0</span> | batch x: [<span class="number">5.</span> <span class="number">7.</span> <span class="number">10.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">2.</span> <span class="number">1.</span> <span class="number">8.</span>] | batch y: [<span class="number">6.</span> <span class="number">4.</span> <span class="number">1.</span> <span class="number">8.</span> <span class="number">7.</span> <span class="number">9.</span> <span class="number">10.</span> <span class="number">3.</span>]</span><br><span class="line">Epoch: <span class="number">0</span> | Step: <span class="number">1</span> | batch x: [<span class="number">9.</span> <span class="number">6.</span>] | batch y: [<span class="number">2.</span> <span class="number">5.</span>]</span><br><span class="line">Epoch: <span class="number">1</span> | Step: <span class="number">0</span> | batch x: [<span class="number">4.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">10.</span> <span class="number">8.</span> <span class="number">5.</span> <span class="number">3.</span> <span class="number">2.</span>] | batch y: [<span class="number">7.</span> <span class="number">5.</span> <span class="number">4.</span> <span class="number">1.</span> <span class="number">3.</span> <span class="number">6.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">Epoch: <span class="number">1</span> | Step: <span class="number">1</span> | batch x: [<span class="number">1.</span> <span class="number">9.</span>] | batch y: [<span class="number">10.</span> <span class="number">2.</span>]</span><br><span class="line">Epoch: <span class="number">2</span> | Step: <span class="number">0</span> | batch x: [<span class="number">4.</span> <span class="number">2.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">10.</span> <span class="number">3.</span> <span class="number">9.</span> <span class="number">1.</span>] | batch y: [<span class="number">7.</span> <span class="number">9.</span> <span class="number">6.</span> <span class="number">5.</span> <span class="number">1.</span> <span class="number">8.</span> <span class="number">2.</span> <span class="number">10.</span>]</span><br><span class="line">Epoch: <span class="number">2</span> | Step: <span class="number">1</span> | batch x: [<span class="number">8.</span> <span class="number">7.</span>] | batch y: [<span class="number">3.</span> <span class="number">4.</span>]</span><br></pre></td></tr></table></figure>
<h3 id="Optimizer优化器"><a href="#Optimizer优化器" class="headerlink" title="Optimizer优化器"></a>Optimizer优化器</h3><p>&emsp;&emsp;为了对比各种优化器的效果，需要模拟一些数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">EPOCH = <span class="number">12</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># fake dataset</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1000</span>), dim=<span class="number">1</span>)</span><br><span class="line">y = x.pow(<span class="number">2</span>) + <span class="number">0.1</span> * torch.normal(torch.zeros(*x.size()))</span><br><span class="line">​</span><br><span class="line"><span class="comment"># put dateset into torch dataset</span></span><br><span class="line">torch_dataset = Data.TensorDataset(x, y)</span><br><span class="line">loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>为了对比每一种优化器，我们给它们各自创建一个神经网络，但这个神经网络都来自同一个<code>Net</code>形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span>  <span class="comment"># default network</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(<span class="number">1</span>, <span class="number">20</span>)  <span class="comment"># hidden layer</span></span><br><span class="line">        self.predict = torch.nn.Linear(<span class="number">20</span>, <span class="number">1</span>)  <span class="comment"># output layer</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.hidden(x))  <span class="comment"># activation function for hidden layer</span></span><br><span class="line">        x = self.predict(x)  <span class="comment"># linear output</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 为每个优化器创建一个net</span></span><br><span class="line">    net_SGD = Net()</span><br><span class="line">    net_Momentum = Net()</span><br><span class="line">    net_RMSprop = Net()</span><br><span class="line">    net_Adam = Net()</span><br><span class="line">    nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># different optimizers</span></span><br><span class="line">    opt_SGD = torch.optim.SGD(net_SGD.parameters(), lr=LR)</span><br><span class="line">    opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=<span class="number">0.8</span>)</span><br><span class="line">    opt_RMSprop = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=<span class="number">0.9</span>)</span><br><span class="line">    opt_Adam = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(<span class="number">0.9</span>, <span class="number">0.99</span>))</span><br><span class="line">    optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]</span><br><span class="line">​</span><br><span class="line">    loss_func = torch.nn.MSELoss()</span><br><span class="line">    losses_his = [[], [], [], []]  <span class="comment"># 记录training时不同神经网络的loss</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):  <span class="comment"># training</span></span><br><span class="line">        print(<span class="string">'Epoch: '</span>, epoch)</span><br><span class="line">        <span class="keyword">for</span> step, (b_x, b_y) <span class="keyword">in</span> enumerate(loader):  <span class="comment"># for each training step</span></span><br><span class="line">            <span class="keyword">for</span> net, opt, l_his <span class="keyword">in</span> zip(nets, optimizers, losses_his):</span><br><span class="line">                output = net(b_x)  <span class="comment"># get output for every net</span></span><br><span class="line">                loss = loss_func(output, b_y)  <span class="comment"># compute loss for every net</span></span><br><span class="line">                opt.zero_grad()  <span class="comment"># clear gradients for next train</span></span><br><span class="line">                loss.backward()  <span class="comment"># backpropagation, compute gradients</span></span><br><span class="line">                opt.step()  <span class="comment"># apply gradients</span></span><br><span class="line">                l_his.append(loss.data.numpy())  <span class="comment"># loss recoder</span></span><br><span class="line">​</span><br><span class="line">    labels = [<span class="string">'SGD'</span>, <span class="string">'Momentum'</span>, <span class="string">'RMSprop'</span>, <span class="string">'Adam'</span>]</span><br><span class="line">    <span class="keyword">for</span> i, l_his <span class="keyword">in</span> enumerate(losses_his):</span><br><span class="line">        plt.plot(l_his, label=labels[i])</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Steps'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">    plt.ylim((<span class="number">0</span>, <span class="number">0.2</span>))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/深度学习/pytorch基础教程/4.png" height="281" width="386"></p>
<p><code>SGD</code>是最普通的优化器，也可以说没有加速效果；而<code>Momentum</code>是<code>SGD</code>的改良版，它加入了动量原则；后面的<code>RMSprop</code>又是<code>Momentum</code>的升级版；而<code>Adam</code>又是<code>RMSprop</code>的升级版。</p>
<h3 id="Dropout缓解过拟合"><a href="#Dropout缓解过拟合" class="headerlink" title="Dropout缓解过拟合"></a>Dropout缓解过拟合</h3><p>&emsp;&emsp;随机生成一些数据，用来模拟真实情况，数据少才能凸显过拟合问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">N_SAMPLES = <span class="number">20</span></span><br><span class="line">N_HIDDEN = <span class="number">300</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># training data</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(<span class="number">-1</span>, <span class="number">1</span>, N_SAMPLES), <span class="number">1</span>)</span><br><span class="line">y = x + <span class="number">0.3</span> * torch.normal(torch.zeros(N_SAMPLES, <span class="number">1</span>), torch.ones(N_SAMPLES, <span class="number">1</span>))</span><br><span class="line">​</span><br><span class="line"><span class="comment"># test data</span></span><br><span class="line">test_x = torch.unsqueeze(torch.linspace(<span class="number">-1</span>, <span class="number">1</span>, N_SAMPLES), <span class="number">1</span>)</span><br><span class="line">test_y = test_x + <span class="number">0.3</span> * torch.normal(torch.zeros(N_SAMPLES, <span class="number">1</span>), torch.ones(N_SAMPLES, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;我们在这里搭建两个神经网络，一个没有<code>dropout</code>，一个有<code>dropout</code>。没有<code>dropout</code>的容易出现过拟合，那我们就命名为<code>net_overfitting</code>；另一个就是<code>net_dropped</code>，<code>torch.nn.Dropout(0.5)</code>中的<code>0.5</code>指的是随机丢弃<code>50%</code>的神经元：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">net_overfitting = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(<span class="number">1</span>, N_HIDDEN),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(N_HIDDEN, N_HIDDEN),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(N_HIDDEN, <span class="number">1</span>),</span><br><span class="line">)</span><br><span class="line">​</span><br><span class="line">net_dropped = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(<span class="number">1</span>, N_HIDDEN),</span><br><span class="line">    torch.nn.Dropout(<span class="number">0.5</span>),  <span class="comment"># drop 50% of the neuron</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(N_HIDDEN, N_HIDDEN),</span><br><span class="line">    torch.nn.Dropout(<span class="number">0.5</span>),  <span class="comment"># drop 50% of the neuron</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(N_HIDDEN, <span class="number">1</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在训练的时候，将这两个神经网络分开训练，训练的环境都一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">optimizer_ofit = torch.optim.Adam(net_overfitting.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">optimizer_drop = torch.optim.Adam(net_dropped.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">loss_func = torch.nn.MSELoss()</span><br><span class="line">​</span><br><span class="line">plt.ion()  <span class="comment"># something about plotting</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    pred_ofit = net_overfitting(x)</span><br><span class="line">    pred_drop = net_dropped(x)</span><br><span class="line">    loss_ofit = loss_func(pred_ofit, y)</span><br><span class="line">    loss_drop = loss_func(pred_drop, y)</span><br><span class="line">​</span><br><span class="line">    optimizer_ofit.zero_grad()</span><br><span class="line">    optimizer_drop.zero_grad()</span><br><span class="line">    loss_ofit.backward()</span><br><span class="line">    loss_drop.backward()</span><br><span class="line">    optimizer_ofit.step()</span><br><span class="line">    optimizer_drop.step()</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 将神经网络转换成测试形式，画好图之后改回训练形式。因为drop网络在train的时候和test的时候参数不一样</span></span><br><span class="line">        net_overfitting.eval()</span><br><span class="line">        net_dropped.eval()</span><br><span class="line">​</span><br><span class="line">        <span class="comment"># plotting</span></span><br><span class="line">        plt.cla()</span><br><span class="line">        test_pred_ofit = net_overfitting(test_x)</span><br><span class="line">        test_pred_drop = net_dropped(test_x)</span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy(), c=<span class="string">'magenta'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.3</span>, label=<span class="string">'train'</span>)</span><br><span class="line">        plt.scatter(test_x.data.numpy(), test_y.data.numpy(), c=<span class="string">'cyan'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.3</span>, label=<span class="string">'test'</span>)</span><br><span class="line">        plt.plot(test_x.data.numpy(), test_pred_ofit.data.numpy(), <span class="string">'r-'</span>, lw=<span class="number">3</span>, label=<span class="string">'overfitting'</span>)</span><br><span class="line">        plt.plot(test_x.data.numpy(), test_pred_drop.data.numpy(), <span class="string">'b--'</span>, lw=<span class="number">3</span>, label=<span class="string">'dropout(50%)'</span>)</span><br><span class="line">        plt.text(<span class="number">0</span>, <span class="number">-1.2</span>, <span class="string">'overfitting loss=%.4f'</span> % loss_func(test_pred_ofit, test_y).data.numpy(),</span><br><span class="line">                 fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'red'</span>&#125;)</span><br><span class="line">        plt.text(<span class="number">0</span>, <span class="number">-1.5</span>, <span class="string">'dropout loss=%.4f'</span> % loss_func(test_pred_drop, test_y).data.numpy(),</span><br><span class="line">                 fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'blue'</span>&#125;)</span><br><span class="line">        plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">        plt.ylim((<span class="number">-2.5</span>, <span class="number">2.5</span>))</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line">​</span><br><span class="line">        <span class="comment"># change back to train mode</span></span><br><span class="line">        net_overfitting.train()</span><br><span class="line">        net_dropped.train()</span><br><span class="line">​</span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/01/14/深度学习/pytorch基础教程/5.png" height="264" width="390"></p>
<h3 id="GPU加速运算"><a href="#GPU加速运算" class="headerlink" title="GPU加速运算"></a>GPU加速运算</h3><p>&emsp;&emsp;代码需要修改的地方包括将数据的形式变成<code>GPU</code>能读的形式，将<code>CNN</code>也变成<code>GPU</code>能读的形式，做法就是在后面加上<code>.cuda()</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">​</span><br><span class="line">EPOCH = <span class="number">1</span></span><br><span class="line">BATCH_SIZE = <span class="number">50</span></span><br><span class="line">LR = <span class="number">0.001</span></span><br><span class="line">DOWNLOAD_MNIST = <span class="keyword">False</span></span><br><span class="line">​</span><br><span class="line">train_data = torchvision.datasets.MNIST(root=<span class="string">'./mnist/'</span>, train=<span class="keyword">True</span>, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST, )</span><br><span class="line">train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line">test_data = torchvision.datasets.MNIST(root=<span class="string">'./mnist/'</span>, train=<span class="keyword">False</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Change in here</span></span><br><span class="line">test_x = torch.unsqueeze(test_data.test_data, dim=<span class="number">1</span>).type(torch.FloatTensor)[:<span class="number">2000</span>].cuda() / <span class="number">255.</span>  <span class="comment"># Tensor on GPU</span></span><br><span class="line">test_y = test_data.test_labels[:<span class="number">2000</span>].cuda()</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>, ),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.out = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        output = self.out(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">​</span><br><span class="line">cnn = CNN()</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Change in here</span></span><br><span class="line">cnn.cuda()  <span class="comment"># Moves all model parameters and buffers to the GPU</span></span><br><span class="line">​</span><br><span class="line">optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)</span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        <span class="comment"># Change in here</span></span><br><span class="line">        b_x = x.cuda()  <span class="comment"># Tensor on GPU</span></span><br><span class="line">        b_y = y.cuda()  <span class="comment"># Tensor on GPU</span></span><br><span class="line">​</span><br><span class="line">        output = cnn(b_x)</span><br><span class="line">        loss = loss_func(output, b_y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            test_output = cnn(test_x)</span><br><span class="line">​</span><br><span class="line">            <span class="comment"># Change in here</span></span><br><span class="line">            pred_y = torch.max(test_output, <span class="number">1</span>)[<span class="number">1</span>].cuda().data.squeeze()  <span class="comment"># move the computation in GPU</span></span><br><span class="line">            accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(<span class="number">0</span>)</span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">'| train loss: %.4f'</span> % loss.data.cpu().numpy(), <span class="string">'| test accuracy: %.2f'</span> % accuracy)</span><br><span class="line">​</span><br><span class="line">test_output = cnn(test_x[:<span class="number">10</span>])</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Change in here</span></span><br><span class="line">pred_y = torch.max(test_output, <span class="number">1</span>)[<span class="number">1</span>].cuda().data.squeeze()  <span class="comment"># move the computation in GPU</span></span><br><span class="line">​</span><br><span class="line">print(pred_y, <span class="string">'prediction number'</span>)</span><br><span class="line">print(test_y[:<span class="number">10</span>], <span class="string">'real number'</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;如果有些计算还是需要在<code>CPU</code>上进行(比如<code>matplotlib</code>的可视化)，只要将这些计算或者数据转移至<code>CPU</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpu_data = gpu_data.cpu()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<strong>补充说明</strong>：<br>&emsp;&emsp;1. <code>GPU</code>训练的模型文件在使用<code>CPU</code>加载后会出错，而<code>CPU</code>训练的模型文件可以被<code>GPU</code>加载。<br>&emsp;&emsp;2. 数据和模型的所在位置要一致，要么都在<code>GPU</code>，要么都在<code>CPU</code>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/13/深度学习/pytorch函数总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/13/深度学习/pytorch函数总结/" itemprop="url">pytorch函数总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-13T20:05:19+08:00">
                2019-01-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="torch-ones"><a href="#torch-ones" class="headerlink" title="torch.ones"></a>torch.ones</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones(*sizes, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>sizes(int...)</code>：整数序列，定义了输出形状。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回一个全为<code>1</code>的张量，形状由可变参数<code>sizes</code>定义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"> <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span></span><br><span class="line"> <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.ones(<span class="number">5</span>)</span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-zeros"><a href="#torch-zeros" class="headerlink" title="torch.zeros"></a>torch.zeros</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.zeros(*sizes, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>sizes(int...)</code>：整数序列，定义了输出形状。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回一个全为标量<code>0</code>的张量，形状由可变参数<code>sizes</code>定义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.zeros(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"> <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"> <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.zeros(<span class="number">5</span>)</span><br><span class="line"> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-arange"><a href="#torch-arange" class="headerlink" title="torch.arange"></a>torch.arange</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(start, end, step=1, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>start(float)</code>：序列的起始点。</li>
<li><code>end(float)</code>：序列的终止点。</li>
<li><code>step(float)</code>：相邻点的间隔大小。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回一个<code>1</code>维张量，长度为<code>floor((end - start)/step)</code>，包含从<code>start</code>到<code>end</code>，以<code>step</code>为步长的一组序列值(默认步长为<code>1</code>)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.arange(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">3</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.arange(<span class="number">1</span>, <span class="number">2.5</span>, <span class="number">0.5</span>)</span><br><span class="line"> <span class="number">1.0000</span></span><br><span class="line"> <span class="number">1.5000</span></span><br><span class="line"> <span class="number">2.0000</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-normal"><a href="#torch-normal" class="headerlink" title="torch.normal"></a>torch.normal</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means, std, out=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>means(Tensor)</code>：均值。</li>
<li><code>std(Tensor)</code>：标准差。</li>
<li><code>out(Tensor)</code>：可选的输出张量。</li>
</ul>
<p>返回一个张量，包含从给定参数<code>means</code>、<code>std</code>的离散正态分布中抽取随机数。均值<code>means</code>是一个张量，包含每个输出元素相关的正态分布的均值；<code>std</code>是一个张量，包含每个输出元素相关的正态分布的标准差。均值和标准差的形状不须匹配，但每个张量的元素个数须相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means=torch.arange(<span class="number">1</span>, <span class="number">11</span>), std=torch.arange(<span class="number">1</span>, <span class="number">0</span>, <span class="number">-0.1</span>))</span><br><span class="line"> <span class="number">1.5104</span></span><br><span class="line"> <span class="number">1.6955</span></span><br><span class="line"> <span class="number">2.4895</span></span><br><span class="line"> <span class="number">4.9185</span></span><br><span class="line"> <span class="number">4.9895</span></span><br><span class="line"> <span class="number">6.9155</span></span><br><span class="line"> <span class="number">7.3683</span></span><br><span class="line"> <span class="number">8.1836</span></span><br><span class="line"> <span class="number">8.7164</span></span><br><span class="line"> <span class="number">9.8916</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<p>第二个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(mean=<span class="number">0.0</span>, std, out=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>means(Tensor, optional)</code>：所有分布均值。</li>
<li><code>std(Tensor)</code>：每个元素的标准差。</li>
<li><code>out(Tensor)</code>：可选的输出张量。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.normal(mean=<span class="number">0.5</span>, std=torch.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">  <span class="number">0.5723</span></span><br><span class="line">  <span class="number">0.0871</span></span><br><span class="line"> <span class="number">-0.3783</span></span><br><span class="line"> <span class="number">-2.5689</span></span><br><span class="line"> <span class="number">10.7893</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>第三个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means, std=<span class="number">1.0</span>, out=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>means(Tensor)</code>：每个元素的均值。</li>
<li><code>std(float, optional)</code>：所有分布的标准差。</li>
<li><code>out(Tensor)</code>：可选的输出张量。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.normal(means=torch.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line"> <span class="number">1.1681</span></span><br><span class="line"> <span class="number">2.8884</span></span><br><span class="line"> <span class="number">3.7718</span></span><br><span class="line"> <span class="number">2.5616</span></span><br><span class="line"> <span class="number">4.2500</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(inputs, dimension=0) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>inputs(sequence of Tensors)</code>：可以是任意相同<code>Tensor</code>类型的<code>python</code>序列。</li>
<li><code>dimension(int, optional)</code>：沿着此维连接张量序列。</li>
</ul>
<p>在给定维度上对输入的张量序列<code>seq</code>进行连接操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line"> <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span></span><br><span class="line"> <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">0</span>)</span><br><span class="line"> <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span></span><br><span class="line"> <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span></span><br><span class="line"> <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span></span><br><span class="line"> <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span></span><br><span class="line"> <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span></span><br><span class="line"> <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">6</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((x, x, x), <span class="number">1</span>)</span><br><span class="line"> <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span>  <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span>  <span class="number">0.5983</span> <span class="number">-0.0341</span>  <span class="number">2.4918</span></span><br><span class="line"> <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span>  <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span>  <span class="number">1.5981</span> <span class="number">-0.5265</span> <span class="number">-0.8735</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x9]</span><br></pre></td></tr></table></figure>
<h3 id="size"><a href="#size" class="headerlink" title="size"></a>size</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">size() -&gt; torch.Size</span><br></pre></td></tr></table></figure>
<p>返回<code>tensor</code>的大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.Tensor(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>).size()</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<h3 id="torch-randn"><a href="#torch-randn" class="headerlink" title="torch.randn"></a>torch.randn</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(*sizes, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>sizes(int...)</code>：整数序列，定义了输出形状。</li>
<li><code>out(Tensor, optinal)</code>：结果张量。</li>
</ul>
<p>返回一个张量，包含了从标准正态分布(均值为<code>0</code>，方差为<code>1</code>，即<code>高斯白噪声</code>)中抽取一组随机数，形状由可变参数<code>sizes</code>定义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">4</span>)</span><br><span class="line"><span class="number">-0.1145</span></span><br><span class="line"> <span class="number">0.0094</span></span><br><span class="line"><span class="number">-1.1717</span></span><br><span class="line"> <span class="number">0.9846</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"> <span class="number">1.4339</span>  <span class="number">0.3351</span> <span class="number">-1.0999</span></span><br><span class="line"> <span class="number">1.5458</span> <span class="number">-0.9643</span> <span class="number">-0.3558</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x3]</span><br></pre></td></tr></table></figure>
<h3 id="torch-max"><a href="#torch-max" class="headerlink" title="torch.max"></a>torch.max</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.max(input)</span><br></pre></td></tr></table></figure>
<p>返回输入张量所有元素的最大值，参数<code>input</code>(<code>Tensor</code>)是输入张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"><span class="number">0.4729</span> <span class="number">-0.2266</span> <span class="number">-0.2085</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">1</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.max(a)</span><br><span class="line"><span class="number">0.4729</span></span><br></pre></td></tr></table></figure>
<p>第二个函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.max(input, dim, max=None, max_indices=None) -&gt; (Tensor, LongTensor)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input(Tensor)</code>：输入张量。</li>
<li><code>dim(int)</code>：指定的维度。</li>
<li><code>max(Tensor, optional)</code>：结果张量，包含给定维度上的最大值。</li>
<li><code>max_indices(LongTensor, optional)</code>：结果张量，包含给定维度上每个最大值的位置索引。</li>
</ul>
<p>返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引。输出形状中，将<code>dim</code>维设定为<code>1</code>，其它与输入形状保持一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; a = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; a</span><br><span class="line"><span class="number">0.0692</span>  <span class="number">0.3142</span>  <span class="number">1.2513</span> <span class="number">-0.5428</span></span><br><span class="line"><span class="number">0.9288</span>  <span class="number">0.8552</span> <span class="number">-0.2073</span>  <span class="number">0.6409</span></span><br><span class="line"><span class="number">1.0695</span> <span class="number">-0.0101</span> <span class="number">-2.4507</span> <span class="number">-1.2230</span></span><br><span class="line"><span class="number">0.7426</span> <span class="number">-0.7666</span>  <span class="number">0.4862</span> <span class="number">-0.6628</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>x4]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.max(a, <span class="number">1</span>)</span><br><span class="line">(<span class="number">1.2513</span> <span class="number">0.9288</span> <span class="number">1.0695</span> <span class="number">0.7426</span> [torch.FloatTensor of size <span class="number">4</span>x1],</span><br><span class="line"> <span class="number">2</span>      <span class="number">0</span>      <span class="number">0</span>      <span class="number">0</span>      [torch.LongTensor of size <span class="number">4</span>x1])</span><br></pre></td></tr></table></figure>
<p>第三个函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.max(input, other, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input(Tensor)</code>：输入张量。</li>
<li><code>other(Tensor)</code>：输出张量。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引，即<code>out_i = max(input_i, other_i)</code>。输出形状中，将<code>dim</code>维设定为<code>1</code>，其它与输入形状保持一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"> <span class="number">1.3869</span></span><br><span class="line"> <span class="number">0.3912</span></span><br><span class="line"><span class="number">-0.8634</span></span><br><span class="line"><span class="number">-0.5468</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.randn(<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line"> <span class="number">1.0067</span></span><br><span class="line"><span class="number">-0.8010</span></span><br><span class="line"> <span class="number">0.6258</span></span><br><span class="line"> <span class="number">0.3627</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.max(a, b)</span><br><span class="line"> <span class="number">1.3869</span></span><br><span class="line"> <span class="number">0.3912</span></span><br><span class="line"> <span class="number">0.6258</span></span><br><span class="line"> <span class="number">0.3627</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-squeeze"><a href="#torch-squeeze" class="headerlink" title="torch.squeeze"></a>torch.squeeze</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(input, dim=<span class="keyword">None</span>, out=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input(Tensor)</code>：输入张量。</li>
<li><code>dim(int, optional)</code>：如果给定，则<code>input</code>只会在给定维度挤压。</li>
<li><code>out(Tensor, optional)</code>：输出张量。</li>
</ul>
<p>将输入张量形状中的<code>1</code>去除并返回。如果输入shape是<code>A * 1 * B * 1 * C * 1 * D</code>，那么输出shape就是<code>A * B * C * D</code>。当给定<code>dim</code>时，那么挤压操作只在给定维度上。例如，输入形状为<code>A * 1 * B</code>，<code>squeeze(input, 0)</code>将会保持张量不变，只有用<code>squeeze(input, 1)</code>，形状会变成<code>A * B</code>。注意，返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">(<span class="number">2L</span>, <span class="number">1L</span>, <span class="number">2L</span>, <span class="number">1L</span>, <span class="number">2L</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">(<span class="number">2L</span>, <span class="number">2L</span>, <span class="number">2L</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">(<span class="number">2L</span>, <span class="number">1L</span>, <span class="number">2L</span>, <span class="number">1L</span>, <span class="number">2L</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.squeeze(x, <span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">(<span class="number">2L</span>, <span class="number">2L</span>, <span class="number">1L</span>, <span class="number">2L</span>)</span><br></pre></td></tr></table></figure>
<h3 id="torch-sum"><a href="#torch-sum" class="headerlink" title="torch.sum"></a>torch.sum</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sum(input) -&gt; float</span><br></pre></td></tr></table></figure>
<p>返回输入张量<code>input</code>所有元素的和。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"> <span class="number">0.6170</span>  <span class="number">0.3546</span>  <span class="number">0.0253</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">1</span>x3]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.sum(a)</span><br><span class="line"><span class="number">0.9969287421554327</span></span><br></pre></td></tr></table></figure>
<p>第二个函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sum(input, dim, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input(Tensor)</code>：输入张量。</li>
<li><code>dim(int)</code>：缩减的维度。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回输入张量给定维度上的数据和。输出形状与输入相同，除了给定维度上为<code>1</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"><span class="number">-0.4640</span>  <span class="number">0.0609</span>  <span class="number">0.1122</span>  <span class="number">0.4784</span></span><br><span class="line"><span class="number">-1.3063</span>  <span class="number">1.6443</span>  <span class="number">0.4714</span> <span class="number">-0.7396</span></span><br><span class="line"><span class="number">-1.3561</span> <span class="number">-0.1959</span>  <span class="number">1.0609</span> <span class="number">-1.9855</span></span><br><span class="line"> <span class="number">2.6833</span>  <span class="number">0.5746</span> <span class="number">-0.5709</span> <span class="number">-0.4430</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>x4]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.sum(a, <span class="number">1</span>)</span><br><span class="line"> <span class="number">0.1874</span></span><br><span class="line"> <span class="number">0.0698</span></span><br><span class="line"><span class="number">-2.4767</span></span><br><span class="line"> <span class="number">2.2440</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>x1]</span><br></pre></td></tr></table></figure>
<h3 id="torch-linspace"><a href="#torch-linspace" class="headerlink" title="torch.linspace"></a>torch.linspace</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.linspace(start, end, steps=100, out=None) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><code>start(float)</code>：序列的起始点。</li>
<li><code>end(float)</code>：序列的最终值。</li>
<li><code>steps(int)</code>：在<code>start</code>和<code>end</code>间生成的样本数。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回一个<code>1</code>维张量，包含在区间<code>start</code>和<code>end</code>上均匀间隔的<code>steps</code>个点，输出<code>1</code>维张量的长度为<code>steps</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.linspace(<span class="number">3</span>, <span class="number">10</span>, steps=<span class="number">5</span>)</span><br><span class="line">  <span class="number">3.0000</span></span><br><span class="line">  <span class="number">4.7500</span></span><br><span class="line">  <span class="number">6.5000</span></span><br><span class="line">  <span class="number">8.2500</span></span><br><span class="line"> <span class="number">10.0000</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.linspace(<span class="number">-10</span>, <span class="number">10</span>, steps=<span class="number">5</span>)</span><br><span class="line"><span class="number">-10</span></span><br><span class="line"> <span class="number">-5</span></span><br><span class="line">  <span class="number">0</span></span><br><span class="line">  <span class="number">5</span></span><br><span class="line"> <span class="number">10</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.linspace(start=<span class="number">-10</span>, end=<span class="number">10</span>, steps=<span class="number">5</span>)</span><br><span class="line"><span class="number">-10</span></span><br><span class="line"> <span class="number">-5</span></span><br><span class="line">  <span class="number">0</span></span><br><span class="line">  <span class="number">5</span></span><br><span class="line"> <span class="number">10</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed"></a>torch.manual_seed</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(seed)</span><br></pre></td></tr></table></figure>
<p>设定生成随机数的种子，并返回一个<code>torch._C.Generator</code>对象，参数<code>seed(int or long)</code>是种子。</p>
<h3 id="torch-unsqueeze"><a href="#torch-unsqueeze" class="headerlink" title="torch.unsqueeze"></a>torch.unsqueeze</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(input, dim, out=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tensor(Tensor)</code>：输入张量。</li>
<li><code>dim(int)</code>：插入维度的索引。</li>
<li><code>out(Tensor, optional)</code>：结果张量。</li>
</ul>
<p>返回一个新的张量，对输入的制定位置插入维度<code>1</code>。返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。如果<code>dim</code>为负，则将会被转化<code>dim + input.dim() + 1</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="number">0</span>)</span><br><span class="line"> <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">1</span>x4]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="number">1</span>)</span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">3</span></span><br><span class="line"> <span class="number">4</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">4</span>x1]</span><br></pre></td></tr></table></figure>
<h3 id="view"><a href="#view" class="headerlink" title="view"></a>view</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">view(*args) -&gt; Tensor</span><br></pre></td></tr></table></figure>
<p>返回一个有相同数据但大小不同的<code>tensor</code>，返回的<code>tensor</code>必须有与原<code>tensor</code>相同的数据和相同数目的元素，但可以有不同的大小。一个<code>tensor</code>必须是连续的(<code>contiguous</code>)才能被查看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size()</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.view(<span class="number">16</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.size()</span><br><span class="line">torch.Size([<span class="number">16</span>])</span><br><span class="line"><span class="comment"># the size -1 is inferred from other dimensions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.view(<span class="number">-1</span>, <span class="number">8</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.size()</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure>
<h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.conv1d(</span><br><span class="line">    input, weight, bias=<span class="keyword">None</span>, stride=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input</code>：输入张量的形状(<code>minibatch, in_channels, iW</code>)。</li>
<li><code>weight</code>：过滤器的形状(<code>out_channels, in_channels, kW</code>)。</li>
<li><code>bias</code>：可选偏置的形状(<code>out_channels</code>)。</li>
<li><code>stride</code>：卷积核的步长。</li>
</ul>
<p>对几个输入平面组成的输入信号应用<code>1D</code>卷积。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>filters = autograd.Variable(torch.randn(<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>inputs = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>F.conv1d(inputs, filters)</span><br></pre></td></tr></table></figure>
<p>第二个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.conv2d(</span><br><span class="line">    input, weight, bias=<span class="keyword">None</span>, stride=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input</code>：输入张量(<code>minibatch, in_channels, iH, iW</code>)。</li>
<li><code>weight</code>：过滤器张量(<code>out_channels, in_channels/groups, kH, kW</code>)。</li>
<li><code>bias</code>：可选偏置张量(<code>out_channels</code>)。</li>
<li><code>stride</code>：卷积核的步长，可以是单个数字或一个元组(<code>sh, sw</code>)。</li>
<li><code>padding</code>：输入边缘零填充，可以是单个数字或元组。</li>
<li><code>groups</code>：将输入分成组，<code>in_channels</code>应该被组数除尽。</li>
</ul>
<p>对几个输入平面组成的输入信号应用<code>2D</code>卷积。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With square kernels and equal stride</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>filters = autograd.Variable(torch.randn(<span class="number">8</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>inputs = autograd.Variable(torch.randn(<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>F.conv2d(inputs, filters, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>第三个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.conv3d(</span><br><span class="line">    input, weight, bias=<span class="keyword">None</span>, stride=<span class="number">1</span>,</span><br><span class="line">    padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>input</code>：输入张量的形状(<code>minibatch, in_channels, iT, iH, iW</code>)。</li>
<li><code>weight</code>：过滤器张量的形状(<code>out_channels, in_channels, kT, kH, kW</code>)。</li>
<li><code>bias</code>：可选偏置张量的形状(<code>out_channels</code>)。</li>
<li><code>stride</code>：卷积核的步长，可以是单个数字或一个元组(<code>sh, sw</code>)。</li>
<li><code>padding</code>：输入上隐含零填充，可以是单个数字或元组。</li>
</ul>
<p>对几个输入平面组成的输入信号应用<code>3D</code>卷积。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>filters = autograd.Variable(torch.randn(<span class="number">33</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>inputs = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">10</span>, <span class="number">20</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>F.conv3d(inputs, filters)</span><br></pre></td></tr></table></figure>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BatchNorm1d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>num_features</code>：来自期望输入的特征数，该期望输入的大小为(<code>batch_size, num_features [, width]</code>)。</li>
<li><code>eps</code>：为保证数值稳定性(分母不能趋近或取<code>0</code>)，给分母加上的值。</li>
<li><code>momentum</code>：动态均值和动态方差所使用的动量。</li>
<li><code>affine</code>：一个布尔值，当设为<code>True</code>时，给该层添加可学习的仿射变换参数。</li>
</ul>
<p>对小批量(<code>mini-batch</code>)的<code>2d</code>或<code>3d</code>输入进行批标准化(<code>Batch Normalization</code>)。在每一个小批量(<code>mini-batch</code>)数据中，计算输入各个维度的均值和标准差。</p>
<p>&emsp;&emsp;在训练时，该层计算每次输入的均值与方差，并进行移动平均，移动平均默认的动量值为<code>0.1</code>；在验证时，训练求得的均值和方差将用于标准化验证数据。<br>&emsp;&emsp;对于<code>Shape</code>，输入(<code>N, C</code>)或者(<code>N, C, L</code>)，输出(<code>N, C</code>)或者(<code>N, C, L</code>)，即输入输出都相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm1d(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm1d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;第二个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BatchNorm2d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>num_features</code>：来自期望输入的特征数，该期望输入的大小为(<code>batch_size, num_features, height, width</code>)。</li>
<li><code>eps</code>：为保证数值稳定性(分母不能趋近或取<code>0</code>)，给分母加上的值。</li>
<li><code>momentum</code>：动态均值和动态方差所使用的动量。</li>
<li><code>affine</code>：一个布尔值，当设为<code>True</code>时，给该层添加可学习的仿射变换参数。</li>
</ul>
<p>对小批量的<code>3d</code>数据组成的<code>4d</code>输入进行批标准化。在每一个小批量数据中，计算输入各个维度的均值和标准差。<br>&emsp;&emsp;在训练时，该层计算每次输入的均值与方差，并进行移动平均，移动平均默认的动量值为<code>0.1</code>；在验证时，训练求得的均值和方差将用于标准化验证数据。<br>&emsp;&emsp;对于<code>Shape</code>，输入(<code>N, C, H, W</code>)，输出(<code>N, C, H, W</code>)，即输入输出相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;第三个函数原型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BatchNorm3d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>num_features</code>：来自期望输入的特征数，该期望输入的大小为(<code>batch_size, num_features, depth, height, width</code>)。</li>
<li><code>eps</code>：为保证数值稳定性(分母不能趋近或取<code>0</code>)，给分母加上的值。</li>
<li><code>momentum</code>：动态均值和动态方差所使用的动量。</li>
<li><code>affine</code>：一个布尔值，当设为<code>True</code>时，给该层添加可学习的仿射变换参数。</li>
</ul>
<p>对小批量的<code>4d</code>数据组成的<code>5d</code>输入进行批标准化操作。在每一个小批量数据中，计算输入各个维度的均值和标准差。<br>&emsp;&emsp;在训练时，该层计算每次输入的均值与方差，并进行移动平均，移动平均默认的动量值为<code>0.1</code>；在验证时，训练求得的均值和方差将用于标准化验证数据。<br>&emsp;&emsp;对于<code>Shape</code>，输入(<code>N, C, D, H, W</code>)，输出(<code>N, C, D, H, W</code>)，即输入输出相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm3d(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># Without Learnable Parameters</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.BatchNorm3d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>, <span class="number">10</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<h3 id="池化层函数"><a href="#池化层函数" class="headerlink" title="池化层函数"></a>池化层函数</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool1d(</span><br><span class="line">    kernel_size, stride=<span class="keyword">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>,</span><br><span class="line">    return_indices=<span class="keyword">False</span>, ceil_mode=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>kernel_size(int or tuple)</code>：<code>max pooling</code>的窗口大小。</li>
<li><code>stride(int or tuple, optional)</code>：<code>max pooling</code>的窗口移动的步长，默认值是<code>kernel_size</code>。</li>
<li><code>padding(int or tuple, optional)</code>：输入的每一条边补充<code>0</code>的层数。</li>
<li><code>dilation(int or tuple, optional)</code>：一个控制窗口中元素步幅的参数。</li>
<li><code>return_indices</code>：如果等于<code>True</code>，则会返回输出最大值的序号，对于上采样操作会有帮助。</li>
<li><code>ceil_mode</code>：如果等于<code>True</code>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作。</li>
</ul>
<p>对于输入信号的输入通道，提供<code>1</code>维最大池化(<code>max pooling</code>)操作。如果<code>padding</code>不是0，会在输入的每一边添加相应数目<code>0</code>；<code>dilation</code>用于控制内核点之间的距离。<br>&emsp;&emsp;对于<code>shape</code>，输入(<code>N, C_in, L_in</code>)，输出(<code>N, C_out, L_out</code>)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pool of size = 3, stride = 2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool1d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;第二个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool2d(</span><br><span class="line">    kernel_size, stride=<span class="keyword">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>,</span><br><span class="line">    return_indices=<span class="keyword">False</span>, ceil_mode=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>对于输入信号的输入通道，提供<code>2</code>维最大池化(<code>max pooling</code>)操作。如果<code>padding</code>不是<code>0</code>，会在输入的每一边添加相应数目<code>0</code>；<code>dilation</code>用于控制内核点之间的距离。<br>&emsp;&emsp;参数<code>kernel_size</code>、<code>stride</code>、<code>padding</code>和<code>dilation</code>数据类型：可以是一个<code>int</code>类型的数据，此时卷积<code>height</code>和<code>width</code>值相同；也可以是一个<code>tuple</code>数组(包含两个<code>int</code>类型的数据)，第一个<code>int</code>数据表示<code>height</code>的数值，第二个<code>int</code>类型的数据表示<code>width</code>的数值。</p>
<ul>
<li><code>kernel_size(int or tuple)</code>：<code>max pooling</code>的窗口大小。</li>
<li><code>stride(int or tuple, optional)</code>：<code>max pooling</code>的窗口移动的步长，默认值是<code>kernel_size</code>。</li>
<li><code>padding(int or tuple, optional)</code>：输入的每一条边补充<code>0</code>的层数。</li>
<li><code>dilation(int or tuple, optional)</code>：一个控制窗口中元素步幅的参数。</li>
<li><code>return_indices</code>：如果等于<code>True</code>，会返回输出最大值的序号，对于上采样操作会有帮助。</li>
<li><code>ceil_mode</code>：如果等于<code>True</code>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d((<span class="number">3</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">32</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;第三个函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool3d(</span><br><span class="line">    kernel_size, stride=<span class="keyword">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>,</span><br><span class="line">    return_indices=<span class="keyword">False</span>, ceil_mode=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>kernel_size(int or tuple)</code>：<code>max pooling</code>的窗口大小。</li>
<li><code>stride(int or tuple, optional)</code>：<code>max pooling</code>的窗口移动的步长，默认值是<code>kernel_size</code>。</li>
<li><code>padding(int or tuple, optional)</code>：输入的每一条边补充<code>0</code>的层数。</li>
<li><code>dilation(int or tuple, optional)</code>：一个控制窗口中元素步幅的参数。</li>
<li><code>return_indices</code>：如果等于<code>True</code>，会返回输出最大值的序号，对于上采样操作会有帮助。</li>
<li><code>ceil_mode</code>：如果等于<code>True</code>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作。</li>
</ul>
<p>对于输入信号的输入通道，提供<code>3</code>维最大池化(<code>max pooling</code>)操作。如果<code>padding</code>不是<code>0</code>，会在输入的每一边添加相应数目<code>0</code>；<code>dilation</code>用于控制内核点之间的距离。<br>&emsp;&emsp;参数<code>kernel_size</code>、<code>stride</code>、<code>padding</code>、<code>dilation</code>数据类型：可以是<code>int</code>类型的数据，此时卷积<code>height</code>和<code>width</code>值相同；也可以是一个<code>tuple</code>数组(包含两个<code>int</code>类型的数据)，第一个<code>int</code>数据表示<code>height</code>的数值，第二个<code>int</code>类型的数据表示<code>width</code>的数值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pool of square window of size=3, stride=2</span></span><br><span class="line">&gt;&gt;&gt;m = nn.MaxPool3d(<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># pool of non-square window</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = nn.MaxPool3d((<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>,<span class="number">44</span>, <span class="number">31</span>))  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = m(input)</span><br></pre></td></tr></table></figure>
<h3 id="torchvision-transforms-CenterCrop-size"><a href="#torchvision-transforms-CenterCrop-size" class="headerlink" title="torchvision.transforms.CenterCrop(size)"></a>torchvision.transforms.CenterCrop(size)</h3><p>&emsp;&emsp;将<code>PIL.Image</code>根据给定的<code>size</code>进行中心切割。<code>size</code>可以是<code>tuple(target_height, target_width)</code>，也可以是一个<code>Integer</code>，在这种情况下，切出来的图片是正方形。</p>
<h3 id="ConvTranspose2d"><a href="#ConvTranspose2d" class="headerlink" title="ConvTranspose2d"></a>ConvTranspose2d</h3><p>&emsp;&emsp;二维反卷积层的函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.ConvTranspose2d(</span><br><span class="line">    in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>,</span><br><span class="line">    output_padding=<span class="number">0</span>, groups=<span class="number">1</span>, bias=<span class="keyword">True</span>, dilation=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>in_channels</code>：输入信号的通道数。</li>
<li><code>out_channels</code>：卷积后输出结果的通道数。</li>
<li><code>kernel_size</code>：卷积核的形状。</li>
<li><code>stride</code>：卷积每次移动的步长。</li>
<li><code>padding</code>：处理边界时填充<code>0</code>的数量，默认为<code>0</code>(不填充)。</li>
<li><code>output_padding</code>：输出时在每一个维度首尾补<code>0</code>的数量(卷积时，形状不同的输入数据对相同的核函数可以产生形状相同的结果；反卷积时，同一个输入对相同的核函数可以产生多个形状不同的输出，而输出结果只能有一个，因此必须对输出形状进行约束)。</li>
<li><code>bias</code>：为<code>True</code>时表示添加偏置。</li>
<li><code>dilation</code>：采样间隔数量，大于<code>1</code>时为非致密采样。</li>
<li><code>groups</code>：控制输入和输出之间的连接，当<code>group</code>为<code>1</code>时，输出是所有输入的卷积；当<code>group</code>为<code>2</code>时，相当于有并排的两个卷积层，每个卷积层只在对应的输入通道和输出通道之间计算，并且输出时会将所有输出通道简单的首尾相接作为结果输出。</li>
</ul>
<p>&emsp;&emsp;<code>in_channels</code>和<code>out_channels</code>都应当可以被<code>groups</code>整除。<code>kernel_size</code>、<code>stride</code>、<code>padding</code>和<code>output_padding</code>可以为:</p>
<ul>
<li>单个<code>int</code>值：宽和高均被设定为此值。</li>
<li>两个<code>int</code>组成的<code>tuple</code>：第一个<code>int</code>为高度，第二个<code>int</code>为宽度。</li>
</ul>
<p>&emsp;&emsp;输入和输出的<code>shape</code>如下：</p>
<ul>
<li>输入Input：(<code>N, Cin, Hin, Win</code>)。</li>
<li>输出Output：(<code>N, Cout, Hout, Wout</code>)，其中：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hout = (Hin - <span class="number">1</span>) * stride[<span class="number">0</span>] - <span class="number">2</span> * padding[<span class="number">0</span>] + kernel_size[<span class="number">0</span>] + output_padding[<span class="number">0</span>]</span><br><span class="line">Wout = (Win - <span class="number">1</span>) * stride[<span class="number">1</span>] - <span class="number">2</span> * padding[<span class="number">1</span>] + kernel_size[<span class="number">1</span>] + output_padding[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>&emsp;&emsp;对输入运用修正线性单元函数(<code>Relu(x) = max(0, x)</code>)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.ReLU(inplace=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>inplace</code>的默认设置为<code>False</code>，表示新创建一个对象对其修改；也可以设置为<code>True</code>，表示直接对这个对象进行修改。</p>
<h3 id="cuda-is-available"><a href="#cuda-is-available" class="headerlink" title="cuda.is_available"></a>cuda.is_available</h3><p>&emsp;&emsp;Check whether pytorch is using GPU:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">use_gpu = torch.cuda.is_available()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/13/软件与硬件问题/Java环境搭建/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/13/软件与硬件问题/Java环境搭建/" itemprop="url">Java环境搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-13T19:44:15+08:00">
                2019-01-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Java官方JDK"><a href="#Java官方JDK" class="headerlink" title="Java官方JDK"></a>Java官方JDK</h3><p>&emsp;&emsp;在<code>系统变量</code>中设置<code>3</code>项属性：<code>JAVA_HOME</code>、<code>PATH</code>、<code>CLASSPATH</code>。</p>
<ul>
<li><code>JAVA_HOME</code>的值是<code>D:\Program Files (x86)\Java\jdk1.8.0_91</code>，这个路径就是<code>JDK</code>安装的路径。</li>
<li><code>CLASSPATH</code>的值是<code>.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;</code>，记得前面有个<code>.</code>。</li>
<li>在<code>Path</code>后添加<code>%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;</code>。</li>
</ul>
<p>&emsp;&emsp;配置完成之后，打开<code>cmd</code>，然后输入<code>java -version</code>进行测试。</p>
<h3 id="OpenJDK"><a href="#OpenJDK" class="headerlink" title="OpenJDK"></a>OpenJDK</h3><p>&emsp;&emsp;从<code>http://jdk.java.net/10/</code>下载<code>openjdk</code>的<code>Windows</code>版本，然后解压至系统<code>C</code>盘。随后增加<code>JAVA_HOME</code>环境变量，其值为<code>C:\jdk-10.0.1</code>。然后在环境变量<code>path</code>中增加<code>%JAVA_HOME%\bin</code>，在终端输入<code>java -version</code>进行测试。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/13/软件与硬件问题/Python环境搭建/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/13/软件与硬件问题/Python环境搭建/" itemprop="url">Python环境搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-13T19:00:42+08:00">
                2019-01-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="pip安装和入门"><a href="#pip安装和入门" class="headerlink" title="pip安装和入门"></a>pip安装和入门</h3><p>&emsp;&emsp;对于<code>linux</code>系统，可以使用如下命令进行安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-pip</span><br></pre></td></tr></table></figure>
<p><code>pip</code>基本用法如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pip install Package  <span class="comment"># 安装包</span></span><br><span class="line">pip list --outdated  <span class="comment"># 检查哪些包需要更新</span></span><br><span class="line">pip install Package -U <span class="comment"># 升级包</span></span><br><span class="line">pip uninstall Package  <span class="comment"># 卸载包</span></span><br><span class="line">pip -V  <span class="comment"># 查看当前pip对应的python版本(“python -V”查看python版本)</span></span><br><span class="line">pip freeze &gt; requirements.txt  <span class="comment"># 生成requirements.txt文件</span></span><br><span class="line">pip install -r requirements.txt  <span class="comment"># 安装requirements.txt依赖</span></span><br></pre></td></tr></table></figure>
<h3 id="打开ipynb文件"><a href="#打开ipynb文件" class="headerlink" title="打开ipynb文件"></a>打开ipynb文件</h3><p>&emsp;&emsp;首先需要安装<code>ipython</code>和<code>jupyter</code>，使用如下命令(<code>Windows</code>系统需要去掉<code>sudo</code>)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install ipython --upgrade</span><br><span class="line">sudo pip install jupyter</span><br></pre></td></tr></table></figure>
<p>接下来需要在终端中输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>
<p>即可在浏览器中打开当前目录。可以通过切换目录来选择需要打开的<code>ipynb</code>文件。</p>
<hr>
<h3 id="TensorFlow的安装"><a href="#TensorFlow的安装" class="headerlink" title="TensorFlow的安装"></a>TensorFlow的安装</h3><h4 id="Windows版本"><a href="#Windows版本" class="headerlink" title="Windows版本"></a>Windows版本</h4><p>&emsp;&emsp;如果只是安装<code>cpu</code>版本，则使用如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure>
<p>如果需要安装<code>gpu</code>版本，首先确保有<code>NVIDIA</code>的显卡并安装好驱动，然后还要安装<code>CUDA</code>和<code>cuDNN</code>库。<br>&emsp;&emsp;首先去<code>TensorFlow</code>的官网查看支持的<code>CUDA</code>版本，然后去<code>https://developer.nvidia.com/cuda-downloads</code>下载对应的<code>CUDA</code>，并进行安装。<br>&emsp;&emsp;再去<code>https://developer.nvidia.com/rdp/cudnn-download#a-collapse705-91</code>下载<code>cuDNN</code>库，名称类似于<code>cudnn-9.1-windows10-x64-v7.1.zip</code>。下载完成并解压，里面有<code>3</code>个文件夹，需要复制到<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1</code>文件夹下覆盖。<br>&emsp;&emsp;最后安装<code>TensorFlow</code>的<code>gpu</code>版本(当时是<code>1.9.0</code>版本)，使用如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu==1.9.0</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;进入<code>Python</code>，对安装的<code>TensorFlow</code>进行测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">​</span><br><span class="line">hello = tf.constant(<span class="string">'hello, TensorFlow!'</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(hello))</span><br></pre></td></tr></table></figure>
<p>如果输出了<code>GPU</code>的信息，说明安装成功。</p>
<h4 id="Linux版本"><a href="#Linux版本" class="headerlink" title="Linux版本"></a>Linux版本</h4><p>&emsp;&emsp;首先查看所安装的<code>CUDA</code>版本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/version.txt</span><br></pre></td></tr></table></figure>
<p>然后查看安装的<code>cuDNN</code>版本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>假设<code>CUDA</code>版本是<code>8.0</code>，<code>cuDNN</code>版本是<code>6.0</code>，可以安装<code>TensorFlow</code>的<code>1.4.0</code>版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow==1.4.0</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="远程访问“Jupyter-Notebook”"><a href="#远程访问“Jupyter-Notebook”" class="headerlink" title="远程访问“Jupyter Notebook”"></a>远程访问“Jupyter Notebook”</h3><p>&emsp;&emsp;在远程服务器上启动<code>jupyter notebooks</code>服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --no-browser --port=8889</span><br></pre></td></tr></table></figure>
<p>在本地终端中启动<code>ssh</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -L localhost:8888:localhost:8889 username@serverIP</span><br></pre></td></tr></table></figure>
<p>其中<code>-N</code>告诉<code>ssh</code>没有命令要被远程执行，<code>-f</code>告诉<code>ssh</code>在后台执行，<code>-L</code>指定<code>port forwarding</code>的配置，远端端口是<code>8889</code>，本地的端口号的<code>8888</code>。注意<code>username@serverIP</code>替换成服务器的对应账号。最后打开浏览器，访问<code>http://localhost:8888/</code>。</p>
<hr>
<h3 id="使用conda创建python虚拟环境"><a href="#使用conda创建python虚拟环境" class="headerlink" title="使用conda创建python虚拟环境"></a>使用conda创建python虚拟环境</h3><p>&emsp;&emsp;首先在系统中安装<code>Anaconda</code>，可以输入<code>conda -V</code>查看是否安装成功以及当前<code>conda</code>的版本。<code>conda</code>常用命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda list  <span class="comment"># 查看安装了的包</span></span><br><span class="line">conda env list  <span class="comment"># 查看当前存在的虚拟环境</span></span><br><span class="line">conda update conda  <span class="comment"># 检查更新当前的conda</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用命令<code>conda create -n your_env_name python=X.X</code>创建<code>python</code>版本为<code>X.X</code>，名字为<code>your_env_name</code>的虚拟环境，随后可以在<code>Anaconda</code>中的<code>envs</code>目录下找到<code>your_env_name</code>文件，这里的<code>X.X</code>可以是<code>2.7</code>或<code>3.6</code>等。<br>&emsp;&emsp;使用激活(或切换不同<code>python</code>版本)的虚拟环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> activate your_env_name  <span class="comment"># Linux系统</span></span><br><span class="line">activate your_env_name  <span class="comment"># Windows系统</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用命令<code>conda install -n your_env_name package</code>即可安装<code>package</code>到<code>your_env_name</code>中。或者进入<code>conda</code>虚拟环境，使用<code>conda install package</code>(或者<code>conda install package=版本</code>)安装<code>package</code>。<br>&emsp;&emsp;关闭虚拟环境(即从当前虚拟环境中退出，使用<code>PATH</code>环境中的默认<code>python</code>)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> deactivate  <span class="comment"># Linux系统</span></span><br><span class="line">deactivate  <span class="comment"># Windows系统</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用命令<code>conda remove -n your_env_name --all</code>即可删除指定的虚拟环境。<br>&emsp;&emsp;使用命令<code>conda remove -n your_env_name package_name</code>删除虚拟环境中的<code>package_name</code>包。或者进入<code>conda</code>虚拟环境，使用<code>conda uninstall package</code>卸载<code>package</code>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/12/Python语法/xml模块/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/12/Python语法/xml模块/" itemprop="url">xml模块</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-12T14:08:01+08:00">
                2019-01-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="什么是XML？"><a href="#什么是XML？" class="headerlink" title="什么是XML？"></a>什么是XML？</h3><p>&emsp;&emsp;<code>XML</code>指可扩展标记语言(<code>Extensible Markup Language</code>)，标准通用标记语言的子集，是一种用于标记电子文件使其具有结构性的标记语言。它被设计用于传输和存储数据。<br>&emsp;&emsp;<code>XML</code>是一套定义语义标记的规则，这些标记将文档分成许多部件，并对这些部件加以标识。它也是元标记语言，即定义了用于定义其他与特定领域有关的、语义的、结构化的标记语言的句法语言。</p>
<h3 id="python对XML的解析"><a href="#python对XML的解析" class="headerlink" title="python对XML的解析"></a>python对XML的解析</h3><p>&emsp;&emsp;常见的<code>XML</code>编程接口有<code>DOM</code>和<code>SAX</code>，这两种接口处理<code>XML</code>文件的方式不同，当然使用场合也不同。<code>python</code>有三种方法解析<code>XML</code>：<code>SAX</code>、<code>DOM</code>以及<code>ElementTree</code>：</p>
<ul>
<li><code>SAX(Simple API for XML)</code>：<code>python</code>标准库包含<code>SAX</code>解析器，<code>SAX</code>用事件驱动模型，通过在解析<code>XML</code>的过程中触发一个个的事件，并调用用户定义的回调函数来处理<code>XML</code>文件。</li>
<li><code>DOM(Document Object Model)</code>：将<code>XML</code>数据在内存中解析成一个树，通过对树的操作来操作<code>XML</code>。</li>
</ul>
<p>本章节使用到的<code>XML</code>实例文件<code>movies.xml</code>内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">collection</span> <span class="attr">shelf</span>=<span class="string">"New Arrivals"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">movie</span> <span class="attr">title</span>=<span class="string">"Enemy Behind"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>War, Thriller<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">format</span>&gt;</span>DVD<span class="tag">&lt;/<span class="name">format</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">year</span>&gt;</span>2003<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rating</span>&gt;</span>PG<span class="tag">&lt;/<span class="name">rating</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">stars</span>&gt;</span>10<span class="tag">&lt;/<span class="name">stars</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Talk about a US-Japan war<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">movie</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">movie</span> <span class="attr">title</span>=<span class="string">"Transformers"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>Anime, Science Fiction<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">format</span>&gt;</span>DVD<span class="tag">&lt;/<span class="name">format</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">year</span>&gt;</span>1989<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rating</span>&gt;</span>R<span class="tag">&lt;/<span class="name">rating</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">stars</span>&gt;</span>8<span class="tag">&lt;/<span class="name">stars</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>A schientific fiction<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">movie</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">movie</span> <span class="attr">title</span>=<span class="string">"Trigun"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>Anime, Action<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">format</span>&gt;</span>DVD<span class="tag">&lt;/<span class="name">format</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">episodes</span>&gt;</span>4<span class="tag">&lt;/<span class="name">episodes</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rating</span>&gt;</span>PG<span class="tag">&lt;/<span class="name">rating</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">stars</span>&gt;</span>10<span class="tag">&lt;/<span class="name">stars</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Vash the Stampede!<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">movie</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">movie</span> <span class="attr">title</span>=<span class="string">"Ishtar"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>Comedy<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">format</span>&gt;</span>VHS<span class="tag">&lt;/<span class="name">format</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rating</span>&gt;</span>PG<span class="tag">&lt;/<span class="name">rating</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">stars</span>&gt;</span>2<span class="tag">&lt;/<span class="name">stars</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Viewable boredom<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">movie</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">collection</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="python使用SAX解析xml"><a href="#python使用SAX解析xml" class="headerlink" title="python使用SAX解析xml"></a>python使用SAX解析xml</h3><p>&emsp;&emsp;<code>SAX</code>是一种基于事件驱动的<code>API</code>。利用<code>SAX</code>解析<code>XML</code>文档牵涉到两个部分，即<code>解析器</code>和<code>事件处理器</code>。</p>
<ul>
<li>解析器负责读取XML文档，并向事件处理器发送事件，例如元素开始和元素结束事件。</li>
<li>事件处理器则负责对事件作出相应，对传递的XML数据进行处理。</li>
</ul>
<p>&emsp;&emsp;在<code>python</code>中使用<code>SAX</code>方式处理<code>XML</code>，要先引入<code>xml.sax</code>中的<code>parse</code>函数，还有<code>xml.sax.handler</code>中的<code>ContentHandler</code>。</p>
<h4 id="ContentHandler类方法介绍"><a href="#ContentHandler类方法介绍" class="headerlink" title="ContentHandler类方法介绍"></a>ContentHandler类方法介绍</h4><ul>
<li><code>characters(content)</code>方法：调用时机是：从行开始，在遇到标签之前，如果存在字符，<code>content</code>的值为这些字符串；从一个标签开始，在遇到下一个标签之前，如果存在字符，<code>content</code>的值为这些字符串；从一个标签，在遇到行结束符之前，如果存在字符，<code>content</code>的值为这些字符串。标签可以是开始标签，也可以是结束标签。</li>
<li><code>startDocument</code>方法：文档启动的时候调用。</li>
<li><code>endDocument</code>方法：解析器到达文档结尾时调用。</li>
<li><code>startElement(name, attrs)</code>方法：遇到<code>XML</code>开始标签时调用，<code>name</code>是标签的名字，<code>attrs</code>是标签的属性值字典。</li>
<li><code>endElement(name)</code>方法：遇到<code>XML</code>结束标签时调用。</li>
</ul>
<h4 id="make-parser方法"><a href="#make-parser方法" class="headerlink" title="make_parser方法"></a>make_parser方法</h4><p>&emsp;&emsp;以下方法创建一个新的解析器对象并返回：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xml.sax.make_parser([parser_list])</span><br></pre></td></tr></table></figure>
<p>参数<code>parser_list</code>是可选参数，即解析器列表。</p>
<h4 id="parser方法"><a href="#parser方法" class="headerlink" title="parser方法"></a>parser方法</h4><p>&emsp;&emsp;以下方法创建一个<code>SAX</code>解析器，并解析<code>xml</code>文档：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xml.sax.parse(xmlfile, contenthandler[, errorhandler])</span><br></pre></td></tr></table></figure>
<p>参数<code>xmlfile</code>是<code>xml</code>文件名；<code>contenthandler</code>必须是一个<code>ContentHandler</code>的对象；对于<code>errorhandler</code>，如果指定该参数，<code>errorhandler</code>必须是一个<code>SAX ErrorHandler</code>对象。</p>
<h4 id="parseString方法"><a href="#parseString方法" class="headerlink" title="parseString方法"></a>parseString方法</h4><p>&emsp;&emsp;<code>parseString</code>方法创建一个<code>XML</code>解析器，并解析<code>xml</code>字符串：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xml.sax.parseString(xmlstring, contenthandler[, errorhandler])</span><br></pre></td></tr></table></figure>
<p>参数<code>xmlstring</code>是<code>xml</code>字符串；<code>contenthandler</code>必须是一个<code>ContentHandler</code>的对象；对于<code>errorhandler</code>，如果指定该参数，<code>errorhandler</code>必须是一个<code>SAX ErrorHandler</code>对象。</p>
<h3 id="Python解析XML实例"><a href="#Python解析XML实例" class="headerlink" title="Python解析XML实例"></a>Python解析XML实例</h3><p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.sax</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieHandler</span><span class="params">(xml.sax.ContentHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.CurrentData = <span class="string">""</span></span><br><span class="line">        self.type = <span class="string">""</span></span><br><span class="line">        self.format = <span class="string">""</span></span><br><span class="line">        self.year = <span class="string">""</span></span><br><span class="line">        self.rating = <span class="string">""</span></span><br><span class="line">        self.stars = <span class="string">""</span></span><br><span class="line">        self.description = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">startElement</span><span class="params">(self, tag, attributes)</span>:</span>  <span class="comment"># 元素开始调用</span></span><br><span class="line">        self.CurrentData = tag</span><br><span class="line">        <span class="keyword">if</span> tag == <span class="string">"movie"</span>:</span><br><span class="line">            print(<span class="string">"*****Movie*****"</span>)</span><br><span class="line">            title = attributes[<span class="string">"title"</span>]</span><br><span class="line">            print(<span class="string">"Title:"</span>, title)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">endElement</span><span class="params">(self, tag)</span>:</span>  <span class="comment"># 元素结束调用</span></span><br><span class="line">        <span class="keyword">if</span> self.CurrentData == <span class="string">"type"</span>:</span><br><span class="line">            print(<span class="string">"Type:"</span>, self.type)</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"format"</span>:</span><br><span class="line">            print(<span class="string">"Format:"</span>, self.format)</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"year"</span>:</span><br><span class="line">            print(<span class="string">"Year:"</span>, self.year)</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"rating"</span>:</span><br><span class="line">            print(<span class="string">"Rating:"</span>, self.rating)</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"stars"</span>:</span><br><span class="line">            print(<span class="string">"Stars:"</span>, self.stars)</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"description"</span>:</span><br><span class="line">            print(<span class="string">"Description:"</span>, self.description)</span><br><span class="line">        self.CurrentData = <span class="string">""</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">characters</span><span class="params">(self, content)</span>:</span>  <span class="comment"># 读取字符时调用</span></span><br><span class="line">        <span class="keyword">if</span> self.CurrentData == <span class="string">"type"</span>:</span><br><span class="line">            self.type = content</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"format"</span>:</span><br><span class="line">            self.format = content</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"year"</span>:</span><br><span class="line">            self.year = content</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"rating"</span>:</span><br><span class="line">            self.rating = content</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"stars"</span>:</span><br><span class="line">            self.stars = content</span><br><span class="line">        <span class="keyword">elif</span> self.CurrentData == <span class="string">"description"</span>:</span><br><span class="line">            self.description = content</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    parser = xml.sax.make_parser()  <span class="comment"># 创建一个XMLReader</span></span><br><span class="line">    <span class="comment"># turn off namepsaces</span></span><br><span class="line">    parser.setFeature(xml.sax.handler.feature_namespaces, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 重写ContextHandler</span></span><br><span class="line">    Handler = MovieHandler()</span><br><span class="line">    parser.setContentHandler(Handler)</span><br><span class="line">    parser.parse(<span class="string">"movies.xml"</span>)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">*****Movie*****</span><br><span class="line">Title: Enemy Behind</span><br><span class="line">Type: War, Thriller</span><br><span class="line">Format: DVD</span><br><span class="line">Year: <span class="number">2003</span></span><br><span class="line">Rating: PG</span><br><span class="line">Stars: <span class="number">10</span></span><br><span class="line">Description: Talk about a US-Japan war</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Transformers</span><br><span class="line">Type: Anime, Science Fiction</span><br><span class="line">Format: DVD</span><br><span class="line">Year: <span class="number">1989</span></span><br><span class="line">Rating: R</span><br><span class="line">Stars: <span class="number">8</span></span><br><span class="line">Description: A schientific fiction</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Trigun</span><br><span class="line">Type: Anime, Action</span><br><span class="line">Format: DVD</span><br><span class="line">Rating: PG</span><br><span class="line">Stars: <span class="number">10</span></span><br><span class="line">Description: Vash the Stampede!</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Ishtar</span><br><span class="line">Type: Comedy</span><br><span class="line">Format: VHS</span><br><span class="line">Rating: PG</span><br><span class="line">Stars: <span class="number">2</span></span><br><span class="line">Description: Viewable boredom</span><br></pre></td></tr></table></figure>
<h3 id="使用xml-dom解析xml"><a href="#使用xml-dom解析xml" class="headerlink" title="使用xml.dom解析xml"></a>使用xml.dom解析xml</h3><p>&emsp;&emsp;文件对象模型(<code>Document Object Model</code>，即<code>DOM</code>)是<code>W3C</code>组织推荐的处理可扩展置标语言的标准编程接口。<br>&emsp;&emsp;一个<code>DOM</code>的解析器在解析一个<code>XML</code>文档时，一次性读取整个文档，把文档中所有元素保存在内存中的一个树结构里，之后可以利用<code>DOM</code>提供的不同的函数来读取或修改文档的内容和结构，也可以把修改过的内容写入<code>xml</code>文件。<br>&emsp;&emsp;<code>python</code>中用<code>xml.dom.minidom</code>来解析<code>xml</code>文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xml.dom.minidom <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">import</span> xml.dom.minidom</span><br><span class="line">​</span><br><span class="line">DOMTree = xml.dom.minidom.parse(<span class="string">"movies.xml"</span>)  <span class="comment"># 使用minidom解析器打开XML文档</span></span><br><span class="line">collection = DOMTree.documentElement</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> collection.hasAttribute(<span class="string">"shelf"</span>):</span><br><span class="line">    print(<span class="string">"Root element : %s"</span> % collection.getAttribute(<span class="string">"shelf"</span>))</span><br><span class="line">​</span><br><span class="line">movies = collection.getElementsByTagName(<span class="string">"movie"</span>)  <span class="comment"># 在集合中获取所有电影</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> movie <span class="keyword">in</span> movies:  <span class="comment"># 打印每部电影的详细信息</span></span><br><span class="line">    print(<span class="string">"*****Movie*****"</span>)</span><br><span class="line">    <span class="keyword">if</span> movie.hasAttribute(<span class="string">"title"</span>):</span><br><span class="line">        print(<span class="string">"Title: %s"</span> % movie.getAttribute(<span class="string">"title"</span>))</span><br><span class="line">​</span><br><span class="line">    type = movie.getElementsByTagName(<span class="string">'type'</span>)[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">"Type: %s"</span> % type.childNodes[<span class="number">0</span>].data)</span><br><span class="line">    format = movie.getElementsByTagName(<span class="string">'format'</span>)[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">"Format: %s"</span> % format.childNodes[<span class="number">0</span>].data)</span><br><span class="line">    rating = movie.getElementsByTagName(<span class="string">'rating'</span>)[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">"Rating: %s"</span> % rating.childNodes[<span class="number">0</span>].data)</span><br><span class="line">    description = movie.getElementsByTagName(<span class="string">'description'</span>)[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">"Description: %s"</span> % description.childNodes[<span class="number">0</span>].data)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Root element : New Arrivals</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Enemy Behind</span><br><span class="line">Type: War, Thriller</span><br><span class="line">Format: DVD</span><br><span class="line">Rating: PG</span><br><span class="line">Description: Talk about a US-Japan war</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Transformers</span><br><span class="line">Type: Anime, Science Fiction</span><br><span class="line">Format: DVD</span><br><span class="line">Rating: R</span><br><span class="line">Description: A schientific fiction</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Trigun</span><br><span class="line">Type: Anime, Action</span><br><span class="line">Format: DVD</span><br><span class="line">Rating: PG</span><br><span class="line">Description: Vash the Stampede!</span><br><span class="line">*****Movie*****</span><br><span class="line">Title: Ishtar</span><br><span class="line">Type: Comedy</span><br><span class="line">Format: VHS</span><br><span class="line">Rating: PG</span><br><span class="line">Description: Viewable boredom</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="xml-etree-ElementTree-—-The-ElementTree-XML-API"><a href="#xml-etree-ElementTree-—-The-ElementTree-XML-API" class="headerlink" title="xml.etree.ElementTree — The ElementTree XML API"></a>xml.etree.ElementTree — The ElementTree XML API</h3><p>&emsp;&emsp;The <code>xml.etree.ElementTree</code> module implements a simple and efficient <code>API</code> for parsing and creating <code>XML</code> data.<br>&emsp;&emsp;Changed in <code>version 3.3</code>: This module will use a fast implementation whenever available. The <code>xml.etree.cElementTree</code> module is deprecated.<br>&emsp;&emsp;<strong>Warning</strong>: The <code>xml.etree.ElementTree</code> module is not secure against maliciously constructed data. If you need to parse untrusted or unauthenticated data.</p>
<h3 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h3><p>&emsp;&emsp;This is a short tutorial for using <code>xml.etree.ElementTree</code> (<code>ET</code> in short). The goal is to demonstrate some of the building blocks and basic concepts of the module.</p>
<h4 id="XML-tree-and-elements"><a href="#XML-tree-and-elements" class="headerlink" title="XML tree and elements"></a>XML tree and elements</h4><p>&emsp;&emsp;<code>XML</code> is an inherently hierarchical data format, and the most natural way to represent it is with a tree. <code>ET</code> has two classes for this purpose - <code>ElementTree</code> represents the whole <code>XML</code> document as a tree, and <code>Element</code> represents a single node in this tree. Interactions with the whole document (reading and writing to/from files) are usually done on the <code>ElementTree</code> level. Interactions with a single <code>XML</code> element and its <code>sub-elements</code> are done on the <code>Element</code> level.</p>
<h4 id="Parsing-XML"><a href="#Parsing-XML" class="headerlink" title="Parsing XML"></a>Parsing XML</h4><p>&emsp;&emsp;We’ll be using the following <code>XML</code> document as the sample data for this section:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Liechtenstein"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span>&gt;</span>1<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2008<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>141100<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Austria"</span> <span class="attr">direction</span>=<span class="string">"E"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Switzerland"</span> <span class="attr">direction</span>=<span class="string">"W"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Singapore"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span>&gt;</span>4<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>59900<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Malaysia"</span> <span class="attr">direction</span>=<span class="string">"N"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Panama"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span>&gt;</span>68<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>13600<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Costa Rica"</span> <span class="attr">direction</span>=<span class="string">"W"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Colombia"</span> <span class="attr">direction</span>=<span class="string">"E"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>We can import this data by reading from a file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line">tree = ET.parse(<span class="string">'country_data.xml'</span>)</span><br><span class="line">root = tree.getroot()</span><br><span class="line">Or directly <span class="keyword">from</span> a string:</span><br><span class="line">root = ET.fromstring(country_data_as_string)</span><br></pre></td></tr></table></figure>
<p><code>fromstring()</code> parses <code>XML</code> from a string directly into an <code>Element</code>, which is the root element of the parsed tree. Other parsing functions may create an <code>ElementTree</code>.<br>&emsp;&emsp;As an <code>Element</code>, root has a tag and a dictionary of attributes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>root.tag</span><br><span class="line"><span class="string">'data'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>root.attrib</span><br><span class="line">&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>It also has children nodes over which we can iterate:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> child <span class="keyword">in</span> root:</span><br><span class="line"><span class="meta">... </span>    print(child.tag, child.attrib)</span><br><span class="line">...</span><br><span class="line">country &#123;<span class="string">'name'</span>: <span class="string">'Liechtenstein'</span>&#125;</span><br><span class="line">country &#123;<span class="string">'name'</span>: <span class="string">'Singapore'</span>&#125;</span><br><span class="line">country &#123;<span class="string">'name'</span>: <span class="string">'Panama'</span>&#125;</span><br></pre></td></tr></table></figure>
<p>Children are nested, and we can access specific child nodes by <code>index</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>root[<span class="number">0</span>][<span class="number">1</span>].text</span><br><span class="line"><span class="string">'2008'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<strong>Note</strong>: Not all elements of the <code>XML</code> input will end up as elements of the parsed tree. Currently, this module skips over any <code>XML</code> comments, processing instructions, and document type declarations in the input. Nevertheless, trees built using this module’s <code>API</code> rather than parsing from <code>XML</code> text can have comments and processing instructions in them; they will be included when generating <code>XML</code> output. A document type declaration may be accessed by passing a custom <code>TreeBuilder</code> instance to the <code>XMLParser</code> constructor.</p>
<h4 id="Pull-API-for-non-blocking-parsing"><a href="#Pull-API-for-non-blocking-parsing" class="headerlink" title="Pull API for non-blocking parsing"></a>Pull API for non-blocking parsing</h4><p>&emsp;&emsp;Most parsing functions provided by this module require the whole document to be read at once before returning any result. It is possible to use an <code>XMLParser</code> and feed data into it incrementally, but it is a push <code>API</code> that calls methods on a callback target, which is too <code>low-level</code> and inconvenient for most needs. Sometimes what the user really wants is to be able to parse <code>XML</code> incrementally, without blocking operations, while enjoying the convenience of fully constructed <code>Element</code> objects.<br>&emsp;&emsp;The most powerful tool for doing this is <code>XMLPullParser</code>. It does not require a blocking read to obtain the <code>XML</code> data, and is instead fed with data incrementally with <code>XMLPullParser.feed()</code> calls. To get the parsed <code>XML</code> elements, call <code>XMLPullParser.read_events()</code>. Here is an example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser = ET.XMLPullParser([<span class="string">'start'</span>, <span class="string">'end'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser.feed(<span class="string">'&lt;mytag&gt;sometext'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(parser.read_events())</span><br><span class="line">[(<span class="string">'start'</span>, &lt;Element <span class="string">'mytag'</span> at <span class="number">0x7fa66db2be58</span>&gt;)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser.feed(<span class="string">' more text&lt;/mytag&gt;'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> event, elem <span class="keyword">in</span> parser.read_events():</span><br><span class="line"><span class="meta">... </span>    print(event)</span><br><span class="line"><span class="meta">... </span>    print(elem.tag, <span class="string">'text='</span>, elem.text)</span><br><span class="line">...</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>The obvious use case is applications that operate in a <code>non-blocking</code> fashion where the <code>XML</code> data is being received from a socket or read incrementally from some storage device. In such cases, <code>blocking</code> reads are unacceptable.<br>&emsp;&emsp;Because it’s so flexible, <code>XMLPullParser</code> can be inconvenient to use for simpler <code>use-cases</code>. If you don’t mind your application <code>blocking</code> on reading <code>XML</code> data but would still like to have incremental parsing capabilities, take a look at <code>iterparse()</code>. It can be useful when you’re reading a large <code>XML</code> document and don’t want to hold it wholly in memory.</p>
<h4 id="Finding-interesting-elements"><a href="#Finding-interesting-elements" class="headerlink" title="Finding interesting elements"></a>Finding interesting elements</h4><p>&emsp;&emsp;<code>Element</code> has some useful methods that help iterate recursively over all the <code>sub-tree</code> below it (its children, their children, and so on). For example, <code>Element.iter()</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> neighbor <span class="keyword">in</span> root.iter(<span class="string">'neighbor'</span>):</span><br><span class="line"><span class="meta">... </span>    print(neighbor.attrib)</span><br><span class="line">...</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'Austria'</span>, <span class="string">'direction'</span>: <span class="string">'E'</span>&#125;</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'Switzerland'</span>, <span class="string">'direction'</span>: <span class="string">'W'</span>&#125;</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'Malaysia'</span>, <span class="string">'direction'</span>: <span class="string">'N'</span>&#125;</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'Costa Rica'</span>, <span class="string">'direction'</span>: <span class="string">'W'</span>&#125;</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'Colombia'</span>, <span class="string">'direction'</span>: <span class="string">'E'</span>&#125;</span><br></pre></td></tr></table></figure>
<p><code>Element.findall()</code> finds only elements with a tag which are direct children of the current element. <code>Element.find()</code> finds the first child with a particular tag, and <code>Element.text</code> accesses the element’s text content. <code>Element.get()</code> accesses the element’s attributes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> country <span class="keyword">in</span> root.findall(<span class="string">'country'</span>):</span><br><span class="line"><span class="meta">... </span>    rank = country.find(<span class="string">'rank'</span>).text</span><br><span class="line"><span class="meta">... </span>    name = country.get(<span class="string">'name'</span>)</span><br><span class="line"><span class="meta">... </span>    print(name, rank)</span><br><span class="line">...</span><br><span class="line">Liechtenstein <span class="number">1</span></span><br><span class="line">Singapore <span class="number">4</span></span><br><span class="line">Panama <span class="number">68</span></span><br></pre></td></tr></table></figure>
<p>More sophisticated specification of which elements to look for is possible by using <code>XPath</code>.</p>
<h4 id="Modifying-an-XML-File"><a href="#Modifying-an-XML-File" class="headerlink" title="Modifying an XML File"></a>Modifying an XML File</h4><p>&emsp;&emsp;<code>ElementTree</code> provides a simple way to build <code>XML</code> documents and write them to files. The <code>ElementTree.write()</code> method serves this purpose.<br>&emsp;&emsp;Once created, an <code>Element</code> object may be manipulated by directly changing its fields (such as <code>Element.text</code>), adding and modifying attributes (<code>Element.set()</code> method), as well as adding new children (for example with <code>Element.append()</code>).<br>&emsp;&emsp;Let’s say we want to add one to each country’s rank, and add an updated attribute to the rank element:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> rank <span class="keyword">in</span> root.iter(<span class="string">'rank'</span>):</span><br><span class="line"><span class="meta">... </span>    new_rank = int(rank.text) + <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    rank.text = str(new_rank)</span><br><span class="line"><span class="meta">... </span>    rank.set(<span class="string">'updated'</span>, <span class="string">'yes'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree.write(<span class="string">'output.xml'</span>)</span><br></pre></td></tr></table></figure>
<p>Our <code>XML</code> now looks like this:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Liechtenstein"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span> <span class="attr">updated</span>=<span class="string">"yes"</span>&gt;</span>2<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2008<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>141100<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Austria"</span> <span class="attr">direction</span>=<span class="string">"E"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Switzerland"</span> <span class="attr">direction</span>=<span class="string">"W"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Singapore"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span> <span class="attr">updated</span>=<span class="string">"yes"</span>&gt;</span>5<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>59900<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Malaysia"</span> <span class="attr">direction</span>=<span class="string">"N"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Panama"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span> <span class="attr">updated</span>=<span class="string">"yes"</span>&gt;</span>69<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>13600<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Costa Rica"</span> <span class="attr">direction</span>=<span class="string">"W"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Colombia"</span> <span class="attr">direction</span>=<span class="string">"E"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>We can remove elements using <code>Element.remove()</code>. Let’s say we want to remove all countries with a rank higher than <code>50</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> country <span class="keyword">in</span> root.findall(<span class="string">'country'</span>):</span><br><span class="line"><span class="meta">... </span>    rank = int(country.find(<span class="string">'rank'</span>).text)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> rank &gt; <span class="number">50</span>:</span><br><span class="line"><span class="meta">... </span>        root.remove(country)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree.write(<span class="string">'output.xml'</span>)</span><br></pre></td></tr></table></figure>
<p>Our <code>XML</code> now looks like this:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">data</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Liechtenstein"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span> <span class="attr">updated</span>=<span class="string">"yes"</span>&gt;</span>2<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2008<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>141100<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Austria"</span> <span class="attr">direction</span>=<span class="string">"E"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Switzerland"</span> <span class="attr">direction</span>=<span class="string">"W"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">country</span> <span class="attr">name</span>=<span class="string">"Singapore"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rank</span> <span class="attr">updated</span>=<span class="string">"yes"</span>&gt;</span>5<span class="tag">&lt;/<span class="name">rank</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">year</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">year</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">gdppc</span>&gt;</span>59900<span class="tag">&lt;/<span class="name">gdppc</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">neighbor</span> <span class="attr">name</span>=<span class="string">"Malaysia"</span> <span class="attr">direction</span>=<span class="string">"N"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">data</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="Building-XML-documents"><a href="#Building-XML-documents" class="headerlink" title="Building XML documents"></a>Building XML documents</h4><p>&emsp;&emsp;The <code>SubElement()</code> function also provides a convenient way to create new <code>sub-elements</code> for a given element:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = ET.Element(<span class="string">'a'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = ET.SubElement(a, <span class="string">'b'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = ET.SubElement(a, <span class="string">'c'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = ET.SubElement(c, <span class="string">'d'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ET.dump(a)</span><br><span class="line">&lt;a&gt;&lt;b /&gt;&lt;c&gt;&lt;d /&gt;&lt;/c&gt;&lt;/a&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Parsing-XML-with-Namespaces"><a href="#Parsing-XML-with-Namespaces" class="headerlink" title="Parsing XML with Namespaces"></a>Parsing XML with Namespaces</h4><p>&emsp;&emsp;If the <code>XML</code> input has <code>namespaces</code>, <code>tags</code> and <code>attributes</code> with prefixes in the form <code>prefix:sometag</code> get expanded to <code>{uri}sometag</code> where the prefix is replaced by the full <code>URI</code>. Also, if there is a default namespace, that full <code>URI</code> gets prepended to all of the <code>non-prefixed</code> tags.<br>&emsp;&emsp;Here is an <code>XML</code> example that incorporates two namespaces, one with the prefix <code>fictional</code> and the other serving as the default namespace:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">actors</span> <span class="attr">xmlns:fictional</span>=<span class="string">"http://characters.example.com"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns</span>=<span class="string">"http://people.example.com"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">actor</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>John Cleese<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fictional:character</span>&gt;</span>Lancelot<span class="tag">&lt;/<span class="name">fictional:character</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fictional:character</span>&gt;</span>Archie Leach<span class="tag">&lt;/<span class="name">fictional:character</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">actor</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">actor</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Eric Idle<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fictional:character</span>&gt;</span>Sir Robin<span class="tag">&lt;/<span class="name">fictional:character</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fictional:character</span>&gt;</span>Gunther<span class="tag">&lt;/<span class="name">fictional:character</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">fictional:character</span>&gt;</span>Commander Clement<span class="tag">&lt;/<span class="name">fictional:character</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">actor</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">actors</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>One way to search and explore this <code>XML</code> example is to manually add the <code>URI</code> to every tag or attribute in the xpath of a <code>find()</code> or <code>findall()</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root = fromstring(xml_text)</span><br><span class="line"><span class="keyword">for</span> actor <span class="keyword">in</span> root.findall(<span class="string">'&#123;http://people.example.com&#125;actor'</span>):</span><br><span class="line">    name = actor.find(<span class="string">'&#123;http://people.example.com&#125;name'</span>)</span><br><span class="line">    print(name.text)</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> actor.findall(<span class="string">'&#123;http://characters.example.com&#125;character'</span>):</span><br><span class="line">        print(<span class="string">' |--&gt;'</span>, char.text)</span><br></pre></td></tr></table></figure>
<p>A better way to search the namespaced <code>XML</code> example is to create a dictionary with your own prefixes and use those in the search functions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ns = &#123;<span class="string">'real_person'</span>: <span class="string">'http://people.example.com'</span>, <span class="string">'role'</span>: <span class="string">'http://characters.example.com'</span>&#125;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> actor <span class="keyword">in</span> root.findall(<span class="string">'real_person:actor'</span>, ns):</span><br><span class="line">    name = actor.find(<span class="string">'real_person:name'</span>, ns)</span><br><span class="line">    print(name.text)</span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> actor.findall(<span class="string">'role:character'</span>, ns):</span><br><span class="line">        print(<span class="string">' |--&gt;'</span>, char.text)</span><br></pre></td></tr></table></figure>
<p>These two approaches both output:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">John Cleese</span><br><span class="line"> |--&gt; Lancelot</span><br><span class="line"> |--&gt; Archie Leach</span><br><span class="line">Eric Idle</span><br><span class="line"> |--&gt; Sir Robin</span><br><span class="line"> |--&gt; Gunther</span><br><span class="line"> |--&gt; Commander Clement</span><br></pre></td></tr></table></figure>
<h3 id="XPath-support"><a href="#XPath-support" class="headerlink" title="XPath support"></a>XPath support</h3><p>&emsp;&emsp;This module provides limited support for <code>XPath</code> expressions for locating elements in a tree. The goal is to support a small subset of the abbreviated syntax; a full <code>XPath</code> engine is outside the scope of the module.</p>
<h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p>&emsp;&emsp;Here’s an example that demonstrates some of the <code>XPath</code> capabilities of the module. We’ll be using the countrydata <code>XML</code> document from the Parsing <code>XML</code> section:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line">​</span><br><span class="line">root = ET.fromstring(countrydata)</span><br><span class="line">root.findall(<span class="string">"."</span>)  <span class="comment"># Top-level elements</span></span><br><span class="line"><span class="comment"># All 'neighbor' grand-children of 'country' children of the top-level elements</span></span><br><span class="line">root.findall(<span class="string">"./country/neighbor"</span>)</span><br><span class="line"><span class="comment"># Nodes with name='Singapore' that have a 'year' child</span></span><br><span class="line">root.findall(<span class="string">".//year/..[@name='Singapore']"</span>)</span><br><span class="line"><span class="comment"># 'year' nodes that are children of nodes with name='Singapore'</span></span><br><span class="line">root.findall(<span class="string">".//*[@name='Singapore']/year"</span>)</span><br><span class="line"><span class="comment"># All 'neighbor' nodes that are the second child of their parent</span></span><br><span class="line">root.findall(<span class="string">".//neighbor[2]"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Supported-XPath-syntax"><a href="#Supported-XPath-syntax" class="headerlink" title="Supported XPath syntax"></a>Supported XPath syntax</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Syntax</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tag</code></td>
<td>Selects all child elements with the given <code>tag</code>. For example, <code>spam</code> selects all child elements named <code>spam</code>, and <code>spam/egg</code> selects all grandchildren named <code>egg</code> in all children named <code>spam</code>.</td>
</tr>
<tr>
<td><code>*</code></td>
<td>Selects all child elements. For example, <code>*/egg</code> selects all grandchildren named <code>egg</code>.</td>
</tr>
<tr>
<td><code>.</code></td>
<td>Selects the current node. This is mostly useful at the <code>beginning</code> of the path, to indicate that it’s a relative path.</td>
</tr>
<tr>
<td><code>//</code></td>
<td>Selects all subelements, on all levels beneath the current element. For example, <code>.//egg</code> selects all <code>egg</code> elements in the entire tree.</td>
</tr>
<tr>
<td><code>..</code></td>
<td>Selects the parent element. Returns <code>None</code> if the path attempts to reach the ancestors of the <code>start</code> element (the element find was called on).</td>
</tr>
<tr>
<td><code>[@attrib]</code></td>
<td>Selects all elements that have the given <code>attribute</code>.</td>
</tr>
<tr>
<td><code>[@attrib=&#39;value&#39;]</code></td>
<td>Selects all elements for which the given <code>attribute</code> has the given <code>value</code>. The value cannot contain quotes.</td>
</tr>
<tr>
<td><code>[tag]</code></td>
<td>Selects all elements that have a child named <code>tag</code>. Only immediate children are supported.</td>
</tr>
<tr>
<td><code>[tag=&#39;text&#39;]</code></td>
<td>Selects all elements that have a child named <code>tag</code> whose complete <code>text</code> content, including descendants, equals the given <code>text</code>.</td>
</tr>
<tr>
<td><code>[position]</code></td>
<td>Selects all elements that are located at the given <code>position</code>. The <code>position</code> can be either an <code>integer</code> (<code>1</code> is the <code>first position</code>), the expression <code>last()</code> (for the <code>last position</code>), or a <code>position</code> relative to the <code>last position</code> (e.g. <code>last() - 1</code>).</td>
</tr>
</tbody>
</table>
</div>
<p>Predicates (expressions within square brackets) must be preceded by a tag name, an asterisk, or another predicate. position predicates must be preceded by a tag name.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><h4 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h4><p>&emsp;&emsp;<code>xml.etree.ElementTree.Comment(text=None)</code>: <code>Comment</code> <code>element</code> factory. This factory function creates a special <code>element</code> that will be serialized as an <code>XML</code> <code>comment</code> by the standard serializer. The <code>comment</code> string can be either a <code>bytestring</code> or a <code>Unicode string</code>. <code>text</code> is a string containing the <code>comment</code> string. Returns an <code>element</code> instance representing a <code>comment</code>.<br>&emsp;&emsp;Note that <code>XMLParser</code> skips over <code>comments</code> in the input instead of creating <code>comment</code> objects for them. An <code>ElementTree</code> will only contain <code>comment</code> nodes if they have been inserted into to the <code>tree</code> using one of the <code>Element</code> methods.<br>&emsp;&emsp;<code>xml.etree.ElementTree.dump(elem)</code>: Writes an <code>element</code> tree or <code>element</code> structure to <code>sys.stdout</code>. This function should be used for debugging only. The exact output format is implementation dependent. In this version, it’s written as an ordinary <code>XML</code> file. <code>elem</code> is an <code>element</code> tree or an individual <code>element</code>.<br>&emsp;&emsp;<code>xml.etree.ElementTree.fromstring(text)</code>: Parses an <code>XML</code> section from a <code>string</code> constant. Same as <code>XML()</code>. <code>text</code> is a <code>string</code> containing <code>XML</code> data. Returns an <code>Element</code> instance.<br>&emsp;&emsp;<code>xml.etree.ElementTree.fromstringlist(sequence, parser=None)</code>: Parses an <code>XML</code> document from a <code>sequence</code> of <code>string</code> fragments. <code>sequence</code> is a list or other <code>sequence</code> containing <code>XML</code> data fragments. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> <code>parser</code> is used. Returns an <code>Element</code> instance.<br>&emsp;&emsp;<code>xml.etree.ElementTree.iselement(element)</code>: Checks if an object appears to be a valid <code>element</code> object. <code>element</code> is an <code>element</code> instance. Returns a <code>true</code> value if this is an <code>element</code> object.<br>&emsp;&emsp;<code>xml.etree.ElementTree.iterparse(source, events=None, parser=None)</code>: Parses an <code>XML</code> section into an <code>element tree</code> incrementally, and reports what’s going on to the user. <code>source</code> is a filename or file object containing <code>XML</code> data. <code>events</code> is a sequence of <code>events</code> to report back. The supported <code>events</code> are the strings <code>start</code>, <code>end</code>, <code>start-ns</code> and <code>end-ns</code> (the <code>ns</code> events are used to get detailed namespace information). If <code>events</code> is omitted, only <code>end events</code> are reported. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> parser is used. <code>parser</code> must be a subclass of <code>XMLParser</code> and can only use the default <code>TreeBuilder</code> as a target. Returns an iterator providing <code>(event, elem)</code> pairs.<br>&emsp;&emsp;Note that while <code>iterparse()</code> builds the <code>tree</code> incrementally, it issues blocking reads on source (or the file it names). As such, it’s unsuitable for applications where blocking reads can’t be made. For fully <code>non-blocking</code> parsing, see <code>XMLPullParser</code>.<br>&emsp;&emsp;<strong>Note</strong>: <code>iterparse()</code> only guarantees that it has seen the <code>&gt;</code> character of a starting tag when it emits a <code>start</code> event, so the attributes are defined, but the contents of the <code>text</code> and <code>tail</code> attributes are undefined at that point. The same applies to the <code>element</code> children; they may or may not be present. If you need a fully populated <code>element</code>, look for <code>end</code> events instead.<br>&emsp;&emsp;<code>xml.etree.ElementTree.parse(source, parser=None)</code>: Parses an <code>XML</code> section into an <code>element</code> tree. <code>source</code> is a filename or file object containing <code>XML</code> data. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> parser is used. Returns an <code>ElementTree</code> instance.<br>&emsp;&emsp;<code>xml.etree.ElementTree.ProcessingInstruction(target, text=None)</code>: <code>PI</code> element factory. This factory function creates a special <code>element</code> that will be serialized as an <code>XML</code> processing instruction. <code>target</code> is a string containing the <code>PI</code> target. <code>text</code> is a string containing the <code>PI</code> contents, if given. Returns an <code>element</code> instance, representing a processing instruction.<br>&emsp;&emsp;Note that XMLParser skips over processing instructions in the input instead of creating comment objects for them. An ElementTree will only contain processing instruction nodes if they have been inserted into to the tree using one of the Element methods.<br>&emsp;&emsp;<code>xml.etree.ElementTree.register_namespace(prefix, uri)</code>: Registers a <code>namespace prefix</code>. The <code>registry</code> is global, and any existing mapping for either the given <code>prefix</code> or the <code>namespace URI</code> will be removed. <code>prefix</code> is a <code>namespace prefix</code>. <code>uri</code> is a <code>namespace uri</code>. Tags and attributes in this <code>namespace</code> will be serialized with the given <code>prefix</code>, if at all possible.<br>&emsp;&emsp;<code>xml.etree.ElementTree.SubElement(parent, tag, attrib={}, **extra)</code>: <code>Subelement</code> factory. This function creates an <code>element</code> instance, and appends it to an existing <code>element</code>.<br>&emsp;&emsp;The <code>element</code> name, attribute names, and attribute values can be either <code>bytestrings</code> or <code>Unicode strings</code>. <code>parent</code> is the <code>parent</code> element. <code>tag</code> is the subelement name. <code>attrib</code> is an optional dictionary, containing <code>element</code> attributes. <code>extra</code> contains additional attributes, given as keyword arguments. Returns an <code>element</code> instance.<br>&emsp;&emsp;<code>xml.etree.ElementTree.tostring(element, encoding=&quot;us-ascii&quot;, method=&quot;xml&quot;, *, short_empty_elements=True)</code>: Generates a <code>string</code> representation of an <code>XML</code> element, including all subelements. <code>element</code> is an <code>Element</code> instance. <code>encoding</code> is the output <code>encoding</code> (default is <code>US-ASCII</code>). Use <code>encoding=&quot;unicode&quot;</code> to generate a <code>Unicode string</code> (otherwise, a <code>bytestring</code> is generated). <code>method</code> is either <code>xml</code>, <code>html</code> or <code>text</code> (default is <code>xml</code>). <code>short_empty_elements</code> has the same meaning as in <code>ElementTree.write()</code>. Returns an (optionally) <code>encoded string</code> containing the <code>XML</code> data.<br>&emsp;&emsp;<code>xml.etree.ElementTree.tostringlist(element, encoding=&quot;us-ascii&quot;, method=&quot;xml&quot;, *, short_empty_elements=True)</code>: Generates a <code>string</code> representation of an <code>XML</code> element, including all subelements. <code>element</code> is an <code>Element</code> instance. <code>encoding</code> is the output <code>encoding</code> (default is <code>US-ASCII</code>). Use <code>encoding=&quot;unicode&quot;</code> to generate a <code>Unicode string</code> (otherwise, a <code>bytestring</code> is <code>generated</code>). <code>method</code> is either <code>xml</code>, <code>html</code> or <code>text</code> (default is <code>xml</code>). <code>short_empty_elements</code> has the same meaning as in <code>ElementTree.write()</code>. Returns a list of (optionally) <code>encoded strings</code> containing the <code>XML</code> data. It does not guarantee any specific sequence, except that <code>b&quot;&quot;.join(tostringlist(element)) == tostring(element)</code>.<br>&emsp;&emsp;<code>xml.etree.ElementTree.XML(text, parser=None)</code>: Parses an <code>XML</code> section from a string constant. This function can be used to embed <code>XML literals</code> in Python code. <code>text</code> is a string containing <code>XML</code> data. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> parser is used. Returns an <code>Element</code> instance.<br>&emsp;&emsp;<code>xml.etree.ElementTree.XMLID(text, parser=None)</code>: Parses an <code>XML</code> section from a string constant, and also returns a <code>dictionary</code> which maps from element <code>id:s</code> to elements. <code>text</code> is a string containing <code>XML</code> data. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> parser is used. Returns a <code>tuple</code> containing an <code>Element</code> instance and a <code>dictionary</code>.</p>
<h3 id="Element-Objects"><a href="#Element-Objects" class="headerlink" title="Element Objects"></a>Element Objects</h3><h4 id="class-xml-etree-ElementTree-Element-tag-attrib-extra"><a href="#class-xml-etree-ElementTree-Element-tag-attrib-extra" class="headerlink" title="class xml.etree.ElementTree.Element(tag, attrib={}, **extra)"></a>class xml.etree.ElementTree.Element(tag, attrib={}, **extra)</h4><p>&emsp;&emsp;Element <code>class</code>. This <code>class</code> defines the <code>Element</code> interface, and provides a reference implementation of this interface.<br>&emsp;&emsp;The <code>element name</code>, <code>attribute names</code>, and <code>attribute values</code> can be either <code>bytestrings</code> or <code>Unicode strings</code>. <code>tag</code> is the element name. <code>attrib</code> is an optional <code>dictionary</code>, containing <code>element</code> attributes. <code>extra</code> contains additional attributes, given as keyword arguments.<br>&emsp;&emsp;<code>tag</code>: A <code>string</code> identifying what kind of data this <code>element</code> represents (the <code>element</code> type, in other words).<br>&emsp;&emsp;<code>tail</code>: These attributes can be used to hold additional data associated with the <code>element</code>. Their values are usually strings but may be any <code>application-specific</code> object. If the <code>element</code> is created from an <code>XML</code> file, the text attribute holds either the text between the element’s <code>start tag</code> and its first child or <code>end tag</code>, or <code>None</code>, and the <code>tail</code> attribute holds either the text between the element’s <code>end tag</code> and the <code>next tag</code>, or <code>None</code>. For the <code>XML</code> data</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>1<span class="tag">&lt;<span class="name">c</span>&gt;</span>2<span class="tag">&lt;<span class="name">d</span>/&gt;</span>3<span class="tag">&lt;/<span class="name">c</span>&gt;</span><span class="tag">&lt;/<span class="name">b</span>&gt;</span>4<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>the <code>a</code> element has <code>None</code> for both text and tail attributes, the <code>b</code> element has text <code>1</code> and tail <code>4</code>, the <code>c</code> element has text <code>2</code> and tail <code>None</code>, and the <code>d</code> element has text <code>None</code> and tail <code>3</code>.<br>&emsp;&emsp;To collect the inner text of an element, see <code>itertext()</code>, for example <code>&quot;&quot;.join(element.itertext())</code>.<br>&emsp;&emsp;<code>attrib</code>: A <code>dictionary</code> containing the element’s attributes. Note that while the <code>attrib</code> value is always a real mutable <code>Python dictionary</code>, an <code>ElementTree</code> implementation may choose to use another internal representation, and create the <code>dictionary</code> only if someone asks for it. To take advantage of such implementations, use the <code>dictionary</code> methods below whenever possible.<br>&emsp;&emsp;The following <code>dictionary-like</code> methods work on the element attributes.<br>&emsp;&emsp;<code>clear()</code>: Resets an <code>element</code>. This function removes all subelements, <code>clears</code> all attributes, and sets the text and tail attributes to <code>None</code>.<br>&emsp;&emsp;<code>get(key, default=None)</code>: Gets the <code>element</code> attribute named <code>key</code>. Returns the attribute value, or default if the attribute was not found.<br>&emsp;&emsp;<code>items()</code>: Returns the <code>element</code> attributes as a sequence of <code>(name, value)</code> pairs. The attributes are returned in an arbitrary order.<br>&emsp;&emsp;<code>keys()</code>: Returns the <code>elements</code> attribute names as a list. The names are returned in an arbitrary order.<br>&emsp;&emsp;<code>set(key, value)</code>: Set the attribute <code>key</code> on the element to <code>value</code>.<br>&emsp;&emsp;The following methods work on the element’s children (<code>subelements</code>).<br>&emsp;&emsp;<code>append(subelement)</code>: Adds the element <code>subelement</code> to the end of this element’s internal list of <code>subelements</code>. Raises <code>TypeError</code> if <code>subelement</code> is not an <code>Element</code>.<br>&emsp;&emsp;<code>extend(subelements)</code>: Appends <code>subelements</code> from a sequence object with zero or more <code>elements</code>. Raises <code>TypeError</code> if a <code>subelement</code> is not an <code>Element</code>.<br>&emsp;&emsp;<code>find(match, namespaces=None)</code>: Finds the first subelement matching <code>match</code>. <code>match</code> may be a tag name or a path. Returns an <code>element</code> instance or <code>None</code>. <code>namespaces</code> is an optional mapping from <code>namespace prefix</code> to full name.<br>&emsp;&emsp;<code>findall(match, namespaces=None)</code>: Finds all matching subelements, by tag name or path. Returns a list containing all matching elements in document order. <code>namespaces</code> is an optional mapping from <code>namespace prefix</code> to full name.<br>&emsp;&emsp;<code>findtext(match, default=None, namespaces=None)</code>: Finds text for the first subelement matching <code>match</code>. <code>match</code> may be a tag name or a path. Returns the <code>text</code> content of the first matching <code>element</code>, or <code>default</code> if no <code>element</code> was found. Note that if the matching <code>element</code> has no <code>text</code> content an empty string is returned. <code>namespaces</code> is an optional mapping from <code>namespace prefix</code> to full name.<br>&emsp;&emsp;<code>getchildren()</code>: Deprecated since version <code>3.2</code>: Use <code>list(elem)</code> or <code>iteration</code>.<br>&emsp;&emsp;<code>getiterator(tag=None)</code>: Deprecated since version <code>3.2</code>: Use method <code>Element.iter()</code> instead.<br>&emsp;&emsp;<code>insert(index, subelement)</code>: Inserts <code>subelement</code> at the given position in this <code>element</code>. Raises <code>TypeError</code> if <code>subelement</code> is not an <code>Element</code>.<br>&emsp;&emsp;<code>iter(tag=None)</code>: Creates a tree <code>iterator</code> with the current <code>element</code> as the <code>root</code>. The <code>iterator</code> iterates over this <code>element</code> and all <code>elements</code> below it, in document <code>(depth first)</code> order. If <code>tag</code> is not <code>None</code> or <code>*</code>, only <code>elements</code> whose <code>tag</code> equals <code>tag</code> are returned from the <code>iterator</code>. If the tree structure is modified during iteration, the result is undefined.<br>&emsp;&emsp;<code>iterfind(match, namespaces=None)</code>: Finds all matching subelements, by tag name or path. Returns an iterable yielding all matching <code>elements</code> in document order. <code>namespaces</code> is an optional mapping from <code>namespace prefix</code> to full name.<br>&emsp;&emsp;<code>itertext()</code>: Creates a text <code>iterator</code>. The <code>iterator</code> loops over this <code>element</code> and all subelements, in document order, and returns all inner <code>text</code>.<br>&emsp;&emsp;<code>makeelement(tag, attrib)</code>: Creates a new <code>element</code> object of the same type as this <code>element</code>. Do not call this method, use the <code>SubElement()</code> factory function instead.<br>&emsp;&emsp;<code>remove(subelement)</code>: Removes <code>subelement</code> from the <code>element</code>. Unlike the <code>find*</code> methods, this method compares elements based on the instance identity, not on tag value or contents.<br>&emsp;&emsp;Element objects also support the following sequence type methods for working with subelements: <code>__delitem__()</code>, <code>__getitem__()</code>, <code>__setitem__()</code>, <code>__len__()</code>.<br>&emsp;&emsp;<strong>Caution</strong>: Elements with no subelements will test as <code>False</code>. This behavior will change in future versions. Use specific <code>len(elem)</code> or elem is <code>None</code> test instead.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">element = root.find(<span class="string">'foo'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> element:  <span class="comment"># careful!</span></span><br><span class="line">    print(<span class="string">"element not found, or element has no subelements"</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> element <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">    print(<span class="string">"element not found"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="ElementTree-Objects"><a href="#ElementTree-Objects" class="headerlink" title="ElementTree Objects"></a>ElementTree Objects</h3><h4 id="class-xml-etree-ElementTree-ElementTree-element-None-file-None"><a href="#class-xml-etree-ElementTree-ElementTree-element-None-file-None" class="headerlink" title="class xml.etree.ElementTree.ElementTree(element=None, file=None)"></a>class xml.etree.ElementTree.ElementTree(element=None, file=None)</h4><p>&emsp;&emsp;<code>ElementTree</code> wrapper class. This class represents an entire <code>element</code> hierarchy, and adds some extra support for serialization to and from standard <code>XML</code>.<br>&emsp;&emsp;<code>element</code> is the <code>root element</code>. The <code>tree</code> is initialized with the contents of the <code>XML</code> file if given.<br>&emsp;&emsp;<code>_setroot(element)</code>: Replaces the <code>root element</code> for this tree. This discards the current contents of the tree, and replaces it with the given <code>element</code>. Use with care. <code>element</code> is an <code>element</code> instance.<br>&emsp;&emsp;<code>find(match, namespaces=None)</code>: Same as <code>Element.find()</code>, starting at the root of the tree.<br>&emsp;&emsp;<code>findall(match, namespaces=None)</code>: Same as <code>Element.findall()</code>, starting at the root of the tree.<br>&emsp;&emsp;<code>findtext(match, default=None, namespaces=None)</code>: Same as <code>Element.findtext()</code>, starting at the root of the tree.<br>&emsp;&emsp;<code>getiterator(tag=None)</code>: Deprecated since version <code>3.2</code>: Use method <code>ElementTree.iter()</code> instead.<br>&emsp;&emsp;<code>getroot()</code>: Returns the <code>root element</code> for this tree.<br>&emsp;&emsp;<code>iter(tag=None)</code>: Creates and returns a tree <code>iterator</code> for the <code>root element</code>. The <code>iterator</code> loops over all elements in this tree, in section order. <code>tag</code> is the <code>tag</code> to look for (default is to return all elements).<br>&emsp;&emsp;<code>iterfind(match, namespaces=None)</code>: Same as <code>Element.iterfind()</code>, starting at the root of the tree.<br>&emsp;&emsp;<code>parse(source, parser=None)</code>: Loads an external <code>XML</code> section into this <code>element</code> tree. <code>source</code> is a file name or file object. <code>parser</code> is an optional <code>parser</code> instance. If not given, the standard <code>XMLParser</code> parser is used. Returns the section <code>root element</code>.<br>&emsp;&emsp;<code>write(file, encoding=&quot;us-ascii&quot;, xml_declaration=None, default_namespace=None, method=&quot;xml&quot;, *, short_empty_elements=True)</code>: Writes the element tree to a file, as <code>XML</code>. <code>file</code> is a <code>file name</code>, or a <code>file object</code> opened for writing. <code>encoding</code> is the output <code>encoding</code> (default is <code>US-ASCII</code>). <code>xml_declaration</code> controls if an <code>XML</code> declaration should be added to the <code>file</code>. Use False for never, <code>True</code> for always, <code>None</code> for only if not <code>US-ASCII</code> or <code>UTF-8</code> or <code>Unicode</code> (default is <code>None</code>). <code>default_namespace</code> sets the default <code>XML</code> namespace (for <code>xmlns</code>). <code>method</code> is either <code>xml</code>, <code>html</code> or <code>text</code> (default is <code>xml</code>). The <code>keyword-only</code> <code>short_empty_elements</code> parameter controls the formatting of elements that contain no content. If <code>True</code> (the default), they are emitted as a single <code>self-closed</code> tag, otherwise they are emitted as a pair of start/end tags.<br>&emsp;&emsp;The output is either a <code>string</code> (<code>str</code>) or <code>binary</code> (<code>bytes</code>). This is controlled by the encoding argument. If encoding is <code>unicode</code>, the output is a <code>string</code>; otherwise, it’s <code>binary</code>. Note that this may conflict with the type of file if it’s an open file object; make sure you do not try to write a <code>string</code> to a <code>binary</code> stream and vice versa.<br>&emsp;&emsp;This is the <code>XML</code> file that is going to be manipulated:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Example page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>Moved to <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://example.org/"</span>&gt;</span>example.org<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        or <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://example.com/"</span>&gt;</span>example.com<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Example of changing the attribute <code>target</code> of every link in first paragraph:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> xml.etree.ElementTree <span class="keyword">import</span> ElementTree</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree = ElementTree()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree.parse(<span class="string">"index.xhtml"</span>)</span><br><span class="line">&lt;Element <span class="string">'html'</span> at <span class="number">0xb77e6fac</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = tree.find(<span class="string">"body/p"</span>)  <span class="comment"># Finds first occurrence of tag p in body</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p</span><br><span class="line">&lt;Element <span class="string">'p'</span> at <span class="number">0xb77ec26c</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>links = list(p.iter(<span class="string">"a"</span>))  <span class="comment"># Returns list of all links</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>links</span><br><span class="line">[&lt;Element <span class="string">'a'</span> at <span class="number">0xb77ec2ac</span>&gt;, &lt;Element <span class="string">'a'</span> at <span class="number">0xb77ec1cc</span>&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> links:  <span class="comment"># Iterates through all found links</span></span><br><span class="line"><span class="meta">... </span>    i.attrib[<span class="string">"target"</span>] = <span class="string">"blank"</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree.write(<span class="string">"output.xhtml"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="QName-Objects"><a href="#QName-Objects" class="headerlink" title="QName Objects"></a>QName Objects</h3><h4 id="class-xml-etree-ElementTree-QName-text-or-uri-tag-None"><a href="#class-xml-etree-ElementTree-QName-text-or-uri-tag-None" class="headerlink" title="class xml.etree.ElementTree.QName(text_or_uri, tag=None)"></a>class xml.etree.ElementTree.QName(text_or_uri, tag=None)</h4><p>&emsp;&emsp;<code>QName</code> wrapper. This can be used to wrap a <code>QName</code> attribute value, in order to get proper namespace handling on output. <code>text_or_uri</code> is a string containing the <code>QName</code> value, in the form <code>{uri}local</code>, or, if the <code>tag</code> argument is given, the <code>URI</code> part of a <code>QName</code>. If <code>tag</code> is given, the first argument is interpreted as a <code>URI</code>, and this argument is interpreted as a local name. <code>QName</code> instances are opaque.</p>
<h3 id="TreeBuilder-Objects"><a href="#TreeBuilder-Objects" class="headerlink" title="TreeBuilder Objects"></a>TreeBuilder Objects</h3><h4 id="class-xml-etree-ElementTree-TreeBuilder-element-factory-None"><a href="#class-xml-etree-ElementTree-TreeBuilder-element-factory-None" class="headerlink" title="class xml.etree.ElementTree.TreeBuilder(element_factory=None)"></a>class xml.etree.ElementTree.TreeBuilder(element_factory=None)</h4><p>&emsp;&emsp;Generic <code>element</code> structure <code>builder</code>. This builder converts a sequence of start, data, and end method calls to a <code>well-formed</code> element structure. You can use this class to build an <code>element</code> structure using a custom <code>XML</code> parser, or a parser for some other <code>XML-like</code> format. <code>element_factory</code>, when given, must be a callable accepting two positional arguments: a <code>tag</code> and a <code>dict</code> of attributes. It is expected to return a new <code>element</code> instance.<br>&emsp;&emsp;<code>close()</code>: Flushes the builder buffers, and returns the toplevel document <code>element</code>. Returns an <code>Element</code> instance.<br>&emsp;&emsp;<code>data(data)</code>: Adds text to the current <code>element</code>. <code>data</code> is a string. This should be either a <code>bytestring</code>, or a <code>Unicode</code> string.<br>&emsp;&emsp;<code>end(tag)</code>: Closes the current <code>element</code>. <code>tag</code> is the <code>element</code> name. Returns the closed element.<br>&emsp;&emsp;<code>start(tag, attrs)</code>: Opens a new <code>element</code>. <code>tag</code> is the <code>element</code> name. <code>attrs</code> is a dictionary containing <code>element</code> attributes. Returns the opened <code>element</code>.<br>&emsp;&emsp;In addition, a custom <code>TreeBuilder</code> object can provide the following method:<br>&emsp;&emsp;<code>doctype(name, pubid, system)</code>: Handles a <code>doctype</code> declaration. <code>name</code> is the <code>doctype</code> name. <code>pubid</code> is the <code>public</code> identifier. <code>system</code> is the <code>system</code> identifier. This method does not exist on the default <code>TreeBuilder</code> class.</p>
<h3 id="XMLParser-Objects"><a href="#XMLParser-Objects" class="headerlink" title="XMLParser Objects"></a>XMLParser Objects</h3><h4 id="class-xml-etree-ElementTree-XMLParser-html-0-target-None-encoding-None"><a href="#class-xml-etree-ElementTree-XMLParser-html-0-target-None-encoding-None" class="headerlink" title="class xml.etree.ElementTree.XMLParser(html=0, target=None, encoding=None)"></a>class xml.etree.ElementTree.XMLParser(html=0, target=None, encoding=None)</h4><p>&emsp;&emsp;This class is the <code>low-level</code> building block of the module. It uses <code>xml.parsers.expat</code> for efficient, <code>event-based</code> parsing of <code>XML</code>. It can be fed <code>XML</code> data incrementally with the <code>feed()</code> method, and parsing events are translated to a push <code>API</code> - by invoking callbacks on the <code>target</code> object. If <code>target</code> is omitted, the standard <code>TreeBuilder</code> is used. The html argument was historically used for backwards compatibility and is now deprecated. If <code>encoding</code> is given, the value overrides the <code>encoding</code> specified in the <code>XML</code> file.<br>&emsp;&emsp;Deprecated since version <code>3.4</code>: The html argument. The remaining arguments should be passed via keyword to prepare for the removal of the html argument.<br>&emsp;&emsp;<code>close()</code>: Finishes feeding data to the <code>parser</code>. Returns the result of calling the <code>close()</code> method of the <code>target</code> passed during construction; by default, this is the toplevel document element.<br>&emsp;&emsp;<code>doctype(name, pubid, system)</code>: Deprecated since version <code>3.2</code>: Define the <code>TreeBuilder.doctype()</code> method on a custom <code>TreeBuilder</code> target.<br>&emsp;&emsp;<code>feed(data)</code>: Feeds <code>data</code> to the <code>parser</code>. <code>data</code> is encoded <code>data</code>.<br>&emsp;&emsp;<code>XMLParser.feed()</code> calls target’s <code>start(tag, attrs_dict)</code> method for each opening tag, its <code>end(tag)</code> method for each closing tag, and data is processed by method <code>data(data)</code>. <code>XMLParser.close()</code> calls target’s method <code>close()</code>. <code>XMLParser</code> can be used not only for building a tree structure. This is an example of counting the maximum depth of an <code>XML</code> file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> xml.etree.ElementTree <span class="keyword">import</span> XMLParser</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">MaxDepth</span>:</span>  <span class="comment"># The target object of the parser</span></span><br><span class="line"><span class="meta">... </span>    maxDepth = <span class="number">0</span></span><br><span class="line"><span class="meta">... </span>    depth = <span class="number">0</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, tag, attrib)</span>:</span>  <span class="comment"># Called for each opening tag.</span></span><br><span class="line"><span class="meta">... </span>        self.depth += <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> self.depth &gt; self.maxDepth:</span><br><span class="line"><span class="meta">... </span>            self.maxDepth = self.depth</span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">end</span><span class="params">(self, tag)</span>:</span>  <span class="comment"># Called for each closing tag.</span></span><br><span class="line"><span class="meta">... </span>        self.depth -= <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">data</span><span class="params">(self, data)</span>:</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">pass</span>  <span class="comment"># We do not need to do anything with data.</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span>  <span class="comment"># Called when all data has been parsed.</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> self.maxDepth</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = MaxDepth()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser = XMLParser(target=target)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>exampleXml = <span class="string">"""</span></span><br><span class="line"><span class="string"><span class="meta">... </span>&lt;a&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>  &lt;b&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>  &lt;/b&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>  &lt;b&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    &lt;c&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>      &lt;d&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>      &lt;/d&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>    &lt;/c&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>  &lt;/b&gt;</span></span><br><span class="line"><span class="string"><span class="meta">... </span>&lt;/a&gt;"""</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser.feed(exampleXml)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parser.close()</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>
<h3 id="XMLPullParser-Objects"><a href="#XMLPullParser-Objects" class="headerlink" title="XMLPullParser Objects"></a>XMLPullParser Objects</h3><h4 id="class-xml-etree-ElementTree-XMLPullParser-events-None"><a href="#class-xml-etree-ElementTree-XMLPullParser-events-None" class="headerlink" title="class xml.etree.ElementTree.XMLPullParser(events=None)"></a>class xml.etree.ElementTree.XMLPullParser(events=None)</h4><p>&emsp;&emsp;A <code>pull parser</code> suitable for <code>non-blocking</code> applications. Its <code>input-side API</code> is similar to that of <code>XMLParser</code>, but instead of pushing calls to a callback target, <code>XMLPullParser</code> collects an internal list of parsing <code>events</code> and lets the user read from it. <code>events</code> is a sequence of <code>events</code> to report back. The supported <code>events</code> are the strings <code>start</code>, <code>end</code>, <code>start-ns</code> and <code>end-ns</code> (the <code>ns</code> events are used to get detailed namespace information). If <code>events</code> is omitted, only <code>end</code> events are reported.<br>&emsp;&emsp;<code>feed(data)</code>: Feed the given <code>bytes data</code> to the <code>parser</code>.<br>&emsp;&emsp;<code>close()</code>: Signal the <code>parser</code> that the data stream is terminated. Unlike <code>XMLParser.close()</code>, this method always returns <code>None</code>. Any events not yet retrieved when the <code>parser</code> is closed can still be read with <code>read_events()</code>.<br>&emsp;&emsp;<code>read_events()</code>: Return an iterator over the <code>events</code> which have been encountered in the data fed to the <code>parser</code>. The iterator yields <code>(event, elem)</code> pairs, where <code>event</code> is a string representing the type of <code>event</code> (e.g. <code>end</code>) and <code>elem</code> is the encountered <code>Element</code> object.<br>&emsp;&emsp;<code>Events</code> provided in a previous call to <code>read_events()</code> will not be yielded again. <code>Events</code> are consumed from the internal queue only when they are retrieved from the iterator, so multiple readers iterating in parallel over iterators obtained from <code>read_events()</code> will have unpredictable results.<br>&emsp;&emsp;<strong>Note</strong>: <code>XMLPullParser</code> only guarantees that it has seen the <code>&gt;</code> character of a starting tag when it emits a <code>start</code> event, so the attributes are defined, but the contents of the text and tail attributes are undefined at that point. The same applies to the <code>element</code> children; they may or may not be present. If you need a fully populated <code>element</code>, look for <code>end</code> events instead.</p>
<h3 id="Exceptions"><a href="#Exceptions" class="headerlink" title="Exceptions"></a>Exceptions</h3><h4 id="class-xml-etree-ElementTree-ParseError"><a href="#class-xml-etree-ElementTree-ParseError" class="headerlink" title="class xml.etree.ElementTree.ParseError"></a>class xml.etree.ElementTree.ParseError</h4><p>&emsp;&emsp;<code>XML</code> parse error, raised by the various parsing methods in this module when parsing fails. The string representation of an instance of this exception will contain a <code>user-friendly</code> error message. In addition, it will have the following <code>attributes</code> available:<br>&emsp;&emsp;<code>code</code>: A numeric error <code>code</code> from the expat <code>parser</code>. See the documentation of <code>xml.parsers.expat</code> for the list of error codes and their meanings.<br>&emsp;&emsp;<code>position</code>: A tuple of line, column numbers, specifying where the error occurred.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/12/Python语法/sqlite3模块/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/12/Python语法/sqlite3模块/" itemprop="url">sqlite3模块</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-12T10:15:33+08:00">
                2019-01-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>SQLite3</code>可使用<code>sqlite3</code>模块与<code>Python</code>进行集成。它提供了一个与<code>PEP 249</code>描述的<code>DB-API 2.0</code>规范兼容的<code>SQL</code>接口。不需要单独安装该模块，因为<code>Python 2.5</code>以上版本默认自带了该模块。为了使用<code>sqlite3</code>模块，首先必须创建一个表示数据库的连接对象，然后可以有选择地创建光标对象，这将帮助你执行所有的<code>SQL</code>语句。</p>
<h3 id="sqlite3模块API"><a href="#sqlite3模块API" class="headerlink" title="sqlite3模块API"></a>sqlite3模块API</h3><p>&emsp;&emsp;以下是重要的<code>sqlite3</code>模块<code>API</code>，可以满足你在<code>Python</code>程序中使用<code>SQLite</code>数据库的需求。</p>
<h4 id="connect"><a href="#connect" class="headerlink" title="connect"></a>connect</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlite3.connect(database [, timeout, other optional arguments])</span><br></pre></td></tr></table></figure>
<p>该<code>API</code>打开一个到<code>SQLite</code>数据库文件<code>database</code>的链接。你可以使用<code>:memory:</code>来在<code>RAM</code>中打开一个到<code>database</code>的数据库连接，而不是在磁盘上打开。如果数据库成功打开，则返回一个连接对象。<br>&emsp;&emsp;当一个数据库被多个连接访问，且其中一个修改了数据库，此时<code>SQLite</code>数据库被锁定，直到事务提交。<code>timeout</code>参数表示连接等待锁定的持续时间，直到发生异常断开连接。<code>timeout</code>参数默认是<code>5.0</code>(<code>5</code>秒)。<br>&emsp;&emsp;如果给定的数据库名称<code>filename</code>不存在，则该调用将创建一个数据库。如果不想在当前目录中创建数据库，可以指定带有路径的文件名，这样就能在任意地方创建数据库。</p>
<h4 id="cursor"><a href="#cursor" class="headerlink" title="cursor"></a>cursor</h4><p>&emsp;&emsp;该方法用于创建一个<code>cursor</code>，将在<code>Python</code>数据库编程中用到。该方法接受一个单一的可选的参数<code>cursorClass</code>。如果提供了该参数，则它必须是一个扩展自<code>sqlite3.Cursor</code>的自定义<code>cursor</code>类。</p>
<h4 id="cursor-execute"><a href="#cursor-execute" class="headerlink" title="cursor.execute"></a>cursor.execute</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.execute(sql [, optional parameters])</span><br></pre></td></tr></table></figure>
<p>该例程执行一个<code>SQL</code>语句。该<code>SQL</code>语句可以被参数化(也就是使用占位符代替<code>SQL</code>文本)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.execute(<span class="string">"insert into people values (?, ?)"</span>, (who, age))</span><br></pre></td></tr></table></figure>
<h4 id="connection-execute"><a href="#connection-execute" class="headerlink" title="connection.execute"></a>connection.execute</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.execute(sql [, optional parameters])</span><br></pre></td></tr></table></figure>
<p>该例程是上面执行的由光标(<code>cursor</code>)对象提供的方法的快捷方式，它通过调用光标(<code>cursor</code>)方法创建了一个中间的光标对象，然后通过给定的参数调用光标的<code>execute</code>方法。</p>
<h4 id="cursor-executemany"><a href="#cursor-executemany" class="headerlink" title="cursor.executemany"></a>cursor.executemany</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.executemany(sql, seq_of_parameters)</span><br></pre></td></tr></table></figure>
<p>该例程对<code>seq_of_parameters</code>中的所有参数或映射执行一个<code>SQL</code>命令。</p>
<h4 id="connection-executemany"><a href="#connection-executemany" class="headerlink" title="connection.executemany"></a>connection.executemany</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.executemany(sql[, parameters])</span><br></pre></td></tr></table></figure>
<p>该例程是一个由调用光标(<code>cursor</code>)方法创建的中间的光标对象的快捷方式，然后通过给定的参数调用光标的<code>executemany</code>方法。</p>
<h4 id="cursor-executescript"><a href="#cursor-executescript" class="headerlink" title="cursor.executescript"></a>cursor.executescript</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.executescript(sql_script)</span><br></pre></td></tr></table></figure>
<p>该例程一旦接收到脚本，会执行多个<code>SQL</code>语句。它首先执行<code>COMMIT</code>语句，然后执行作为参数传入的<code>SQL</code>脚本。所有的<code>SQL</code>语句应该用分号<code>;</code>分隔。</p>
<h4 id="connection-executescript"><a href="#connection-executescript" class="headerlink" title="connection.executescript"></a>connection.executescript</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.executescript(sql_script)</span><br></pre></td></tr></table></figure>
<p>该例程是一个由调用光标(<code>cursor</code>)方法创建的中间的光标对象的快捷方式，然后通过给定的参数调用光标的<code>executescript</code>方法。</p>
<h4 id="total-changes"><a href="#total-changes" class="headerlink" title="total_changes"></a>total_changes</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.total_changes()</span><br></pre></td></tr></table></figure>
<p>该例程返回自数据库连接打开以来被修改、插入或删除的数据库总行数。</p>
<h4 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.commit()</span><br></pre></td></tr></table></figure>
<p>该方法提交当前的事务。如果未调用该方法，那么自上一次调用<code>commit</code>以来所做的任何动作对其他数据库连接来说是不可见的。</p>
<h4 id="rollback"><a href="#rollback" class="headerlink" title="rollback"></a>rollback</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.rollback()</span><br></pre></td></tr></table></figure>
<p>该方法回滚自上一次调用<code>commit</code>以来对数据库所做的更改。</p>
<h4 id="close"><a href="#close" class="headerlink" title="close"></a>close</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connection.close()</span><br></pre></td></tr></table></figure>
<p>该方法关闭数据库连接。请注意，这不会自动调用<code>commit</code>。如果之前未调用<code>commit</code>方法，就直接关闭数据库连接，你所做的所有更改将全部丢失！</p>
<h4 id="fetchone"><a href="#fetchone" class="headerlink" title="fetchone"></a>fetchone</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.fetchone()</span><br></pre></td></tr></table></figure>
<p>该方法获取查询结果集中的下一行，返回一个单一的序列，当没有更多可用的数据时，则返回<code>None</code>。</p>
<h4 id="fetchmany"><a href="#fetchmany" class="headerlink" title="fetchmany"></a>fetchmany</h4><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cursor.fetchmany([size=cursor.arraysize])</span><br></pre></td></tr></table></figure>
<p>该方法获取查询结果集中的下一行组，返回一个列表。当没有更多的可用的行时，则返回一个空的列表。该方法尝试获取由<code>size</code>参数指定的尽可能多的行。</p>
<h3 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h3><p>&emsp;&emsp;下面的<code>Python</code>代码显示了如何连接到一个现有的数据库。如果数据库不存在，那么它就会被创建，最后将返回一个数据库对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br></pre></td></tr></table></figure>
<p>在这里，您也可以把数据库名称赋值为特定的名称<code>:memory:</code>，这样就会在<code>RAM</code>中创建一个数据库。现在来运行上面的程序，在当前目录中创建数据库<code>test.db</code>。</p>
<h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><p>&emsp;&emsp;下面的<code>Python</code>代码段将用于在先前创建的数据库中创建一个表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">c.execute(<span class="string">'''CREATE TABLE COMPANY</span></span><br><span class="line"><span class="string">       (ID INT PRIMARY KEY     NOT NULL,</span></span><br><span class="line"><span class="string">        NAME           TEXT    NOT NULL,</span></span><br><span class="line"><span class="string">        AGE            INT     NOT NULL,</span></span><br><span class="line"><span class="string">        ADDRESS        CHAR(50),</span></span><br><span class="line"><span class="string">        SALARY         REAL);'''</span>)</span><br><span class="line">print(<span class="string">"Table created successfully"</span>)</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
<p>上述程序执行时，它会在<code>test.db</code>中创建<code>COMPANY</code>表，并显示如下消息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Opened database successfully</span><br><span class="line">Table created successfully</span><br></pre></td></tr></table></figure>
<h3 id="INSERT操作"><a href="#INSERT操作" class="headerlink" title="INSERT操作"></a>INSERT操作</h3><p>&emsp;&emsp;下面显示了如何在上面创建的<code>COMPANY</code>表中创建记录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br><span class="line">c.execute(<span class="string">"INSERT INTO COMPANY (ID, NAME, AGE, ADDRESS, SALARY) \</span></span><br><span class="line"><span class="string">           VALUES (1, 'Paul', 32, 'California', 20000.00)"</span>)</span><br><span class="line">c.execute(<span class="string">"INSERT INTO COMPANY (ID, NAME, AGE, ADDRESS, SALARY) \</span></span><br><span class="line"><span class="string">           VALUES (2, 'Allen', 25, 'Texas', 15000.00)"</span>)</span><br><span class="line">c.execute(<span class="string">"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \</span></span><br><span class="line"><span class="string">           VALUES (3, 'Teddy', 23, 'Norway', 20000.00)"</span>)</span><br><span class="line">c.execute(<span class="string">"INSERT INTO COMPANY (ID, NAME, AGE, ADDRESS, SALARY) \</span></span><br><span class="line"><span class="string">           VALUES (4, 'Mark', 25, 'Rich-Mond', 65000.00)"</span>)</span><br><span class="line">conn.commit()</span><br><span class="line">print(<span class="string">"Records created successfully"</span>)</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
<p>上述程序执行时，它会在COMPANY表中创建给定记录，并会显示如下信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Opened database successfully</span><br><span class="line">Records created successfully</span><br></pre></td></tr></table></figure>
<h3 id="SELECT操作"><a href="#SELECT操作" class="headerlink" title="SELECT操作"></a>SELECT操作</h3><p>&emsp;&emsp;下面显示了如何从前面创建的<code>COMPANY</code>表中获取并显示记录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br><span class="line">​</span><br><span class="line">cursor = c.execute(<span class="string">"SELECT id, name, address, salary  from COMPANY"</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> cursor:</span><br><span class="line">    print(<span class="string">"ID ="</span>, row[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">"NAME ="</span>, row[<span class="number">1</span>])</span><br><span class="line">    print(<span class="string">"ADDRESS ="</span>, row[<span class="number">2</span>])</span><br><span class="line">    print(<span class="string">"SALARY ="</span>, row[<span class="number">3</span>])</span><br><span class="line">    print(<span class="string">"----------"</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"Operation done successfully"</span>)</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Opened database successfully</span><br><span class="line">ID = <span class="number">1</span></span><br><span class="line">NAME = Paul</span><br><span class="line">ADDRESS = California</span><br><span class="line">SALARY = <span class="number">20000.0</span></span><br><span class="line">----------</span><br><span class="line">ID = <span class="number">2</span></span><br><span class="line">NAME = Allen</span><br><span class="line">ADDRESS = Texas</span><br><span class="line">SALARY = <span class="number">15000.0</span></span><br><span class="line">----------</span><br><span class="line">ID = <span class="number">3</span></span><br><span class="line">NAME = Teddy</span><br><span class="line">ADDRESS = Norway</span><br><span class="line">SALARY = <span class="number">20000.0</span></span><br><span class="line">----------</span><br><span class="line">ID = <span class="number">4</span></span><br><span class="line">NAME = Mark</span><br><span class="line">ADDRESS = Rich-Mond</span><br><span class="line">SALARY = <span class="number">65000.0</span></span><br><span class="line">----------</span><br><span class="line">Operation done successfully</span><br></pre></td></tr></table></figure>
<h3 id="UPDATE操作"><a href="#UPDATE操作" class="headerlink" title="UPDATE操作"></a>UPDATE操作</h3><p>&emsp;&emsp;下面显示了如何使用<code>UPDATE</code>语句来更新任何记录，然后从<code>COMPANY</code>表中获取并显示更新的记录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br><span class="line">​</span><br><span class="line">c.execute(<span class="string">"UPDATE COMPANY set SALARY = 25000.00 where ID=1"</span>)</span><br><span class="line">conn.commit()</span><br><span class="line">print(<span class="string">"Total number of rows updated :"</span>, conn.total_changes)</span><br><span class="line">​</span><br><span class="line">cursor = conn.execute(<span class="string">"SELECT id, name, address, salary from COMPANY"</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> cursor:</span><br><span class="line">    print(<span class="string">"ID ="</span>, row[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">"NAME = "</span>, row[<span class="number">1</span>])</span><br><span class="line">    print(<span class="string">"ADDRESS = "</span>, row[<span class="number">2</span>])</span><br><span class="line">    print(<span class="string">"SALARY = "</span>, row[<span class="number">3</span>], <span class="string">"\n"</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"Operation done successfully"</span>)</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
<h3 id="DELETE操作"><a href="#DELETE操作" class="headerlink" title="DELETE操作"></a>DELETE操作</h3><p>&emsp;&emsp;下面显示了如何使用<code>DELETE</code>语句删除任何记录，然后从<code>COMPANY</code>表中获取并显示剩余的记录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line">​</span><br><span class="line">conn = sqlite3.connect(<span class="string">'test.db'</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">print(<span class="string">"Opened database successfully"</span>)</span><br><span class="line">​</span><br><span class="line">c.execute(<span class="string">"DELETE from COMPANY where ID=2;"</span>)</span><br><span class="line">conn.commit()</span><br><span class="line">print(<span class="string">"Total number of rows deleted :"</span>, conn.total_changes)</span><br><span class="line">​</span><br><span class="line">cursor = conn.execute(<span class="string">"SELECT id, name, address, salary  from COMPANY"</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> cursor:</span><br><span class="line">    print(<span class="string">"ID ="</span>, row[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">"NAME ="</span>, row[<span class="number">1</span>])</span><br><span class="line">    print(<span class="string">"ADDRESS ="</span>, row[<span class="number">2</span>])</span><br><span class="line">    print(<span class="string">"SALARY = "</span>, row[<span class="number">3</span>], <span class="string">"\n"</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"Operation done successfully"</span>)</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/12/Python语法/模块和包/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/12/Python语法/模块和包/" itemprop="url">模块和包</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-12T09:24:26+08:00">
                2019-01-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><p>&emsp;&emsp;容器是数据的封装，函数是语句的封装，类是方法和属性的封装，模块是模块就是程序。<br>&emsp;&emsp;在使用模块时，要注意命名空间。在<code>hi.py</code>中输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"hello"</span>)</span><br></pre></td></tr></table></figure>
<p>在终端输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hi</span><br><span class="line">hi()  <span class="comment"># 结果将会报错</span></span><br><span class="line">hi.hello()  <span class="comment"># 结果为“hello”</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;导入模块的三个方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> 模块名</span><br><span class="line"><span class="keyword">from</span> 模块名 <span class="keyword">import</span> 函数名</span><br><span class="line"><span class="keyword">import</span> 模块名 <span class="keyword">as</span> 新名字</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在<code>Temp.py</code>中输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">c2f</span><span class="params">(cel)</span>:</span></span><br><span class="line">    fah = cel * <span class="number">1.8</span> + <span class="number">32</span></span><br><span class="line">    <span class="keyword">return</span> fah</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f2c</span><span class="params">(fah)</span>:</span></span><br><span class="line">    cel = (fah - <span class="number">32</span>) / <span class="number">1.8</span></span><br><span class="line">    <span class="keyword">return</span> cel</span><br></pre></td></tr></table></figure>
<p>在<code>clac.py</code>中输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Temp</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"32摄氏度 = %.2f华氏度"</span> % Temp.c2f(<span class="number">32</span>))</span><br><span class="line">print(<span class="string">"99华氏度 = %.2f摄氏度"</span> % Temp.f2c(<span class="number">99</span>))</span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="keyword">from</span> Temp <span class="keyword">import</span> c2f, f2c  <span class="comment"># 写成“from Temp import *”也是可以的，但不推荐</span></span><br><span class="line">​</span><br><span class="line">print(<span class="string">"32摄氏度 = %.2f华氏度"</span> % c2f(<span class="number">32</span>))</span><br><span class="line">print(<span class="string">"99华氏度 = %.2f摄氏度"</span> % f2c(<span class="number">99</span>))</span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="keyword">import</span> Temp <span class="keyword">as</span> tc</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"32摄氏度 = %.2f华氏度"</span> % tc.c2f(<span class="number">32</span>))</span><br><span class="line">print(<span class="string">"99华氏度 = %.2f摄氏度"</span> % tc.f2c(<span class="number">99</span>))</span><br></pre></td></tr></table></figure>
<p>注意，模块文件要放在与源文件一样的路径下！</p>
<h3 id="if-name-‘main‘"><a href="#if-name-‘main‘" class="headerlink" title="if __name__ == ‘main‘"></a>if __name__ == ‘<strong>main</strong>‘</h3><p>&emsp;&emsp;在<code>Temp.py</code>中输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">c2f</span><span class="params">(cel)</span>:</span></span><br><span class="line">    fah = cel * <span class="number">1.8</span> + <span class="number">32</span></span><br><span class="line">    <span class="keyword">return</span> fah</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f2c</span><span class="params">(fah)</span>:</span></span><br><span class="line">    cel = (fah - <span class="number">32</span>) / <span class="number">1.8</span></span><br><span class="line">    <span class="keyword">return</span> cel</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"0摄氏度 = %.2f华氏度"</span> % c2f(<span class="number">0</span>))</span><br><span class="line">    print(<span class="string">"0华氏度 = %.2f摄氏度"</span> % f2c(<span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line">test()</span><br></pre></td></tr></table></figure>
<p>在<code>calc.py</code>中输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Temp <span class="keyword">as</span> tc</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"32摄氏度 = %.2f华氏度"</span> % tc.c2f(<span class="number">32</span>))</span><br><span class="line">print(<span class="string">"99华氏度 = %.2f摄氏度"</span> % tc.f2c(<span class="number">99</span>))</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>摄氏度 = <span class="number">32.00</span>华氏度</span><br><span class="line"><span class="number">0</span>华氏度 = <span class="number">-17.78</span>摄氏度</span><br><span class="line"><span class="number">32</span>摄氏度 = <span class="number">89.60</span>华氏度</span><br><span class="line"><span class="number">99</span>华氏度 = <span class="number">37.22</span>摄氏度</span><br></pre></td></tr></table></figure>
<p>有时候我们希望模块中的测试程序只有在测试模块时被执行，在模块加载进执行应用程序时不被执行，可以加上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br></pre></td></tr></table></figure>
<p>于是模块文件可以改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>
<p>在执行应用程序时，在终端输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__name__  <span class="comment"># 结果为“__main__”</span></span><br><span class="line">tc.__name__  <span class="comment"># 结果为“Temp”</span></span><br></pre></td></tr></table></figure>
<p>在执行模块程序时，在终端输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__name__  <span class="comment"># 结果为'__main__'</span></span><br></pre></td></tr></table></figure>
<p>即执行哪个程序，那一个程序的<code>name</code>为<code>main</code>。</p>
<h3 id="包"><a href="#包" class="headerlink" title="包"></a>包</h3><p>&emsp;&emsp;创建<code>包</code>(<code>package</code>)的方法：创建一个文件夹，用于存放相关的模块，文件夹的名字就是包的名字；在文件夹中创建一个<code>__init__.py</code>的模块文件，内容可以为空。<br>&emsp;&emsp;具体使用方法：在当前文件夹下创建一个文件夹<code>M1</code>，把<code>Temp.py</code>放入<code>M1</code>文件夹，并在<code>M1</code>文件夹中创建一个空文件<code>__init__.py</code>。把应用程序改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> M1.Temp <span class="keyword">as</span> tc</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"32摄氏度 = %.2f华氏度"</span> % tc.c2f(<span class="number">32</span>))</span><br><span class="line">print(<span class="string">"99华氏度 = %.2f摄氏度"</span> % tc.f2c(<span class="number">99</span>))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/11/Python语法/运算符重载/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/11/Python语法/运算符重载/" itemprop="url">运算符重载</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-11T22:01:32+08:00">
                2019-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>Python</code>的对象天生拥有一些神奇的方法，这些方法总被双下划线所包围，是面向对象的<code>Python</code>的一切。它们是可以给你的类增加魔力的特殊方法，如果你的对象实现(<code>重载</code>)了这些方法中的某一个，那么这个方法就会在特殊的情况下被<code>Python</code>所调用，你可以定义自己想要的行为，而这一切都是自动发生的。<br>&emsp;&emsp;基本的魔法方法如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__new__(cls[, ...])</code></td>
<td>1. <code>__new__</code>是在一个对象实例化的时候所调用的第一个方法<br>2.它的第一个参数是这个类，其他的参数是用来直接传递给<code>__init__</code>方法<br>3. <code>__new__</code>决定是否要使用该<code>__init__</code>方法，因为<code>__new__</code>可以调用其他类的构造方法或者直接返回别的实例对象来作为本类的实例，如果<code>__new__</code>没有返回实例对象，则<code>__init__</code>不会被调用<br>4. <code>__new__</code>主要是用于继承一个不可变的类型，比如一个<code>tuple</code>或者<code>string</code></td>
</tr>
<tr>
<td><code>__init__(self[, ...])</code></td>
<td>构造器，当一个实例被创建的时候调用的初始化方法</td>
</tr>
<tr>
<td><code>__del__(self)</code></td>
<td>析构器，当一个实例被销毁的时候调用的方法</td>
</tr>
<tr>
<td><code>__call__(self[, args...])</code></td>
<td>允许一个类的实例像函数一样被调用：<code>x(a, b)</code>调用<code>x.__call__(a, b)</code></td>
</tr>
<tr>
<td><code>__len__(self)</code></td>
<td>定义当被<code>len</code>调用时的行为</td>
</tr>
<tr>
<td><code>__repr__(self)</code></td>
<td>定义当被<code>repr</code>调用时的行为</td>
</tr>
<tr>
<td><code>__str__(self)</code></td>
<td>定义当被<code>str</code>调用时的行为</td>
</tr>
<tr>
<td><code>__bytes__(self)</code></td>
<td>定义当被<code>bytes</code>调用时的行为</td>
</tr>
<tr>
<td><code>__hash__(self)</code></td>
<td>定义当被<code>hash</code>调用时的行为</td>
</tr>
<tr>
<td><code>__bool__(self)</code></td>
<td>定义当被<code>bool</code>调用时的行为，应该返回<code>True</code>或<code>False</code></td>
</tr>
<tr>
<td><code>__format__(self, format_spec)</code></td>
<td>定义当被<code>format</code>调用时的行为</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;有关属性的方法如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__getattr__(self, name)</code></td>
<td>定义当用户试图获取一个不存在的属性时的行为</td>
</tr>
<tr>
<td><code>__getattribute__(self, name)</code></td>
<td>定义当该类的属性被访问时的行为</td>
</tr>
<tr>
<td><code>__setattr__(self, name, value)</code></td>
<td>定义当一个属性被设置时的行为</td>
</tr>
<tr>
<td><code>__delattr__(self, name)</code></td>
<td>定义当一个属性被删除时的行为</td>
</tr>
<tr>
<td><code>__dir__(self)</code></td>
<td>定义当<code>dir</code>被调用时的行为</td>
</tr>
<tr>
<td><code>__get__(self, instance, owner)</code></td>
<td>定义当描述符的值被取得时的行为</td>
</tr>
<tr>
<td><code>__set__(self, instance, value)</code></td>
<td>定义当描述符的值被改变时的行为</td>
</tr>
<tr>
<td><code>__delete__(self, instance)</code></td>
<td>定义当描述符的值被删除时的行为</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;比较操作符如下所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__lt__(self, other)</code></td>
<td>定义小于号的行为：<code>x &lt; y</code>调用<code>x.__lt__(y)</code></td>
</tr>
<tr>
<td><code>__le__(self, other)</code></td>
<td>定义小于等于号的行为：<code>x &lt;= y</code>调用<code>x.__le__(y)</code></td>
</tr>
<tr>
<td><code>__eq__(self, other)</code></td>
<td>定义等于号的行为：<code>x == y</code>调用<code>x.__eq__(y)</code></td>
</tr>
<tr>
<td><code>__ne__(self, other)</code></td>
<td>定义不等号的行为：<code>x != y</code>调用<code>x.__ne__(y)</code></td>
</tr>
<tr>
<td><code>__gt__(self, other)</code></td>
<td>定义大于号的行为：<code>x &gt; y</code>调用<code>x.__gt__(y)</code></td>
</tr>
<tr>
<td><code>__ge__(self, other)</code></td>
<td>定义大于等于号的行为：<code>x &gt;= y</code>调用<code>x.__ge__(y)</code></td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;算数运算符如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__add__(self, other)</code></td>
<td>定义加法的行为<code>+</code></td>
</tr>
<tr>
<td><code>__sub__(self, other)</code></td>
<td>定义减法的行为<code>-</code></td>
</tr>
<tr>
<td><code>__mul__(self, other)</code></td>
<td>定义乘法的行为<code>*</code></td>
</tr>
<tr>
<td><code>__truediv__(self, other)</code></td>
<td>定义真除法的行为<code>/</code></td>
</tr>
<tr>
<td><code>__floordiv__(self, other)</code></td>
<td>定义整数除法的行为<code>//</code></td>
</tr>
<tr>
<td><code>__mod__(self, other)</code></td>
<td>定义取模算法的行为<code>%</code></td>
</tr>
<tr>
<td><code>__divmod__(self, other)</code></td>
<td>定义当被<code>divmod</code>调用时的行为</td>
</tr>
<tr>
<td><code>__pow__(self, other[, modulo])</code></td>
<td>定义当被<code>power</code>调用或<code>**</code>运算时的行为</td>
</tr>
<tr>
<td><code>__lshift__(self, other)</code></td>
<td>定义按位左移位的行为<code>&lt;&lt;</code></td>
</tr>
<tr>
<td><code>__rshift__(self, other)</code></td>
<td>定义按位右移位的行为<code>&gt;&gt;</code></td>
</tr>
<tr>
<td><code>__and__(self, other)</code></td>
<td>定义按位与操作的行为<code>&amp;</code></td>
</tr>
<tr>
<td><code>__xor__(self, other)</code></td>
<td>定义按位异或操作的行为<code>^</code></td>
</tr>
<tr>
<td><code>__or__(self, other)</code></td>
<td>定义按位或操作的行为<code>&#124;</code></td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;反运算如下所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__radd__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rsub__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rmul__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rtruediv__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rfloordiv__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rmod__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rdivmod__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rpow__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rlshift__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rrshift__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rand__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__rxor__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
<tr>
<td><code>__ror__(self, other)</code></td>
<td>与上方相同，当左操作数不支持相应的操作时被调用</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;增量赋值运算如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__iadd__(self, other)</code></td>
<td>定义赋值加法的行为<code>+=</code></td>
</tr>
<tr>
<td><code>__isub__(self, other)</code></td>
<td>定义赋值减法的行为<code>-=</code></td>
</tr>
<tr>
<td><code>__imul__(self, other)</code></td>
<td>定义赋值乘法的行为<code>*=</code></td>
</tr>
<tr>
<td><code>__itruediv__(self, other)</code></td>
<td>定义赋值真除法的行为<code>/=</code></td>
</tr>
<tr>
<td><code>__ifloordiv__(self, other)</code></td>
<td>定义赋值整数除法的行为<code>//=</code></td>
</tr>
<tr>
<td><code>__imod__(self, other)</code></td>
<td>定义赋值取模算法的行为<code>%=</code></td>
</tr>
<tr>
<td><code>__ipow__(self, other[, modulo])</code></td>
<td>定义赋值幂运算的行为<code>**=</code></td>
</tr>
<tr>
<td><code>__ilshift__(self, other)</code></td>
<td>定义赋值按位左移位的行为<code>&lt;&lt;=</code></td>
</tr>
<tr>
<td><code>__irshift__(self, other)</code></td>
<td>定义赋值按位右移位的行为<code>&gt;&gt;=</code></td>
</tr>
<tr>
<td><code>__iand__(self, other)</code></td>
<td>定义赋值按位与操作的行为<code>&amp;=</code></td>
</tr>
<tr>
<td><code>__ixor__(self, other)</code></td>
<td>定义赋值按位异或操作的行为<code>^=</code></td>
</tr>
<tr>
<td><code>__ior__(self, other)</code></td>
<td>定义赋值按位或操作的行为<code>&#124;=</code></td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;一元操作符如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__pos__(self)</code></td>
<td>定义正号的行为<code>+x</code></td>
</tr>
<tr>
<td><code>__neg__(self)</code></td>
<td>定义负号的行为<code>-x</code></td>
</tr>
<tr>
<td><code>__abs__(self)</code></td>
<td>定义当被<code>abs</code>调用时的行为</td>
</tr>
<tr>
<td><code>__invert__(self)</code></td>
<td>定义按位求反的行为<code>~x</code></td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;类型转换如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__complex__(self)</code></td>
<td>定义当被<code>complex</code>调用时的行为(需要返回恰当的值)</td>
</tr>
<tr>
<td><code>__int__(self)</code></td>
<td>定义当被<code>int</code>调用时的行为(需要返回恰当的值)</td>
</tr>
<tr>
<td><code>__float__(self)</code></td>
<td>定义当被<code>float</code>调用时的行为(需要返回恰当的值)</td>
</tr>
<tr>
<td><code>__round__(self[, n])</code></td>
<td>定义当被<code>round</code>调用时的行为(需要返回恰当的值)</td>
</tr>
<tr>
<td><code>__index__(self)</code></td>
<td>1. 当对象是被应用在切片表达式中时，实现整形强制转换<br>2. 如果你定义了一个可能在切片时用到的定制的数值型，你应该定义<code>__index__</code><br>3. 如果<code>__index__</code>被定义，则<code>__int__</code>也需要被定义，且返回相同的值</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;上下文管理(<code>with</code>语句)如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__enter__(self)</code></td>
<td>1. 定义当使用<code>with</code>语句时的初始化行为<br>2. <code>__enter__</code>的返回值被<code>with</code>语句的目标或者<code>as</code>后的名字绑定</td>
</tr>
<tr>
<td><code>__exit__(self, exc_type, exc_value, traceback)</code></td>
<td>1. 定义当一个代码块被执行或者终止后上下文管理器应该做什么<br>2. 一般被用来处理异常，清除工作或者做一些代码块执行完毕之后的日常工作</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;容器类型如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>魔法方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__len__(self)</code></td>
<td>定义当被<code>len</code>调用时的行为(返回容器中元素的个数)</td>
</tr>
<tr>
<td><code>__getitem__(self, key)</code></td>
<td>定义获取容器中指定元素的行为，相当于<code>self[key]</code></td>
</tr>
<tr>
<td><code>__setitem__(self, key, value)</code></td>
<td>定义设置容器中指定元素的行为，相当于<code>self[key] = value</code></td>
</tr>
<tr>
<td><code>__delitem__(self, key)</code></td>
<td>定义删除容器中指定元素的行为，相当于<code>del self[key]</code></td>
</tr>
<tr>
<td><code>__iter__(self)</code></td>
<td>定义当迭代容器中的元素的行为</td>
</tr>
<tr>
<td><code>__reversed__(self)</code></td>
<td>定义当被<code>reversed</code>调用时的行为</td>
</tr>
<tr>
<td><code>__contains__(self, item)</code></td>
<td>定义当使用成员测试运算符(<code>in</code>或<code>not in</code>)时的行为</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;在终端输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Try_int</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self + other</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__sub__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self - other</span><br><span class="line"></span><br><span class="line">a = Try_int(<span class="number">3</span>)</span><br><span class="line">a  <span class="comment"># 结果为3</span></span><br><span class="line">b = Try_int(<span class="number">5</span>)</span><br><span class="line">b  <span class="comment"># 结果为5</span></span><br><span class="line">a + b  <span class="comment"># 结果为“出错”，因为会进入无限递归</span></span><br></pre></td></tr></table></figure>
<p>解决方法是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Try_int</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int(self) + int(other)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__sub__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int(self) - int(other)</span><br><span class="line">​</span><br><span class="line">a = Try_int(<span class="number">3</span>)</span><br><span class="line">b = Try_int(<span class="number">5</span>)</span><br><span class="line">a + b  <span class="comment"># 结果为8</span></span><br><span class="line">a - b  <span class="comment"># 结果为“-2”</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在终端输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">int</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int.__sub__(self, other)</span><br><span class="line">​</span><br><span class="line">a = int(<span class="string">"3"</span>)</span><br><span class="line">a  <span class="comment"># 结果为3</span></span><br><span class="line">b = int(<span class="string">"5"</span>)</span><br><span class="line">b  <span class="comment"># 结果为5</span></span><br><span class="line">a + b  <span class="comment"># 结果为“-2”</span></span><br><span class="line"><span class="comment"># ----------------</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Nint</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__radd__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int.__sub__(self, other)</span><br><span class="line">​</span><br><span class="line">a = Nint(<span class="number">5</span>)</span><br><span class="line">a  <span class="comment"># 结果为5</span></span><br><span class="line">b = Nint(<span class="number">3</span>)</span><br><span class="line">b  <span class="comment"># 结果为3</span></span><br><span class="line">a + b  <span class="comment"># 结果为8</span></span><br><span class="line"><span class="number">1</span> + b  <span class="comment"># 结果为2(计算过程是“b - 1”)</span></span><br><span class="line"><span class="comment"># ----------------</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Nint</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rsub__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int.__sub__(self, other)</span><br><span class="line">​</span><br><span class="line">a = Nint(<span class="number">5</span>)</span><br><span class="line"><span class="number">3</span> - a  <span class="comment"># 结果为2(计算过程是“a - 3”)</span></span><br><span class="line"><span class="comment"># ---------------</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Nint</span><span class="params">(int)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rsub__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> int.__sub__(other, self)</span><br><span class="line">​</span><br><span class="line">a = Nint(<span class="number">5</span>)</span><br><span class="line"><span class="number">3</span> - a  <span class="comment"># 结果为“-2”(计算过程是“3 - a”)</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>__str__</code>方法会告诉<code>Python</code>打印(<code>print</code>)一个对象时具体显示什么内容。<code>Python</code>会默认显示以下内容：</p>
<ul>
<li>实例在哪里定义。</li>
<li>类名。</li>
<li>存储实例的内存位置。</li>
</ul>
<p>如果你希望<code>print</code>为对象显示其他的内容，可以定义自己的<code>__str__</code>方法，这会覆盖内置的<code>__str__</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">strtest</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"init: this is only test"</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"str: this is only test"</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    st = strtest()</span><br><span class="line">    print(st)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/11/Python语法/Python编程注意/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/11/Python语法/Python编程注意/" itemprop="url">Python编程注意</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-11T19:41:59+08:00">
                2019-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>由于<code>Python</code>没有变量的检查，在程序中可能会出现变量名近似的错误，例如将<code>girl</code>误写为<code>gril</code>。</li>
<li><code>python</code>打印序列前几个数据可以采取分片的方式，例如<code>for index in suit_list[0:5]</code>。</li>
<li>编写<code>python</code>的函数时，一定要注意<code>return</code>关键字的位置。</li>
<li><code>python</code>中还是有部分函数无法在<code>Linux</code>和<code>Windows</code>上通用，例如<code>os</code>模块中和文件或目录有关的函数。</li>
<li><code>python</code>的<code>16</code>进制示例<code>0xAF</code>，第二个字母是<code>x</code>，大小写都可以；<code>8</code>进制示例<code>0o10</code>，第二个字母是<code>o</code>，大小写都可以。</li>
<li><code>python 3</code>中没有<code>cStringIO</code>，要改为<code>io</code>；没有<code>xrange</code>，要改为<code>range</code>。</li>
<li>对于序列，序号<code>-1</code>代表最后一个元素的位置，<code>-2</code>代表倒数第二个元素的位置。</li>
<li><code>python</code>的<code>import</code>类似于<code>C</code>语言的<code>include</code>，可以把一个文件的内容引入源代码中。</li>
<li>对函数进行注释时，最好把注释的内容写到函数中，这样可以通过<code>__doc__</code>进行显示。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/11/Python语法/sys模块/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/11/Python语法/sys模块/" itemprop="url">sys模块</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-11T19:09:18+08:00">
                2019-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Python语法/" itemprop="url" rel="index">
                    <span itemprop="name">Python语法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>sys</code>模块提供了一系列有关<code>Python</code>运行环境的变量和函数。</p>
<h3 id="sys-argv"><a href="#sys-argv" class="headerlink" title="sys.argv"></a>sys.argv</h3><p>&emsp;&emsp;可以用<code>sys.argv</code>获取当前正在执行的命令行参数的列表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>变量</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>sys.argv[0]</code></td>
<td>当前程序名</td>
</tr>
<tr>
<td><code>sys.argv[1]</code></td>
<td>第一个参数</td>
</tr>
<tr>
<td><code>sys.argv[2]</code></td>
<td>第二个参数</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 获取脚本名字</span></span><br><span class="line">print(<span class="string">'The name of this program is: %s'</span> % (sys.argv[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'The command line arguments are:'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> sys.argv:  <span class="comment"># 获取参数列表</span></span><br><span class="line">    print(i)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 统计参数个数</span></span><br><span class="line">print(<span class="string">'There are %s arguments.'</span> % (len(sys.argv) - <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h3 id="sys-platform"><a href="#sys-platform" class="headerlink" title="sys.platform"></a>sys.platform</h3><p>&emsp;&emsp;用于获取当前执行环境的平台，例如<code>win32</code>表示<code>Windows</code>系统，<code>linux2</code>表示是<code>linux</code>系统：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># linux</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.platform</span><br><span class="line"><span class="string">'linux2'</span></span><br><span class="line"><span class="comment"># windows</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.platform</span><br><span class="line"><span class="string">'win32'</span></span><br></pre></td></tr></table></figure>
<p>使用该方法可以写出跨平台的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line">​</span><br><span class="line">osType = sys.platform</span><br><span class="line"><span class="keyword">if</span> osType == <span class="string">'linux'</span> <span class="keyword">or</span> osType == <span class="string">'linux2'</span>:</span><br><span class="line">    command = <span class="string">'clear'</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    command = <span class="string">'cls'</span></span><br><span class="line">​</span><br><span class="line">os.system(command)</span><br></pre></td></tr></table></figure>
<h3 id="sys-path"><a href="#sys-path" class="headerlink" title="sys.path"></a>sys.path</h3><p>&emsp;&emsp;<code>path</code>是一个目录列表，供<code>Python</code>从中查找第三方扩展模块。在<code>python</code>启动时，<code>sys.path</code>根据内建规则、<code>PYTHONPATH</code>变量进行初始化。当我们导入一个模块时(<code>import xxx</code>)，默认情况下<code>python</code>解析器会搜索当前目录、已安装的内置模块和第三方模块，搜索路径存放在<code>sys</code>模块的<code>path</code>中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.path</span><br></pre></td></tr></table></figure>
<p>当我们要添加自己的搜索目录时，可以使用列表的<code>append</code>方法。如果模块和自己写的脚本不在同一个目录下，可以在脚本开头加上<code>sys.path.append(xxx)</code>。注意这种方法是在运行脚本时有效的，运行结束后就会失效：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'引用模块的地址'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="sys-builtin-module-names"><a href="#sys-builtin-module-names" class="headerlink" title="sys.builtin_module_names"></a>sys.builtin_module_names</h3><p>&emsp;&emsp;<code>sys.builtin_module_names</code>返回一个列表，包含内建模块的名字。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_module</span><span class="params">(module)</span>:</span>  <span class="comment"># print sys.builtin_module_names</span></span><br><span class="line">    <span class="keyword">if</span> module <span class="keyword">in</span> sys.builtin_module_names:</span><br><span class="line">        print(module, <span class="string">"=&gt;"</span>, <span class="string">"__builtin__"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(module, <span class="string">"=&gt;"</span>, __import__(module).__file__)</span><br><span class="line">​</span><br><span class="line">find_module(<span class="string">'os'</span>)</span><br><span class="line">find_module(<span class="string">'sys'</span>)</span><br><span class="line">find_module(<span class="string">'zlib'</span>)</span><br><span class="line">find_module(<span class="string">'string'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="sys-exit"><a href="#sys-exit" class="headerlink" title="sys.exit"></a>sys.exit</h3><p>&emsp;&emsp;调用<code>sys.exit(n)</code>可以中途退出程序，当参数非<code>0</code>时，会引发一个<code>SystemExit</code>异常。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">​</span><br><span class="line">print(<span class="string">'running...'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">except</span> SystemExit:</span><br><span class="line">    print(<span class="string">'SystemExit exit 1'</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">'exited'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="sys-modules"><a href="#sys-modules" class="headerlink" title="sys.modules"></a>sys.modules</h3><p>&emsp;&emsp;使用<code>sys.modules</code>模块查找已导入的模块，<code>This is a dictionary that maps module names to modules which have already been loaded. This can be manipulated to force reloading of modules and other tricks</code>。<code>modules</code>字典包含所有加载的模块，<code>import</code>语句在从磁盘导入内容之前会先检查这个字典。</p>
<h3 id="sys-exc-info"><a href="#sys-exc-info" class="headerlink" title="sys.exc_info"></a>sys.exc_info</h3><p>&emsp;&emsp;This function returns a <code>tuple</code> of three values that give information about the exception that is currently being handled. The information returned is specific both to the current thread and to the current stack frame. If the current stack frame is not handling an exception, the information is taken from the calling stack frame, or its caller, and so on until a stack frame is found that is handling an exception. Here, <code>handling an exception</code> is defined as <code>executing an except clause</code>. For any stack frame, only information about the exception being currently handled is accessible.<br>&emsp;&emsp;If no exception is being handled anywhere on the stack, a tuple containing three <code>None</code> values is returned. Otherwise, the values returned are <code>(type, value, traceback)</code>. Their meaning is: <code>type</code> gets the <code>type</code> of the exception being handled (a subclass of <code>BaseException</code>); <code>value</code> gets the exception <code>instance</code> (an instance of the exception type); <code>traceback</code> gets a <code>traceback</code> object which encapsulates the call stack at the point where the exception originally occurred.</p>
<h3 id="sys-version"><a href="#sys-version" class="headerlink" title="sys.version"></a>sys.version</h3><p>&emsp;&emsp;A string containing the version number of the <code>Python</code> interpreter plus additional information on the build number and compiler used. This string is displayed when the interactive interpreter is started. Do not extract version information out of it, rather, use <code>version_info</code> and the functions provided by the platform module.</p>
<h3 id="sys-version-info"><a href="#sys-version-info" class="headerlink" title="sys.version_info"></a>sys.version_info</h3><p>&emsp;&emsp;A tuple containing the five components of the version number: <code>major</code>, <code>minor</code>, <code>micro</code>, <code>releaselevel</code>, and <code>serial</code>. All values except releaselevel are <code>integers</code>; the release level is <code>alpha</code>, <code>beta</code>, <code>candidate</code>, or <code>final</code>. The <code>version_info</code> value corresponding to the <code>Python version 2.0</code> is <code>(2, 0, 0, &#39;final&#39;, 0)</code>. The components can also be accessed by name, so <code>sys.version_info[0]</code> is equivalent to <code>sys.version_info.major</code> and so on.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.version</span><br><span class="line"><span class="string">'3.6.3 (v3.6.3:2c5fed8, Oct  3 2017, 18:11:49) [MSC v.1900 64 bit (AMD64)]'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.version_info</span><br><span class="line">sys.version_info(major=<span class="number">3</span>, minor=<span class="number">6</span>, micro=<span class="number">3</span>, releaselevel=<span class="string">'final'</span>, serial=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/56/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><span class="page-number current">57</span><a class="page-number" href="/page/58/">58</a><span class="space">&hellip;</span><a class="page-number" href="/page/94/">94</a><a class="extend next" rel="next" href="/page/58/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">934</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
