<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="暴徒">
<meta property="og:url" content="http://fukangwei.gitee.io/page/7/index.html">
<meta property="og:site_name" content="暴徒">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="暴徒">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/page/7/">





  <title>暴徒</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">暴徒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/HTML笔记/URL格式/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/HTML笔记/URL格式/" itemprop="url">URL格式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T19:19:42+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;在<code>WWW</code>上，每一个信息资源都有在网上唯一的地址，该地址就叫<code>URL</code>(<code>Uniform Resource Locator</code>，统一资源定位符)。<code>URL</code>由三部分组成：资源类型、存放资源的主机域名、资源文件名。其一般语法格式为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protocol://hostname[:port]/path/[;parameters][?query]#fragment (带方括号的为可选项)</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.imailtone.com:80/WebApplication1/WebForm1.aspx?name=tom&amp;;age=20#resume</span><br></pre></td></tr></table></figure>
<p>格式说明如下：</p>
<ul>
<li><code>protocol</code>：指定使用的传输协议，最常用的是<code>HTTP</code>协议，它也是目前<code>WWW</code>应用最广的协议。</li>
</ul>
<ol>
<li><code>file</code>：资源是本地计算机上的文件，格式为<code>file://</code>。</li>
<li><code>ftp</code>：通过<code>FTP</code>访问资源，格式为<code>FTP://</code>。</li>
<li><code>gopher</code>：通过Gopher协议访问该资源。</li>
<li><code>http</code>：通过<code>HTTP</code>访问该资源，格式为<code>HTTP://</code>。</li>
<li><code>https</code>：通过<code>HTTPS</code>访问该资源，格式为<code>HTTPS://</code>。</li>
<li><code>mailto</code>：资源为电子邮件地址，通过<code>SMTP</code>访问，格式为<code>mailto://</code>。</li>
<li><code>MMS</code>：通过支持<code>MMS</code>(流媒体)协议的播放该资源，代表软件是<code>Windows Media Player</code>，格式为<code>MMS://</code>。</li>
<li><code>ed2k</code>：通过支持<code>ed2k</code>(专用下载链接)协议的<code>P2P</code>软件访问该资源，代表软件是电驴，格式为<code>ed2k://</code>。</li>
<li><code>news</code>：通过<code>NNTP</code>访问该资源。</li>
</ol>
<ul>
<li><code>hostname</code>：指存放资源的服务器的域名系统(<code>DNS</code>)主机名或<code>IP</code>地址。在主机名前也可以包含连接到服务器所需的用户名和密码，格式为<code>username@password</code>。</li>
<li><code>:port</code>：它是一个整数，省略时使用方案的默认端口，各种传输协议都有默认的端口号，如http的默认端口为80。有时候出于安全或其他考虑，可以在服务器上对端口进行重定义，即采用非标准端口号，此时URL中就不能省略端口号这一项。</li>
<li><code>path</code>：由零或多个<code>/</code>符号隔开的字符串，一般用来表示主机上的一个目录或文件地址。</li>
<li><code>;parameters</code>：这是用于指定特殊参数的可选项。</li>
<li><code>?query</code>：可选项，用于给动态网页(如使用<code>CGI</code>、<code>ISAPI</code>、<code>PHP/JSP/ASP/ASP.NET</code>等技术制作的网页)传递参数，可以有多个参数，用<code>&amp;</code>符号隔开，每个参数的名和值用<code>=</code>符号隔开。</li>
<li><code>fragment</code>：用于指定网络资源中的片断。例如一个网页中有多个名词解释，可使用<code>fragment</code>直接定位到某一名词解释。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/位操作/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/opencv和图像处理/位操作/" itemprop="url">位操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T17:21:23+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>OpenCV</code>提供了<code>4</code>种位操作：<code>AND</code>、<code>OR</code>、<code>NOT</code>和<code>XOR</code>。函数为相关的操作加上<code>cv2.bitwise_</code>前缀，例如<code>cv2.bitwise_not</code>。对于<code>2</code>元操作而言，至少两个参数(<code>src1</code>和<code>src2</code>)。参数<code>dst</code>用于返回结果，它是可选的；<code>msk</code>参数也是可选的，指定<code>msk</code>区域进行相关操作。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bitwise_and(src1, src2[, dst[, mask]]) -&gt; dst</span><br></pre></td></tr></table></figure>
<p>因此可以使用参数返回结果，也可以使用赋值操作返回结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 画矩形</span></span><br><span class="line">Rectangle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.rectangle(Rectangle, (<span class="number">25</span>, <span class="number">25</span>), (<span class="number">275</span>, <span class="number">275</span>), <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Rectangle"</span>, Rectangle)</span><br><span class="line"><span class="comment"># 画圆形</span></span><br><span class="line">Circle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.circle(Circle, (<span class="number">150</span>, <span class="number">150</span>), <span class="number">150</span>, <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Circle"</span>, Circle)</span><br><span class="line"><span class="comment"># 图像的交操作</span></span><br><span class="line">bitwiseAnd = cv2.bitwise_and(Rectangle, Circle)</span><br><span class="line">cv2.imshow(<span class="string">"AND"</span>, bitwiseAnd)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/1.png" height="222" width="628"></p>
<p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 画矩形</span></span><br><span class="line">Rectangle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.rectangle(Rectangle, (<span class="number">25</span>, <span class="number">25</span>), (<span class="number">275</span>, <span class="number">275</span>), <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Rectangle"</span>, Rectangle)</span><br><span class="line"><span class="comment"># 画圆形</span></span><br><span class="line">Circle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.circle(Circle, (<span class="number">150</span>, <span class="number">150</span>), <span class="number">150</span>, <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Circle"</span>, Circle)</span><br><span class="line"><span class="comment"># 图像的或操作</span></span><br><span class="line">bitwiseOr = cv2.bitwise_or(Rectangle, Circle)</span><br><span class="line">cv2.imshow(<span class="string">"OR"</span>, bitwiseOr)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/2.png" height="220" width="628"></p>
<p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 画矩形</span></span><br><span class="line">Rectangle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.rectangle(Rectangle, (<span class="number">25</span>, <span class="number">25</span>), (<span class="number">275</span>, <span class="number">275</span>), <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Rectangle"</span>, Rectangle)</span><br><span class="line"><span class="comment"># 画圆形</span></span><br><span class="line">Circle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.circle(Circle, (<span class="number">150</span>, <span class="number">150</span>), <span class="number">150</span>, <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Circle"</span>, Circle)</span><br><span class="line"><span class="comment"># 图像的异或操作</span></span><br><span class="line">bitwiseXor = cv2.bitwise_xor(Rectangle, Circle)</span><br><span class="line">cv2.imshow(<span class="string">"XOR"</span>, bitwiseXor)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/3.png" height="221" width="628"></p>
<p>&emsp;&emsp;代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 画圆形</span></span><br><span class="line">Circle = np.zeros((<span class="number">300</span>, <span class="number">300</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">cv2.circle(Circle, (<span class="number">150</span>, <span class="number">150</span>), <span class="number">150</span>, <span class="number">255</span>, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Circle"</span>, Circle)</span><br><span class="line"><span class="comment"># 圆形的非运算操作</span></span><br><span class="line">bitwiseNot = cv2.bitwise_not(Circle)</span><br><span class="line">cv2.imshow(<span class="string">"NOT"</span>, bitwiseNot)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/4.png" height="219" width="417"></p>
<h3 id="add函数"><a href="#add函数" class="headerlink" title="add函数"></a>add函数</h3><p>&emsp;&emsp;该函数用于图像矩阵相加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add(src1, src2, dst=<span class="keyword">None</span>, mask=<span class="keyword">None</span>, dtype=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>src1</code>是图像矩阵<code>1</code>，src2是图像矩阵<code>2</code>，<code>dst</code>、<code>mask</code>和<code>dtype</code>一般采用默认选项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line">image = cv2.imread(<span class="string">"timg.jpg"</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Original"</span>, image)</span><br><span class="line"><span class="comment"># 图像image各像素加100</span></span><br><span class="line">M = np.ones(image.shape, dtype=<span class="string">"uint8"</span>) * <span class="number">100</span>  <span class="comment"># 与image大小一样的全100矩阵</span></span><br><span class="line">added = cv2.add(image, M)  <span class="comment"># 将图像image与M相加</span></span><br><span class="line">cv2.imshow(<span class="string">"Added"</span>, added)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/5.png" height="278" width="543"></p>
<h3 id="subtract函数"><a href="#subtract函数" class="headerlink" title="subtract函数"></a>subtract函数</h3><p>&emsp;&emsp;该函数用于图像矩阵相减：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subtract(src1, src2, dst=<span class="keyword">None</span>, mask=<span class="keyword">None</span>, dtype=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>src1</code>是图像矩阵<code>1</code>，<code>src2</code>是图像矩阵<code>2</code>，<code>dst</code>、<code>mask</code>和<code>dtype</code>一般采用默认选项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line">image = cv2.imread(<span class="string">"timg.jpg"</span>)</span><br><span class="line">cv2.imshow(<span class="string">"Original"</span>, image)</span><br><span class="line"><span class="comment"># 图像image各像素减去50</span></span><br><span class="line">M = np.ones(image.shape, dtype=<span class="string">"uint8"</span>) * <span class="number">50</span>  <span class="comment"># 与image大小一样的全50矩阵</span></span><br><span class="line">subtracted = cv2.subtract(image, M)  <span class="comment"># 将图像image与M相减</span></span><br><span class="line">cv2.imshow(<span class="string">"Subtracted"</span>, subtracted)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/位操作/6.png" height="279" width="542"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/opencv和图像处理/全景拼接/" itemprop="url">全景拼接</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T15:04:09+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;官方代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/stitching/stitcher.hpp"</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">bool</span> try_use_gpu = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;Mat&gt; imgs;</span><br><span class="line"><span class="built_in">string</span> result_name = <span class="string">"result.jpg"</span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printUsage</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span></span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[] )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> retval = parseCmdArgs ( argc, argv );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( retval ) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    Mat pano;</span><br><span class="line">    Stitcher stitcher = Stitcher::createDefault ( try_use_gpu );</span><br><span class="line">    Stitcher::Status status = stitcher.stitch ( imgs, pano );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( status != Stitcher::OK ) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span> ( status ) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    imwrite ( result_name, pano );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printUsage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt;</span><br><span class="line">         <span class="string">"Rotation model images stitcher.\n\n"</span></span><br><span class="line">         <span class="string">"stitching img1 img2 [...imgN]\n\n"</span></span><br><span class="line">         <span class="string">"Flags:\n"</span></span><br><span class="line">         <span class="string">"  --try_use_gpu (yes|no)\n"</span></span><br><span class="line">         <span class="string">"      Try to use GPU. The default value is 'no'. All default values\n"</span></span><br><span class="line">         <span class="string">"      are for CPU mode.\n"</span></span><br><span class="line">         <span class="string">"  --output &lt;result_img&gt;\n"</span></span><br><span class="line">         <span class="string">"      The default is 'result.jpg'.\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( argc == <span class="number">1</span> ) &#123;</span><br><span class="line">        printUsage();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">1</span>; i &lt; argc; ++i ) &#123;</span><br><span class="line">        <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--help"</span> || <span class="built_in">string</span> ( argv[i] ) == <span class="string">"/?"</span> ) &#123;</span><br><span class="line">            printUsage();</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--try_use_gpu"</span> ) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i + <span class="number">1</span>] ) == <span class="string">"no"</span> ) &#123;</span><br><span class="line">                try_use_gpu = <span class="literal">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i + <span class="number">1</span>] ) == <span class="string">"yes"</span> ) &#123;</span><br><span class="line">                try_use_gpu = <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; <span class="string">"Bad --try_use_gpu flag value\n"</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">​</span><br><span class="line">            i++;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--output"</span> ) &#123;</span><br><span class="line">            result_name = argv[i + <span class="number">1</span>];</span><br><span class="line">            i++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Mat img = imread ( argv[i] );</span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> ( img.empty() ) &#123;</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't read image '"</span> &lt;&lt; argv[i] &lt;&lt; <span class="string">"'\n"</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">​</span><br><span class="line">            imgs.push_back ( img );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/1.png"></p>
<p>&emsp;&emsp;基于不同模式的全景拼接如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/stitching/stitcher.hpp"</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">bool</span> try_use_gpu = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;Mat&gt; imgs;</span><br><span class="line"><span class="built_in">string</span> result_name = <span class="string">"result.jpg"</span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="comment">/* 输入的图片全部填充到容器imgs中，并将输入的图片显示出来 */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; argc - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">        Mat img = imread(argv[i]);</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> (img.empty()) &#123;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't read image '"</span> &lt;&lt; argv[i] &lt;&lt; <span class="string">"'\n"</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        imgs.push_back(img);</span><br><span class="line">        imshow(argv[i], img);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> retval = parseCmdArgs(argc, argv);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (retval) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    Mat pano;</span><br><span class="line">    <span class="comment">/* 创建一个stitcher对象 */</span></span><br><span class="line">    Stitcher stitcher = Stitcher::createDefault(try_use_gpu);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'1'</span>) &#123;  <span class="comment">/* 1是平面拼接 */</span></span><br><span class="line">        PlaneWarper *cw = <span class="keyword">new</span> PlaneWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'2'</span>) &#123; <span class="comment">/* 2是柱面拼接 */</span></span><br><span class="line">        SphericalWarper *cw = <span class="keyword">new</span> SphericalWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'3'</span>) &#123; <span class="comment">/* 3是立体画面拼接 */</span></span><br><span class="line">        StereographicWarper *cw = <span class="keyword">new</span> cv::StereographicWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* 使用Surf算法来寻找特征点，支持Surf和Orb两种方式 */</span></span><br><span class="line">    detail::SurfFeaturesFinder *featureFinder = <span class="keyword">new</span> detail::SurfFeaturesFinder();</span><br><span class="line">    stitcher.setFeaturesFinder(featureFinder);</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* 匹配给定的图像和估计相机的旋转 */</span></span><br><span class="line">    Stitcher::Status status = stitcher.estimateTransform(imgs);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (status != Stitcher::OK) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span>(status) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    status = stitcher.composePanorama(pano); <span class="comment">/* 生成全景图像 */</span>  </span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (status != Stitcher::OK) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span>(status) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    imwrite(result_name, pano);</span><br><span class="line">    imshow(<span class="string">"show"</span>, pano);</span><br><span class="line">    cv::waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/2.png"></p>
<hr>
<h3 id="基于OpenCV全景拼接"><a href="#基于OpenCV全景拼接" class="headerlink" title="基于OpenCV全景拼接"></a>基于OpenCV全景拼接</h3><p>&emsp;&emsp;基于<code>OpenCV</code>的图片拼接和全景图构建，用于<code>缝合</code>两张有重叠区域的图来创建一张全景图。构建全景图利用到的计算机视觉和图像处理技术有：关键点检测、局部不变特征、关键点匹配、<code>RANSAC</code>和透视变形。因为处理关键点检测和局部不变性在<code>OpenCV 2.4.X</code>和<code>OpenCV 3.X</code>中有很大的不同，比如<code>SIFT</code>和<code>SURF</code>，这里将给出兼容两个版本的代码。<br>&emsp;&emsp;全景拼接算法由四部分组成：</p>
<ul>
<li><code>Step 1</code>: Detect keypoints (<code>DoG</code>, <code>Harris</code> etc) and extract local invariant descriptors (<code>SIFT</code>, <code>SURF</code> etc) from the two input images.</li>
<li><code>Step 2</code>: Match the descriptors between the two images.</li>
<li><code>Step 3</code>: Use the <code>RANSAC</code> algorithm to estimate a homography matrix using our matched feature vectors.</li>
<li><code>Step 4</code>: Apply a warping transformation using the homography matrix obtained from <code>Step 3</code>.</li>
</ul>
<p>将所有的步骤都封装在<code>panorama.py</code>，定义一个<code>Stitcher</code>类来构建全图。<br>&emsp;&emsp;<code>panorama.py</code>如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stitcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.isv3 = imutils.is_cv3()  <span class="comment"># determine if we are using OpenCV v3.X</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stitch</span><span class="params">(self, images, ratio=<span class="number">0.75</span>, reprojThresh=<span class="number">4.0</span>, showMatches=False)</span>:</span></span><br><span class="line">        <span class="comment"># unpack the images, then detect keypoints and extract local invariant descriptors from them</span></span><br><span class="line">        (imageB, imageA) = images</span><br><span class="line">        (kpsA, featuresA) = self.detectAndDescribe(imageA)</span><br><span class="line">        (kpsB, featuresB) = self.detectAndDescribe(imageB)</span><br><span class="line">        <span class="comment"># match features between the two images</span></span><br><span class="line">        M = self.matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> M <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment"># if the match is None, then there aren't enough matched keypoints to create a panorama</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">​</span><br><span class="line">        (matches, H, status) = M  <span class="comment"># otherwise, apply a perspective warp to stitch the images together</span></span><br><span class="line">        result = cv2.warpPerspective(imageA, H, (imageA.shape[<span class="number">1</span>] + imageB.shape[<span class="number">1</span>], imageA.shape[<span class="number">0</span>]))</span><br><span class="line">        result[<span class="number">0</span>:imageB.shape[<span class="number">0</span>], <span class="number">0</span>:imageB.shape[<span class="number">1</span>]] = imageB</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> showMatches:  <span class="comment"># check to see if the keypoint matches should be visualized</span></span><br><span class="line">            vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches, status)</span><br><span class="line">            <span class="keyword">return</span> (result, vis)  <span class="comment"># return a tuple of the stitched image and the visualization</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">return</span> result  <span class="comment"># return the stitched image</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detectAndDescribe</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  <span class="comment"># convert the image to grayscale</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> self.isv3:  <span class="comment"># check to see if we are using OpenCV 3.X</span></span><br><span class="line">            descriptor = cv2.xfeatures2d.SIFT_create()  <span class="comment"># detect and extract features from the image</span></span><br><span class="line">            (kps, features) = descriptor.detectAndCompute(image, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># otherwise, we are using OpenCV 2.4.X</span></span><br><span class="line">            detector = cv2.FeatureDetector_create(<span class="string">"SIFT"</span>)  <span class="comment"># detect keypoints in the image</span></span><br><span class="line">            kps = detector.detect(gray)</span><br><span class="line">            extractor = cv2.DescriptorExtractor_create(<span class="string">"SIFT"</span>)  <span class="comment"># extract features from the image</span></span><br><span class="line">            (kps, features) = extractor.compute(gray, kps)</span><br><span class="line">​</span><br><span class="line">        kps = np.float32([kp.pt <span class="keyword">for</span> kp <span class="keyword">in</span> kps])  <span class="comment"># convert the keypoints from KeyPoint objects to NumPy arrays</span></span><br><span class="line">        <span class="keyword">return</span> (kps, features)  <span class="comment"># return a tuple of keypoints and features</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">matchKeypoints</span><span class="params">(self, kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span>:</span></span><br><span class="line">        <span class="comment"># compute the raw matches and initialize the list of actual matches</span></span><br><span class="line">        matcher = cv2.DescriptorMatcher_create(<span class="string">"BruteForce"</span>)</span><br><span class="line">        rawMatches = matcher.knnMatch(featuresA, featuresB, <span class="number">2</span>)</span><br><span class="line">        matches = []</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> rawMatches:  <span class="comment"># loop over the raw matches</span></span><br><span class="line">            <span class="comment"># ensure the distance is within a certain ratio of each other (i.e. Lowe's ratio test)</span></span><br><span class="line">            <span class="keyword">if</span> len(m) == <span class="number">2</span> <span class="keyword">and</span> m[<span class="number">0</span>].distance &lt; m[<span class="number">1</span>].distance * ratio:</span><br><span class="line">                matches.append((m[<span class="number">0</span>].trainIdx, m[<span class="number">0</span>].queryIdx))</span><br><span class="line">        <span class="keyword">if</span> len(matches) &gt; <span class="number">4</span>:  <span class="comment"># computing a homography requires at least 4 matches</span></span><br><span class="line">            <span class="comment"># construct the two sets of points</span></span><br><span class="line">            ptsA = np.float32([kpsA[i] <span class="keyword">for</span> (_, i) <span class="keyword">in</span> matches])</span><br><span class="line">            ptsB = np.float32([kpsB[i] <span class="keyword">for</span> (i, _) <span class="keyword">in</span> matches])</span><br><span class="line">            <span class="comment"># compute the homography between the two sets of points</span></span><br><span class="line">            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)</span><br><span class="line">            <span class="comment"># return the matches along with the homograpy matrix and status of each matched point</span></span><br><span class="line">            <span class="keyword">return</span> (matches, H, status)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span>  <span class="comment"># otherwise, no homograpy could be computed</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drawMatches</span><span class="params">(self, imageA, imageB, kpsA, kpsB, matches, status)</span>:</span></span><br><span class="line">        <span class="comment"># initialize the output visualization image</span></span><br><span class="line">        (hA, wA) = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">        (hB, wB) = imageB.shape[:<span class="number">2</span>]</span><br><span class="line">        vis = np.zeros((max(hA, hB), wA + wB, <span class="number">3</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">        vis[<span class="number">0</span>:hA, <span class="number">0</span>:wA] = imageA</span><br><span class="line">        vis[<span class="number">0</span>:hB, wA:] = imageB</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ((trainIdx, queryIdx), s) <span class="keyword">in</span> zip(matches, status):  <span class="comment"># loop over the matches</span></span><br><span class="line">            <span class="keyword">if</span> s == <span class="number">1</span>:  <span class="comment"># only process the match if the keypoint was successfully matched</span></span><br><span class="line">                <span class="comment"># draw the match</span></span><br><span class="line">                ptA = (int(kpsA[queryIdx][<span class="number">0</span>]), int(kpsA[queryIdx][<span class="number">1</span>]))</span><br><span class="line">                ptB = (int(kpsB[trainIdx][<span class="number">0</span>]) + wA, int(kpsB[trainIdx][<span class="number">1</span>]))</span><br><span class="line">                cv2.line(vis, ptA, ptB, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> vis  <span class="comment"># return the visualization</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Let’s go ahead and get started by reviewing <code>panorama.py</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stitcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.isv3 = imutils.is_cv3()  <span class="comment"># determine if we are using OpenCV v3.X</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;We start off on <code>Lines 1-3</code> by importing our necessary packages. We’ll be using <code>NumPy</code> for <code>matrix/array</code> operations, <code>imutils</code> for a set of <code>OpenCV</code> convenience methods, and finally <code>cv2</code> for our <code>OpenCV</code> bindings.<br>&emsp;&emsp;From there, we define the <code>Stitcher</code> class on <code>Line 5</code>. The constructor to <code>Stitcher</code> simply checks which version of <code>OpenCV</code> we are using by making a call to the <code>is_cv3</code> method. Since there are major differences in how <code>OpenCV 2.4</code> and <code>OpenCV 3</code> handle keypoint detection and local invariant descriptors, it’s important that we determine the version of <code>OpenCV</code> that we are using.<br>&emsp;&emsp;Next up, let’s start working on the <code>stitch</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stitch</span><span class="params">(self, images, ratio=<span class="number">0.75</span>, reprojThresh=<span class="number">4.0</span>, showMatches=False)</span>:</span></span><br><span class="line">    <span class="comment"># unpack the images, then detect keypoints and extract local invariant descriptors from them</span></span><br><span class="line">    (imageB, imageA) = images</span><br><span class="line">    (kpsA, featuresA) = self.detectAndDescribe(imageA)</span><br><span class="line">    (kpsB, featuresB) = self.detectAndDescribe(imageB)</span><br><span class="line">    <span class="comment"># match features between the two images</span></span><br><span class="line">    M = self.matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span><br><span class="line">    <span class="keyword">if</span> M <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment"># if the match is None, then there aren't enough matched keypoints to create a panorama</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>stitch</code> method requires only a single parameter, <code>images</code>, which is the list of (two) images that we are going to <code>stitch</code> together to form the panorama.<br>&emsp;&emsp;We can also optionally supply <code>ratio</code>, used for <code>David Lowe&#39;s</code> ratio test when matching features, <code>reprojThresh</code> which is the maximum pixel <code>wiggle room</code> allowed by the <code>RANSAC</code> algorithm, and finally <code>showMatches</code>, a <code>boolean</code> used to indicate if the keypoint matches should be visualized or not.<br>&emsp;&emsp;<code>Line 3</code> unpacks the <code>images</code> list (which again, we presume to contain only two images). The ordering to the <code>images</code> list is important: we expect <code>images</code> to be supplied in <code>left-to-right</code> order. If <code>images</code> are not supplied in this order, then our code will still run, but our output panorama will only contain one image, not both.<br>&emsp;&emsp;Once we have unpacked the <code>images</code> list, we make a call to the <code>detectAndDescribe</code> method on <code>Lines 4</code> and <code>5</code>. This method simply detects keypoints and extracts local invariant descriptors (i.e. <code>SIFT</code>) from the two images.<br>&emsp;&emsp;Given the keypoints and features, we use <code>matchKeypoints</code> (Lines <code>7</code>) to match the features in the two images. We’ll define this method later in the lesson.<br>&emsp;&emsp;If the returned matches <code>M</code> are <code>None</code>, then not enough keypoints were matched to create a panorama, so we simply return to the calling function.<br>&emsp;&emsp;Otherwise, we are now ready to apply the perspective transform:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(matches, H, status) = M  <span class="comment"># otherwise, apply a perspective warp to stitch the images together</span></span><br><span class="line">result = cv2.warpPerspective(imageA, H, (imageA.shape[<span class="number">1</span>] + imageB.shape[<span class="number">1</span>], imageA.shape[<span class="number">0</span>]))</span><br><span class="line">result[<span class="number">0</span>:imageB.shape[<span class="number">0</span>], <span class="number">0</span>:imageB.shape[<span class="number">1</span>]] = imageB</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> showMatches:  <span class="comment"># check to see if the keypoint matches should be visualized</span></span><br><span class="line">    vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches, status)</span><br><span class="line">    <span class="keyword">return</span> (result, vis)  <span class="comment"># return a tuple of the stitched image and the visualization</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> result  <span class="comment"># return the stitched image</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Provided that <code>M</code> is not <code>None</code>, we unpack the tuple on <code>Line 1</code>, giving us a list of keypoint matches, the homography matrix <code>H</code> derived from the <code>RANSAC</code> algorithm, and finally status, a list of indexes to indicate which keypoints in matches were successfully spatially verified using <code>RANSAC</code>.<br>&emsp;&emsp;Given our homography matrix <code>H</code>, we are now ready to stitch the two images together. First, we make a call to <code>cv2.warpPerspective</code> which requires three arguments: the image we want to warp (in this case, the right image), the <code>3 x 3</code> transformation matrix (<code>H</code>), and finally the shape out of the output image. We derive the shape out of the output image by taking the sum of the widths of both images and then using the height of the second image.<br>&emsp;&emsp;<code>Line 5</code> makes a check to see if we should visualize the keypoint matches, and if so, we make a call to <code>drawMatches</code> and return a tuple of both the panorama and visualization to the calling method. Otherwise, we simply returned the stitched image.<br>&emsp;&emsp;Now that the stitch method has been defined, let’s look into some of the helper methods that it calls. We’ll start with <code>detectAndDescribe</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectAndDescribe</span><span class="params">(self, image)</span>:</span></span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  <span class="comment"># convert the image to grayscale</span></span><br><span class="line">    <span class="keyword">if</span> self.isv3:  <span class="comment"># check to see if we are using OpenCV 3.X</span></span><br><span class="line">        descriptor = cv2.xfeatures2d.SIFT_create()  <span class="comment"># detect and extract features from the image</span></span><br><span class="line">        (kps, features) = descriptor.detectAndCompute(image, <span class="keyword">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># otherwise, we are using OpenCV 2.4.X</span></span><br><span class="line">        detector = cv2.FeatureDetector_create(<span class="string">"SIFT"</span>)  <span class="comment"># detect keypoints in the image</span></span><br><span class="line">        kps = detector.detect(gray)</span><br><span class="line">        extractor = cv2.DescriptorExtractor_create(<span class="string">"SIFT"</span>)  <span class="comment"># extract features from the image</span></span><br><span class="line">        (kps, features) = extractor.compute(gray, kps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert the keypoints from KeyPoint objects to NumPy arrays</span></span><br><span class="line">    kps = np.float32([kp.pt <span class="keyword">for</span> kp <span class="keyword">in</span> kps])</span><br><span class="line">    <span class="keyword">return</span> (kps, features)  <span class="comment"># return a tuple of keypoints and features</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;As the name suggests, the <code>detectAndDescribe</code> method accepts an image, then detects keypoints and extracts local invariant descriptors. In our implementation we use the <code>Difference of Gaussian</code> (<code>DoG</code>) keypoint detector and the <code>SIFT</code> feature extractor.<br>&emsp;&emsp;On <code>Line 3</code> we check to see if we are using <code>OpenCV 3.X</code>. If we are, then we use the <code>cv2.xfeatures2d.SIFT_create</code> function to instantiate both our <code>DoG</code> keypoint detector and <code>SIFT</code> feature extractor. A call to <code>detectAndCompute</code> handles extracting the keypoints and features.<br>&emsp;&emsp;<code>Lines 7-10</code> handle if we are using <code>OpenCV 2.4</code>. The <code>cv2.FeatureDetector_create</code> function instantiates our keypoint detector (<code>DoG</code>). A call to detect returns our set of keypoints.<br>&emsp;&emsp;From there, we need to initialize <code>cv2.DescriptorExtractor_create</code> using the <code>SIFT</code> keyword to setup our <code>SIFT</code> feature extractor. Calling the compute method of the extractor returns a set of feature vectors which quantify the region surrounding each of the detected keypoints in the image.<br>&emsp;&emsp;Finally, our keypoints are converted from <code>KeyPoint</code> objects to a <code>NumPy</code> array and returned to the calling method.<br>&emsp;&emsp;Next up, let’s look at the <code>matchKeypoints</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matchKeypoints</span><span class="params">(self, kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span>:</span></span><br><span class="line">    <span class="comment"># compute the raw matches and initialize the list of actual matches</span></span><br><span class="line">    matcher = cv2.DescriptorMatcher_create(<span class="string">"BruteForce"</span>)</span><br><span class="line">    rawMatches = matcher.knnMatch(featuresA, featuresB, <span class="number">2</span>)</span><br><span class="line">    matches = []</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> rawMatches:  <span class="comment"># loop over the raw matches</span></span><br><span class="line">        <span class="comment"># ensure the distance is within a certain ratio of each other (i.e. Lowe's ratio test)</span></span><br><span class="line">        <span class="keyword">if</span> len(m) == <span class="number">2</span> <span class="keyword">and</span> m[<span class="number">0</span>].distance &lt; m[<span class="number">1</span>].distance * ratio:</span><br><span class="line">            matches.append((m[<span class="number">0</span>].trainIdx, m[<span class="number">0</span>].queryIdx))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>matchKeypoints</code> function requires four arguments: the keypoints and feature vectors associated with the first image, followed by the keypoints and feature vectors associated with the second image. <code>David Lowe&#39;s</code> ratio test variable and <code>RANSAC</code> <code>re-projection</code> threshold are also be supplied.<br>&emsp;&emsp;Matching features together is actually a fairly straightforward process. We simply loop over the descriptors from both images, compute the distances, and find the smallest distance for each pair of descriptors. Since this is a very common practice in computer vision, <code>OpenCV</code> has a <code>built-in</code> function called <code>cv2.DescriptorMatcher_create</code> that constructs the feature matcher for us. The <code>BruteForce</code> value indicates that we are going to exhaustively compute the <code>Euclidean</code> distance between all feature vectors from both images and find the pairs of descriptors that have the smallest distance.<br>&emsp;&emsp;A call to <code>knnMatch</code> on <code>Line 4</code> performs <code>k-NN</code> matching between the two feature vector sets using <code>k=2</code> (indicating the top two matches for each feature vector are returned).<br>&emsp;&emsp;The reason we want the top two matches rather than just the top one match is because we need to apply <code>David Lowe&#39;s</code> ratio test for <code>false-positive</code> match pruning.<br>&emsp;&emsp;Again, <code>Line 4</code> computes the <code>rawMatches</code> for each pair of descriptors, but there is a chance that some of these pairs are <code>false</code> positives, meaning that the image patches are not actually true matches. In an attempt to prune these <code>false-positive</code> matches, we can loop over each of the <code>rawMatches</code> individually and apply <code>Lowe&#39;s</code> ratio test, which is used to determine <code>high-quality</code> feature matches. Typical values for <code>Lowe&#39;s</code> ratio are normally in the range <code>[0.7, 0.8]</code>.<br>&emsp;&emsp;Once we have obtained the matches using <code>Lowe&#39;s</code> ratio test, we can compute the homography between the two sets of keypoints:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> len(matches) &gt; <span class="number">4</span>:  <span class="comment"># computing a homography requires at least 4 matches</span></span><br><span class="line">    <span class="comment"># construct the two sets of points</span></span><br><span class="line">    ptsA = np.float32([kpsA[i] <span class="keyword">for</span> (_, i) <span class="keyword">in</span> matches])</span><br><span class="line">    ptsB = np.float32([kpsB[i] <span class="keyword">for</span> (i, _) <span class="keyword">in</span> matches])</span><br><span class="line">    <span class="comment"># compute the homography between the two sets of points</span></span><br><span class="line">    (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)</span><br><span class="line">    <span class="comment"># return the matches along with the homograpy matrix and status of each matched point</span></span><br><span class="line">    <span class="keyword">return</span> (matches, H, status)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">None</span> <span class="comment"># otherwise, no homograpy could be computed</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Computing a homography between two sets of points requires at a bare minimum an initial set of four matches. For a more reliable homography estimation, we should have substantially more than just four matched points.<br>&emsp;&emsp;Finally, the last method in our <code>Stitcher</code> method, <code>drawMatches</code> is used to visualize keypoint correspondences between two images:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawMatches</span><span class="params">(self, imageA, imageB, kpsA, kpsB, matches, status)</span>:</span></span><br><span class="line">    <span class="comment"># initialize the output visualization image</span></span><br><span class="line">    (hA, wA) = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">    (hB, wB) = imageB.shape[:<span class="number">2</span>]</span><br><span class="line">    vis = np.zeros((max(hA, hB), wA + wB, <span class="number">3</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">    vis[<span class="number">0</span>:hA, <span class="number">0</span>:wA] = imageA</span><br><span class="line">    vis[<span class="number">0</span>:hB, wA:] = imageB</span><br><span class="line">    <span class="keyword">for</span> ((trainIdx, queryIdx), s) <span class="keyword">in</span> zip(matches, status):  <span class="comment"># loop over the matches</span></span><br><span class="line">        <span class="keyword">if</span> s == <span class="number">1</span>:  <span class="comment"># only process the match if the keypoint was successfully matched</span></span><br><span class="line">            <span class="comment"># draw the match</span></span><br><span class="line">            ptA = (int(kpsA[queryIdx][<span class="number">0</span>]), int(kpsA[queryIdx][<span class="number">1</span>]))</span><br><span class="line">            ptB = (int(kpsB[trainIdx][<span class="number">0</span>]) + wA, int(kpsB[trainIdx][<span class="number">1</span>]))</span><br><span class="line">            cv2.line(vis, ptA, ptB, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> vis  <span class="comment"># return the visualization</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;This method requires that we pass in the two original images, the set of keypoints associated with each image, the initial matches after applying <code>Lowe&#39;s</code> ratio test, and finally the status list provided by the homography calculation. Using these variables, we can visualize the <code>inlier</code> keypoints by drawing a straight line from keypoint <code>N</code> in the first image to keypoint <code>M</code> in the second image.<br>&emsp;&emsp;示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> Stitcher</span><br><span class="line">​</span><br><span class="line">imageA = cv2.imread(<span class="string">"Panorama-1.png"</span>)</span><br><span class="line">imageB = cv2.imread(<span class="string">"Panorama-2.png"</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"former size is:"</span>)</span><br><span class="line">print(imageA.shape)</span><br><span class="line">print(imageB.shape)</span><br><span class="line"><span class="comment"># 使图片的高度相等</span></span><br><span class="line">height, width = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">imageB = imutils.resize(imageB, height=height)</span><br><span class="line">print(<span class="string">"after size is:"</span>)</span><br><span class="line">print(imageA.shape)</span><br><span class="line">print(imageB.shape)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># stitch the images together to create a panorama</span></span><br><span class="line">stitcher = Stitcher()</span><br><span class="line">(result, vis) = stitcher.stitch([imageA, imageB], showMatches=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># show the images</span></span><br><span class="line">cv2.imshow(<span class="string">"Image A"</span>, imageA)</span><br><span class="line">cv2.imshow(<span class="string">"Image B"</span>, imageB)</span><br><span class="line">cv2.imshow(<span class="string">"Keypoint Matches"</span>, vis)</span><br><span class="line">cv2.imshow(<span class="string">"Result"</span>, result)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/3.png" height="236" width="572"></p>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/4.png" height="470" width="573"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/meanshift跟踪算法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/opencv和图像处理/meanshift跟踪算法/" itemprop="url">meanshift跟踪算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T14:05:39+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;首先介绍一下<code>meanshift</code>算法，它的本质是一个迭代的过程，能够在一组数据的密度分布中寻找到局部极值。它比较稳定，而且是无参密度估计(不需要事先知道样本数据的概率密度分布函数，完全依靠对样本点的计算)，而且在采样充分的情况下，一定会收敛，即可以对服从任意分布的数据进行密度估计。<br>&emsp;&emsp;这里就不把<code>meanshift</code>的数学公式都写出来了，只为了让大家知道<code>meanshift</code>的作用是什么；高维的部分也先不考虑，以二维来说明可能更容易理解。下图中的很多的红点就是我们的样本特征点，<code>meanshift</code>就是在这些点中的任意一个点为圆心，然后以半径<code>R</code>画一个圆(在<code>OpenCV</code>中是一个矩形)，然后落在这个圆中的所有点和圆心都会有对应的一个向量，把所有这些向量相加(注意是向量相加)，最终只得到一个向量，就是下图中用黄色箭头表示的向量，这个向量就是<code>meanshift</code>向量。</p>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/1.png" height="193" width="295"></p>
<p>然后再以这个<code>meanshift</code>向量的终点为圆心，继续上述过程，又可以得到一个<code>meanshift</code>向量：</p>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/2.png" height="184" width="293"></p>
<p>然后不断地继续这样的过程，可以得到很多连续的<code>meanshift</code>向量。将这些向量首尾相连，最终会在一个地方停下来(即<code>meanshift</code>算法会收敛)，最后的那个<code>meanshift</code>向量的终点就是最终结果(一个点)：</p>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/3.png" height="180" width="290"></p>
<p>从上述的过程可以看出，<code>meanshift</code>算法的最终效果就是：从起点开始，最终会一步一步到达样本特征点最密集的点那里(当然在哪个点是终点就要取决于设定的阈值)。<br>&emsp;&emsp;到这里可能只知道<code>meanshift</code>算法的作用是向数据密集的地方走的一个效果，但是还是不明白它是怎么在运动跟踪中发挥作用的，尤其是不理解它这个样本特征点(就是上图中的红点)到底和我们图像中的什么对应的。<br>&emsp;&emsp;对于上面这个问题，我们需要先了解一下运动跟踪算法是一个什么样的过程，知道了这个过程之后，就可以知道<code>meanshift</code>算法在这个过程中发挥的作用了。运动跟踪说到底就是在一开始告诉程序一个跟踪目标，然后程序就在接下来的视频帧中去寻找这个目标。给定跟踪目标很简单，直接在图像中给一个<code>ROI</code>给程序就可以了，那么程序接下来要做的就是在下一帧图像中去找这个<code>ROI</code>。但这个<code>ROI</code>是移动了的，已经不在之前的那个位置了，那么此时程序要怎么来找到这个<code>ROI</code>呢？在计算机视觉中，我们是这么来解决的：首先对跟踪目标进行描述，这个描述是将跟踪目标区域转换为颜色<code>HSV</code>空间，然后得到H的这个通道的分布直方图，有了这个描述之后，我们就是要在下一个视频帧中找到和这个描述的一样的区域。但是我们知道要找到完全一样的区域很难，所以我们就用了一个相似函数来衡量找到的区域和目标区域的相似度，通过这个相似函数，相似函数值越大说明我们寻找的区域和目标区域越相似，所以目标就是要找这个对应最大相似值的区域。那么怎么来寻找呢？这时<code>meanshift</code>就排上用场了，它可以通过不断地迭代得到有最大相似值的区域。<code>meanshift</code>的作用可以让我们的搜索窗口不断向两个模型相比颜色变化最大的方向不断移动，直到最后两次移动距离小于阈值，即找到当前帧的位置，并以此作为下一帧的起始搜索窗口中心。重复这个过程，每两帧之间都会产生一个<code>meanshift</code>向量，整个过程的<code>meanshift</code>向量连起来就是目标的运动路径。<br>&emsp;&emsp;整个运动跟踪过程就是如下：</p>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/4.png"></p>
<hr>
<h3 id="Meanshift"><a href="#Meanshift" class="headerlink" title="Meanshift"></a>Meanshift</h3><p>&emsp;&emsp;The intuition behind the <code>meanshift</code> is simple. Consider you have a set of points. (It can be a pixel distribution like histogram backprojection). You are given a small window (may be a circle) and you have to move that window to the area of maximum pixel density (or maximum number of points). It is illustrated in the simple image given below:</p>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/5.png" height="222" width="296"></p>
<p>&emsp;&emsp;The initial window is shown in blue circle with the name <code>C1</code>. Its original center is marked in blue rectangle, named <code>C1_o</code>. But if you find the centroid of the points inside that window, you will get the point <code>C1_r</code> (marked in small blue circle) which is the real centroid of window. Surely they don’t match. So move your window such that circle of the new window matches with previous centroid. Again find the new centroid. Most probably, it won’t match. So move it again, and continue the iterations such that center of window and its centroid falls on the same location (or with a small desired error). So finally what you obtain is a window with maximum pixel distribution. It is marked with green circle, named <code>C2</code>. As you can see in image, it has maximum number of points.<br>&emsp;&emsp;So we normally pass the histogram backprojected image and initial target location. When the object moves, obviously the movement is reflected in histogram backprojected image. As a result, <code>meanshift</code> algorithm moves our window to the new location with maximum density.</p>
<h3 id="Meanshift-in-OpenCV"><a href="#Meanshift-in-OpenCV" class="headerlink" title="Meanshift in OpenCV"></a>Meanshift in OpenCV</h3><p>&emsp;&emsp;To use <code>meanshift</code> in <code>OpenCV</code>, first we need to setup the target, find its histogram so that we can backproject the target on each frame for calculation of <code>meanshift</code>. We also need to provide initial location of window. For histogram, only <code>Hue</code> is considered here. Also, to avoid <code>false</code> values due to low light, low light values are discarded using <code>cv2.inRange()</code> function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line">cap = cv2.VideoCapture(<span class="string">'output_2.avi'</span>)</span><br><span class="line">ret, frame = cap.read()  <span class="comment"># take first frame of the video</span></span><br><span class="line">print(frame.shape)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># setup initial location of window</span></span><br><span class="line">r, h, c, w = <span class="number">200</span>, <span class="number">170</span>, <span class="number">260</span>, <span class="number">100</span>  <span class="comment"># simply hardcoded the values</span></span><br><span class="line">track_window = (c, r, w, h)</span><br><span class="line">​</span><br><span class="line">cv2.rectangle(frame, (c, r), (c + w, r + h), <span class="number">255</span>, <span class="number">2</span>)</span><br><span class="line">cv2.imshow(<span class="string">"frame"</span>, frame)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># set up the ROI for tracking</span></span><br><span class="line">roi = frame[r:r + h, c:c + w]</span><br><span class="line">hsv_roi = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)</span><br><span class="line">mask = cv2.inRange(hsv_roi, np.array((<span class="number">140.</span>, <span class="number">140.</span>, <span class="number">140.</span>)), np.array((<span class="number">290.</span>, <span class="number">290.</span>, <span class="number">290.</span>)))</span><br><span class="line">roi_hist = cv2.calcHist([hsv_roi], [<span class="number">0</span>], mask, [<span class="number">180</span>], [<span class="number">0</span>, <span class="number">180</span>])</span><br><span class="line">cv2.normalize(roi_hist, roi_hist, <span class="number">0</span>, <span class="number">255</span>, cv2.NORM_MINMAX)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Setup the termination criteria, either 10 iteration or move by at least 1 pt</span></span><br><span class="line">term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">True</span>):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ret == <span class="keyword">True</span>:</span><br><span class="line">        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)</span><br><span class="line">        dst = cv2.calcBackProject([hsv], [<span class="number">0</span>], roi_hist, [<span class="number">0</span>, <span class="number">180</span>], <span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line">        <span class="comment"># apply meanshift to get the new location</span></span><br><span class="line">        ret, track_window = cv2.meanShift(dst, track_window, term_crit)</span><br><span class="line">​</span><br><span class="line">        <span class="comment"># Draw it on image</span></span><br><span class="line">        x, y, w, h = track_window</span><br><span class="line">        img2 = cv2.rectangle(frame, (x, y), (x + w, y + h), <span class="number">255</span>, <span class="number">2</span>)</span><br><span class="line">        cv2.imshow(<span class="string">'img2'</span>, img2)</span><br><span class="line">​</span><br><span class="line">        k = cv2.waitKey(<span class="number">60</span>) &amp; <span class="number">0xff</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">27</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cv2.imwrite(chr(k) + <span class="string">".jpg"</span>, img2)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">​</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line">cap.release()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/meanshift跟踪算法/6.png" height="236" width="224"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/RANSAC算法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/opencv和图像处理/RANSAC算法/" itemprop="url">RANSAC算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T13:13:26+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;随机抽样一致算法(<code>random sample consensus</code>，<code>RANSAC</code>)采用迭代的方式从一组包含离群的被观测数据中估算出数学模型的参数。它是一种不确定的算法，即有一定的概率得出一个合理的结果；为了提高概率必须提高迭代次数。<br>&emsp;&emsp;<code>RANSAC</code>算法的基本假设是样本中包含正确数据(<code>inliers</code>，可以被模型描述的数据)，也包含异常数据(<code>outliers</code>，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。同时<code>RANSAC</code>也假设，给定一组正确的数据，存在可以计算出符合这些数据的模型参数的方法。<br>&emsp;&emsp;一个简单的例子是从一组观测数据中找出合适的<code>2</code>维直线。假设观测数据中包含局内点和局外点，其中局内点近似的被直线所通过，而局外点远离于直线。简单的最小二乘法不能找到适应于局内点的直线，原因是最小二乘法尽量去适应包括局外点在内的所有点。相反，<code>RANSAC</code>能得出一个仅仅用局内点计算出模型，并且概率还足够高。但是，<code>RANSAC</code>并不能保证结果一定正确，为了保证算法有足够高的合理概率，我们必须小心的选择算法的参数。左图是包含很多局外点的数据集，右图是<code>RANSAC</code>找到的直线，注意局外点并不影响结果。</p>
<p><img src="/2019/03/07/opencv和图像处理/RANSAC算法/1.png"></p>
<p>&emsp;&emsp;<code>RANSAC</code>算法的输入是一组观测数据，一个可以解释或者适应于观测数据的参数化模型，一些可信的参数。<code>RANSAC</code>通过反复选择数据中的一组随机子集来达成目标。被选取的子集被假设为局内点，并用下述方法进行验证：</p>
<ol>
<li>有一个模型适应于假设的局内点，即所有的未知参数都能从假设的局内点计算得出。</li>
<li>用<code>1</code>中得到的模型去测试所有的其它数据，如果某个点适用于估计的模型，认为它也是局内点。</li>
<li>如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。</li>
<li>然后，用所有假设的局内点去重新估计模型，因为它仅仅被初始的假设局内点估计过。</li>
<li>最后，通过估计局内点与模型的错误率来评估模型。</li>
</ol>
<p>这个过程被重复执行固定的次数，每次产生的模型要么因为局内点太少而被舍弃，要么因为比现有的模型更好而被选用。该流程如下：</p>
<p><img src="/2019/03/07/opencv和图像处理/RANSAC算法/2.png" height="370" width="844"></p>
<p>&emsp;&emsp;<code>wiki</code>上的伪代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Given:</span><br><span class="line">    data - a <span class="built_in">set</span> of observed data points</span><br><span class="line">    model - a model that can be fitted to data points</span><br><span class="line">    n - the minimum number of data values required to fit the model</span><br><span class="line">    k - the maximum number of iterations allowed in the algorithm</span><br><span class="line">    t - a threshold value <span class="keyword">for</span> determining when a data point fits a model</span><br><span class="line">    d - the number of close data values required to assert that a model fits well to data</span><br><span class="line">Return:</span><br><span class="line">    bestfit - <span class="function">model parameters which best fit the <span class="title">data</span> <span class="params">(<span class="keyword">or</span> nil <span class="keyword">if</span> no good model is found)</span></span></span><br><span class="line">​</span><br><span class="line">iterations = <span class="number">0</span></span><br><span class="line">bestfit = nil</span><br><span class="line">besterr = something really large</span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> iterations &lt; k &#123;</span><br><span class="line">    maybeinliers = n randomly selected values from data</span><br><span class="line">    maybemodel = model parameters fitted to maybeinliers</span><br><span class="line">    alsoinliers = empty <span class="built_in">set</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> every point in data <span class="keyword">not</span> in maybeinliers &#123;</span><br><span class="line">        <span class="keyword">if</span> point fits maybemodel with an error smaller than t</span><br><span class="line">             add point to alsoinliers</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> the number of elements in alsoinliers is &gt; d &#123;</span><br><span class="line">        % <span class="keyword">this</span> implies that we may have found a good model</span><br><span class="line">        % now test how good it is</span><br><span class="line">        bettermodel = model parameters fitted to all points in maybeinliers <span class="keyword">and</span> alsoinliers</span><br><span class="line">        thiserr = a measure of how well model fits these points</span><br><span class="line">        <span class="keyword">if</span> thiserr &lt; besterr &#123;</span><br><span class="line">            bestfit = bettermodel</span><br><span class="line">            besterr = thiserr</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    increment iterations</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> bestfit</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;While the parameter values of <code>t</code> and <code>d</code> have to be calculated from the individual requirements it can be experimentally determined. The interesting parameter of the <code>RANSAC</code> algorithm is <code>k</code>. To calculate the parameter <code>k</code> given the known probability <code>w</code> of a good data value, the probability <code>z</code> of seeing only bad data values is used:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = (<span class="number">1</span> - w^n)^k</span><br></pre></td></tr></table></figure>
<p>which leads to:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k = <span class="built_in">log</span>(z)/<span class="built_in">log</span>(<span class="number">1</span> - w^n)</span><br></pre></td></tr></table></figure>
<p>To gain additional confidence, the standard deviation or multiples thereof can be added to <code>k</code>. The standard deviation of <code>k</code> is defined as:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SD(x) = <span class="built_in">sqrt</span>(<span class="number">1</span> - w^n)/w^n</span><br></pre></td></tr></table></figure>
<p>A common case is that <code>w</code> is not well known beforehand, but some rough value can be given. If <code>n</code> data values are given, the probability of success is <code>w^n</code>.<br>&emsp;&emsp;<code>python</code>代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> scipy  <span class="comment"># use numpy if scipy unavailable</span></span><br><span class="line"><span class="keyword">import</span> scipy.linalg  <span class="comment"># use numpy if scipy unavailable</span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ransac</span><span class="params">(data, model, n, k, t, d, debug=False, return_all=False)</span>:</span></span><br><span class="line">    iterations = <span class="number">0</span></span><br><span class="line">    bestfit = <span class="keyword">None</span></span><br><span class="line">    besterr = numpy.inf</span><br><span class="line">    best_inlier_idxs = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> iterations &lt; k:</span><br><span class="line">        maybe_idxs, test_idxs = random_partition(n, data.shape[<span class="number">0</span>])</span><br><span class="line">        maybeinliers = data[maybe_idxs, :]</span><br><span class="line">        test_points = data[test_idxs]</span><br><span class="line">        maybemodel = model.fit(maybeinliers)</span><br><span class="line">        test_err = model.get_error(test_points, maybemodel)</span><br><span class="line">        also_idxs = test_idxs[test_err &lt; t]  <span class="comment"># select indices of rows with accepted points</span></span><br><span class="line">        alsoinliers = data[also_idxs, :]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> debug:</span><br><span class="line">            print(<span class="string">'test_err.min()'</span>, test_err.min())</span><br><span class="line">            print(<span class="string">'test_err.max()'</span>, test_err.max())</span><br><span class="line">            print(<span class="string">'numpy.mean(test_err)'</span>, numpy.mean(test_err))</span><br><span class="line">            print(<span class="string">'iteration %d:len(alsoinliers) = %d'</span> % (iterations, len(alsoinliers)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(alsoinliers) &gt; d:</span><br><span class="line">            betterdata = numpy.concatenate((maybeinliers, alsoinliers))</span><br><span class="line">            bettermodel = model.fit(betterdata)</span><br><span class="line">            better_errs = model.get_error(betterdata, bettermodel)</span><br><span class="line">            thiserr = numpy.mean(better_errs)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> thiserr &lt; besterr:</span><br><span class="line">                bestfit = bettermodel</span><br><span class="line">                besterr = thiserr</span><br><span class="line">                best_inlier_idxs = numpy.concatenate((maybe_idxs, also_idxs))</span><br><span class="line"></span><br><span class="line">        iterations += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> bestfit <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"did not meet fit acceptance criteria"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> return_all:</span><br><span class="line">        <span class="keyword">return</span> bestfit, &#123;<span class="string">'inliers'</span>: best_inlier_idxs&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> bestfit</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_partition</span><span class="params">(n, n_data)</span>:</span></span><br><span class="line">    <span class="string">""" return n random rows of data (and also the other len(data) - n rows) """</span></span><br><span class="line">    all_idxs = numpy.arange(n_data)</span><br><span class="line">    numpy.random.shuffle(all_idxs)</span><br><span class="line">    idxs1 = all_idxs[:n]</span><br><span class="line">    idxs2 = all_idxs[n:]</span><br><span class="line">    <span class="keyword">return</span> idxs1, idxs2</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearLeastSquaresModel</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    linear system solved using linear least squares</span></span><br><span class="line"><span class="string">    This class serves as an example that fulfills the model interface</span></span><br><span class="line"><span class="string">    needed by the ransac() function.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_columns, output_columns, debug=False)</span>:</span></span><br><span class="line">        self.input_columns = input_columns</span><br><span class="line">        self.output_columns = output_columns</span><br><span class="line">        self.debug = debug</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        A = numpy.vstack([data[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> self.input_columns]).T</span><br><span class="line">        B = numpy.vstack([data[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> self.output_columns]).T</span><br><span class="line">        x, resids, rank, s = scipy.linalg.lstsq(A, B)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_error</span><span class="params">(self, data, model)</span>:</span></span><br><span class="line">        A = numpy.vstack([data[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> self.input_columns]).T</span><br><span class="line">        B = numpy.vstack([data[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> self.output_columns]).T</span><br><span class="line">        B_fit = scipy.dot(A, model)</span><br><span class="line">        err_per_point = numpy.sum((B - B_fit) ** <span class="number">2</span>, axis=<span class="number">1</span>)  <span class="comment"># sum squared error per row</span></span><br><span class="line">        <span class="keyword">return</span> err_per_point</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># generate perfect input data</span></span><br><span class="line">    n_samples = <span class="number">500</span></span><br><span class="line">    n_inputs = <span class="number">1</span></span><br><span class="line">    n_outputs = <span class="number">1</span></span><br><span class="line">    A_exact = <span class="number">20</span> * numpy.random.random((n_samples, n_inputs))</span><br><span class="line">    perfect_fit = <span class="number">60</span> * numpy.random.normal(size=(n_inputs, n_outputs))  <span class="comment"># the model</span></span><br><span class="line">    B_exact = scipy.dot(A_exact, perfect_fit)</span><br><span class="line">    <span class="keyword">assert</span> B_exact.shape == (n_samples, n_outputs)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># add a little gaussian noise (linear least squares alone should handle this well)</span></span><br><span class="line">    A_noisy = A_exact + numpy.random.normal(size=A_exact.shape)</span><br><span class="line">    B_noisy = B_exact + numpy.random.normal(size=B_exact.shape)</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># add some outliers</span></span><br><span class="line">        n_outliers = <span class="number">100</span></span><br><span class="line">        all_idxs = numpy.arange(A_noisy.shape[<span class="number">0</span>])</span><br><span class="line">        numpy.random.shuffle(all_idxs)</span><br><span class="line">        outlier_idxs = all_idxs[:n_outliers]</span><br><span class="line">        non_outlier_idxs = all_idxs[n_outliers:]</span><br><span class="line">        A_noisy[outlier_idxs] = <span class="number">20</span> * numpy.random.random((n_outliers, n_inputs))</span><br><span class="line">        B_noisy[outlier_idxs] = <span class="number">50</span> * numpy.random.normal(size=(n_outliers, n_outputs))</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># setup model</span></span><br><span class="line">    all_data = numpy.hstack((A_noisy, B_noisy))</span><br><span class="line">    input_columns = range(n_inputs)  <span class="comment"># the first columns of the array</span></span><br><span class="line">    output_columns = [n_inputs + i <span class="keyword">for</span> i <span class="keyword">in</span> range(n_outputs)]  <span class="comment"># the last columns of the array</span></span><br><span class="line">    debug = <span class="keyword">True</span></span><br><span class="line">    model = LinearLeastSquaresModel(input_columns, output_columns, debug=debug)</span><br><span class="line">​</span><br><span class="line">    linear_fit, resids, rank, s = scipy.linalg.lstsq(all_data[:, input_columns], all_data[:, output_columns])</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># run RANSAC algorithm</span></span><br><span class="line">    ransac_fit, ransac_data = ransac(all_data, model,</span><br><span class="line">                                     <span class="number">50</span>, <span class="number">1000</span>, <span class="number">7e3</span>, <span class="number">300</span>,  <span class="comment"># misc. parameters</span></span><br><span class="line">                                     debug=debug, return_all=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">import</span> pylab</span><br><span class="line">​</span><br><span class="line">        sort_idxs = numpy.argsort(A_exact[:, <span class="number">0</span>])</span><br><span class="line">        A_col0_sorted = A_exact[sort_idxs]  <span class="comment"># maintain as rank-2 array</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>:</span><br><span class="line">            pylab.plot(A_noisy[:, <span class="number">0</span>], B_noisy[:, <span class="number">0</span>], <span class="string">'k.'</span>, label=<span class="string">'data'</span>)</span><br><span class="line">            pylab.plot(A_noisy[ransac_data[<span class="string">'inliers'</span>], <span class="number">0</span>], \</span><br><span class="line">                B_noisy[ransac_data[<span class="string">'inliers'</span>], <span class="number">0</span>], <span class="string">'bx'</span>, label=<span class="string">'RANSAC data'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pylab.plot(A_noisy[non_outlier_idxs, <span class="number">0</span>], B_noisy[non_outlier_idxs, <span class="number">0</span>], <span class="string">'k.'</span>, label=<span class="string">'noisy data'</span>)</span><br><span class="line">            pylab.plot(A_noisy[outlier_idxs, <span class="number">0</span>], B_noisy[outlier_idxs, <span class="number">0</span>], <span class="string">'r.'</span>, label=<span class="string">'outlier data'</span>)</span><br><span class="line">        pylab.plot(A_col0_sorted[:, <span class="number">0</span>], numpy.dot(A_col0_sorted, ransac_fit)[:, <span class="number">0</span>], label=<span class="string">'RANSAC fit'</span>)</span><br><span class="line">        pylab.plot(A_col0_sorted[:, <span class="number">0</span>], numpy.dot(A_col0_sorted, perfect_fit)[:, <span class="number">0</span>], label=<span class="string">'exact system'</span>)</span><br><span class="line">        pylab.plot(A_col0_sorted[:, <span class="number">0</span>], numpy.dot(A_col0_sorted, linear_fit)[:, <span class="number">0</span>], label=<span class="string">'linear fit'</span>)</span><br><span class="line">        pylab.legend()</span><br><span class="line">        pylab.show()</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/RANSAC算法/3.png" height="310" width="318"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/使用摄像头/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/07/opencv和图像处理/使用摄像头/" itemprop="url">使用摄像头</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T09:25:17+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;摄像头的使用在<code>OpenCV</code>中十分简单，仅仅调用一个函数，就能从摄像头中读取一帧帧的画面。准备工作极为简单，找一个普通的摄像头，然后插到<code>USB</code>口中，在使用该摄像头前，需要对其进行测试，看它是否可以正常工作。核心代码为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CvCapture *capture = cvCreateCameraCapture ( <span class="number">0</span> );</span><br><span class="line">IplImage *frame = cvQueryFrame ( capture );</span><br></pre></td></tr></table></figure>
<p>第一行创建一个来自摄像头的<code>capture</code>，注意其参数为<code>0</code>，表示随机取一个摄像头(为<code>-1</code>也是可以的)。当电脑上只有一个摄像头时，就填<code>0</code>；如果有多个时，还需要指定设备<code>id</code>。第二行是从该<code>capture</code>中读取下一帧画面，不断地调用该代码，就能不断地得到新的画面。<br>&emsp;&emsp;获取摄像头并且创建窗口显示的代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cv.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cxcore.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;highgui.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span> </span>&#123;</span><br><span class="line">    IplImage *pFrame = <span class="literal">NULL</span>; <span class="comment">/* 声明IplImage指针 */</span></span><br><span class="line">    CvCapture *pCapture = cvCreateCameraCapture ( <span class="number">-1</span> ); <span class="comment">/* 获取摄像头 */</span></span><br><span class="line">    cvNamedWindow ( <span class="string">"video"</span>, <span class="number">1</span> ); <span class="comment">/* 创建窗口 */</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( <span class="number">1</span> ) &#123; <span class="comment">/* 显示视频 */</span></span><br><span class="line">        pFrame = cvQueryFrame ( pCapture );</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( !pFrame ) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        cvShowImage ( <span class="string">"video"</span>, pFrame );</span><br><span class="line">        <span class="keyword">char</span> c = cvWaitKey ( <span class="number">33</span> );</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( c == <span class="number">27</span> ) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    cvReleaseCapture ( &amp;pCapture );</span><br><span class="line">    cvDestroyWindow ( <span class="string">"video"</span> );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/使用摄像头/1.png" height="244" width="314"></p>
<p>上述代码是以图片方式读取摄像头数据，我们可以在其显示到窗口前，对图片进行操作。下面的代码在每帧图片显示在窗口前，对它进行<code>cvCanny</code>的操作：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cv.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"highgui.h"</span></span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span> </span>&#123;</span><br><span class="line">    cvNamedWindow ( <span class="string">"video"</span> );</span><br><span class="line">    CvCapture *capture = cvCreateCameraCapture ( <span class="number">0</span> );</span><br><span class="line">    IplImage *frame = cvQueryFrame ( capture );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( <span class="number">1</span> ) &#123;</span><br><span class="line">        frame = cvQueryFrame ( capture );</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( !frame ) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        IplImage *out = cvCreateImage ( cvGetSize ( frame ), frame-&gt;depth, <span class="number">1</span> );</span><br><span class="line">        cvCanny ( frame, out, <span class="number">10</span>, <span class="number">100</span>, <span class="number">3</span> );</span><br><span class="line">        cvShowImage ( <span class="string">"video"</span>, out );</span><br><span class="line">        cvReleaseImage ( &amp;out );</span><br><span class="line">        <span class="keyword">char</span> c = cvWaitKey ( <span class="number">50</span> );</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( c == <span class="number">27</span> ) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    cvReleaseCapture ( &amp;capture );</span><br><span class="line">    cvDestroyWindow ( <span class="string">"video"</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/使用摄像头/2.png" height="244" width="309"></p>
<p>&emsp;&emsp;<code>ubuntu</code>下安装摄像头驱动使用如下命令：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install cheese</span><br><span class="line">sudo apt-get install camorama</span><br></pre></td></tr></table></figure>
<p>然后打开应用<code>cheese</code>，对摄像头进行测试。</p>
<hr>
<p>&emsp;&emsp;<code>python</code>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># Our operations on the frame come here</span></span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># Display the resulting frame</span></span><br><span class="line">    cv2.imshow(<span class="string">'frame'</span>, gray)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># When everything done, release the capture</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/使用摄像头/3.png" height="254" width="324"></p>
<p>&emsp;&emsp;对视频进行保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Define the codec and create VideoWriter object</span></span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(*<span class="string">'XVID'</span>)</span><br><span class="line">out = cv2.VideoWriter(<span class="string">'output.avi'</span>, fourcc, <span class="number">20.0</span>, (<span class="number">640</span>, <span class="number">480</span>))</span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> (cap.isOpened()):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret == <span class="keyword">True</span>:</span><br><span class="line">        out.write(frame)  <span class="comment"># write the frame</span></span><br><span class="line">        cv2.imshow(<span class="string">'frame'</span>, frame)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># Release everything if job is finished</span></span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">​</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>读取视频并保存为另一种格式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 如果要调用摄像头，则VideoCapture的参数为0；如果读取本地视频，则要用视频地址</span></span><br><span class="line">video_path = <span class="string">"a07_s01_e01_rgb.avi"</span></span><br><span class="line">cap = cv2.VideoCapture(video_path)</span><br><span class="line">fps = cap.get(cv2.CAP_PROP_FPS)  <span class="comment"># 获取视频的帧率</span></span><br><span class="line"><span class="comment"># 获取视频的大小</span></span><br><span class="line">size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))</span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(<span class="string">'m'</span>, <span class="string">'p'</span>, <span class="string">'4'</span>, <span class="string">'v'</span>)  <span class="comment"># 要保存的视频格式</span></span><br><span class="line">output_viedo = cv2.VideoWriter()  <span class="comment"># 把处理过的视频保存下来</span></span><br><span class="line">video_save_path = <span class="string">'HJH_dealt.mp4'</span>  <span class="comment"># 保存的视频地址</span></span><br><span class="line">output_viedo.open(video_save_path, fourcc, fps, size, <span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    ret, image_np = cap.read()</span><br><span class="line">    <span class="keyword">if</span> ret:</span><br><span class="line">        <span class="comment"># 此处省略对image_np的处理，此为一帧图片</span></span><br><span class="line">        cv2.imshow(<span class="string">'object detection'</span>, cv2.resize(image_np, (<span class="number">800</span>, <span class="number">600</span>)))</span><br><span class="line">        output_viedo.write(image_np)  <span class="comment"># 把帧写入到视频中</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">25</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            cv2.destroyAllWindows()</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">​</span><br><span class="line">output_viedo.release()  <span class="comment"># 释放</span></span><br><span class="line">cap.release()  <span class="comment"># 释放</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/06/opencv和图像处理/Sobel算子/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/06/opencv和图像处理/Sobel算子/" itemprop="url">Sobel算子</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-06T22:39:24+08:00">
                2019-03-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>Sobel</code>算子依然是一种过滤器，只是其是带有方向的。在<code>OpenCV</code>中，使用<code>Sobel</code>算子的函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst = cv2.Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>src</code>：需要处理的图像；</li>
<li><code>ddepth</code>是图像的深度，<code>-1</code>表示采用的是与原图像相同的深度，目标图像的深度必须大于等于原图像的深度；</li>
<li><code>dx</code>和<code>dy</code>：求导的阶数，<code>0</code>表示这个方向上没有求导，一般为<code>0</code>、<code>1</code>、<code>2</code>。</li>
<li><code>ksize</code>：<code>Sobel</code>算子的大小，必须为<code>1</code>、<code>3</code>、<code>5</code>或<code>7</code>。</li>
<li><code>scale</code>：缩放导数的比例常数，默认情况下没有伸缩系数；</li>
<li><code>delta</code>：一个可选的增量，将会加到<code>dst</code>中，默认情况下没有额外的值加到<code>dst</code>中。</li>
<li><code>borderType</code>：图像边界的模式，这个参数默认值为<code>cv2.BORDER_DEFAULT</code>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line">img = cv2.imread(<span class="string">"test.jpg"</span>, <span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line">x = cv2.Sobel(img, cv2.CV_16S, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">y = cv2.Sobel(img, cv2.CV_16S, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line">absX = cv2.convertScaleAbs(x)</span><br><span class="line">absY = cv2.convertScaleAbs(y)</span><br><span class="line">​</span><br><span class="line">dst = cv2.addWeighted(absX, <span class="number">0.5</span>, absY, <span class="number">0.5</span>, <span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line">cv2.imshow(<span class="string">"absX"</span>, absX)</span><br><span class="line">cv2.imshow(<span class="string">"absY"</span>, absY)</span><br><span class="line">cv2.imshow(<span class="string">"Result"</span>, dst)</span><br><span class="line">​</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/06/opencv和图像处理/Sobel算子/1.png" height="222" width="844"></p>
<p>&emsp;&emsp;<code>Sobel</code>函数的第二个参数使用了<code>cv2.CV_16S</code>，因为<code>OpenCV</code>文档对<code>Sobel</code>算子的介绍中有这么一句：in the case of <code>8-bit</code> input images it will result in truncated derivatives，即<code>Sobel</code>函数求完导数后会有负值，还有会大于<code>255</code>的值。而原图像是<code>uint8</code>，所以<code>Sobel</code>建立的图像位数不够，会有截断。因此要使用<code>16</code>位有符号的数据类型，即<code>cv2.CV_16S</code>。<br>&emsp;&emsp;在经过处理后，不要忘记使用<code>convertScaleAbs</code>函数将其转回原来的<code>uint8</code>形式，否则将无法显示图像，而只是一个灰色的窗口。<code>convertScaleAbs</code>的函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst = cv2.convertScaleAbs(src[, dst[, alpha[, beta]]])</span><br></pre></td></tr></table></figure>
<p>参数<code>alpha</code>是伸缩系数，<code>beta</code>是加到结果上的一个值，该函数返回<code>uint8</code>类型的图片。由于<code>Sobel</code>算子是在两个方向计算的，最后还需要用<code>cv2.addWeighted</code>函数将其组合起来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst = cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]])</span><br></pre></td></tr></table></figure>
<p>其中<code>alpha</code>是第一幅图片中元素的权重，<code>beta</code>是第二幅图片中元素的权重，<code>gamma</code>是加到最后结果上的一个值。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/06/opencv和图像处理/Feature Matching/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/06/opencv和图像处理/Feature Matching/" itemprop="url">Feature Matching</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-06T17:47:16+08:00">
                2019-03-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Basics-of-Brute-Force-Matcher"><a href="#Basics-of-Brute-Force-Matcher" class="headerlink" title="Basics of Brute-Force Matcher"></a>Basics of Brute-Force Matcher</h3><p>&emsp;&emsp;<code>Brute-Force</code> matcher is simple. It takes the descriptor of one feature in first set and is matched with all other features in second set using some distance calculation. And the closest one is returned.<br>&emsp;&emsp;For <code>BF</code> matcher, first we have to create the <code>BFMatcher</code> object using <code>cv2.BFMatcher()</code>. It takes two optional params. First one is <code>normType</code>. It specifies the distance measurement to be used. By default, it is <code>cv2.NORM_L2</code>. It is good for <code>SIFT</code>, <code>SURF</code> etc (<code>cv2.NORM_L1</code> is also there). For binary string based descriptors like <code>ORB</code>, <code>BRIEF</code>, <code>BRISK</code> etc, <code>cv2.NORM_HAMMING</code> should be used, which used <code>Hamming</code> distance as measurement. If <code>ORB</code> is using <code>WTA_K == 3</code> or <code>4</code>, <code>cv2.NORM_HAMMING2</code> should be used.<br>&emsp;&emsp;Second param is <code>boolean</code> variable, <code>crossCheck</code> which is <code>false</code> by default. If it is <code>true</code>, <code>Matcher</code> returns only those matches with value <code>(i, j)</code> such that <code>i-th</code> descriptor in set <code>A</code> has <code>j-th</code> descriptor in set <code>B</code> as the best match and <code>vice-versa</code>. That is, the two features in both sets should match each other. It provides consistant result, and is a good alternative to ratio test proposed by <code>D.Lowe</code> in <code>SIFT</code> paper.<br>&emsp;&emsp;Once it is created, two important methods are <code>BFMatcher.match()</code> and <code>BFMatcher.knnMatch()</code>. First one returns the best match. Second method returns <code>k</code> best matches where <code>k</code> is specified by the user. It may be useful when we need to do additional work on that.<br>&emsp;&emsp;Like we used <code>cv2.drawKeypoints()</code> to draw keypoints, <code>cv2.drawMatches()</code> helps us to draw the matches. It stacks two images horizontally and draw lines from first image to second image showing best matches. There is also <code>cv2.drawMatchesKnn</code> which draws all the <code>k</code> best matches. If <code>k = 2</code>, it will draw two <code>match-lines</code> for each keypoint. So we have to pass a mask if we want to selectively draw it.<br>&emsp;&emsp;Let’s see one example for each of <code>SURF</code> and <code>ORB</code> (Both use different distance measurements).</p>
<h3 id="Brute-Force-Matching-with-ORB-Descriptors"><a href="#Brute-Force-Matching-with-ORB-Descriptors" class="headerlink" title="Brute-Force Matching with ORB Descriptors"></a>Brute-Force Matching with ORB Descriptors</h3><p>&emsp;&emsp;Here, we will see a simple example on how to match features between two images. In this case, I have a <code>queryImage</code> and a <code>trainImage</code>. We will try to find the <code>queryImage</code> in <code>trainImage</code> using feature matching (The images are <code>/samples/c/box.png</code> and <code>/samples/c/box_in_scene.png</code>)<br>&emsp;&emsp;We are using <code>SIFT</code> descriptors to match features. So let’s start with loading images, finding descriptors etc.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img1 = cv2.imread(<span class="string">'box.png'</span>, <span class="number">0</span>)  <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv2.imread(<span class="string">'box_in_scene.png'</span>, <span class="number">0</span>)  <span class="comment"># trainImage</span></span><br><span class="line">orb = cv2.ORB()  <span class="comment"># Initiate SIFT detector</span></span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = orb.detectAndCompute(img1, <span class="keyword">None</span>)</span><br><span class="line">kp2, des2 = orb.detectAndCompute(img2, <span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>Next we create a <code>BFMatcher</code> object with distance measurement <code>cv2.NORM_HAMMING</code> (since we are using <code>ORB</code>) and <code>crossCheck</code> is switched on for better results. Then we use <code>Matcher.match()</code> method to get the best matches in two images. We sort them in ascending order of their distances so that best matches (with low distance) come to front. Then we draw only first <code>10</code> matches (Just for sake of visibility. You can increase it as you like):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create BFMatcher object</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># Match descriptors.</span></span><br><span class="line">matches = bf.match(des1, des2)</span><br><span class="line"><span class="comment"># Sort them in the order of their distance.</span></span><br><span class="line">matches = sorted(matches, key=<span class="keyword">lambda</span> x: x.distance)</span><br><span class="line"><span class="comment"># Draw first 10 matches.</span></span><br><span class="line">img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:<span class="number">10</span>], flags=<span class="number">2</span>)</span><br><span class="line">plt.imshow(img3), plt.show()</span><br></pre></td></tr></table></figure>
<p>Below is the result I got:</p>
<p><img src="/2019/03/06/opencv和图像处理/Feature Matching/1.png" height="218" width="327"></p>
<h3 id="What-is-this-Matcher-Object"><a href="#What-is-this-Matcher-Object" class="headerlink" title="What is this Matcher Object"></a>What is this Matcher Object</h3><p>&emsp;&emsp;The result of <code>matches = bf.match(des1, des2)</code> line is a list of <code>DMatch</code> objects. This <code>DMatch</code> object has following attributes:</p>
<ul>
<li><code>DMatch.distance</code>: Distance between descriptors. The lower, the better it is.</li>
<li><code>DMatch.trainIdx</code>: Index of the descriptor in train descriptors.</li>
<li><code>DMatch.queryIdx</code>: Index of the descriptor in query descriptors.</li>
<li><code>DMatch.imgIdx</code>: Index of the train image.</li>
</ul>
<h3 id="Brute-Force-Matching-with-SIFT-Descriptors-and-Ratio-Test"><a href="#Brute-Force-Matching-with-SIFT-Descriptors-and-Ratio-Test" class="headerlink" title="Brute-Force Matching with SIFT Descriptors and Ratio Test"></a>Brute-Force Matching with SIFT Descriptors and Ratio Test</h3><p>&emsp;&emsp;This time, we will use <code>BFMatcher.knnMatch()</code> to get <code>k</code> best matches. In this example, we will take <code>k=2</code> so that we can apply ratio test explained by <code>D.Lowe</code> in his paper.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">img1 = cv2.imread(<span class="string">'box.png'</span>, <span class="number">0</span>)  <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv2.imread(<span class="string">'box_in_scene.png'</span>, <span class="number">0</span>)  <span class="comment"># trainImage</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># Initiate SIFT detector</span></span><br><span class="line">sift = cv2.SIFT()</span><br><span class="line">​</span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1, <span class="keyword">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2, <span class="keyword">None</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># BFMatcher with default params</span></span><br><span class="line">bf = cv2.BFMatcher()</span><br><span class="line">matches = bf.knnMatch(des1, des2, k=<span class="number">2</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Apply ratio test</span></span><br><span class="line">good = []</span><br><span class="line"><span class="keyword">for</span> m, n <span class="keyword">in</span> matches:</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.75</span> * n.distance:</span><br><span class="line">        good.append([m])</span><br><span class="line">​</span><br><span class="line"><span class="comment"># cv2.drawMatchesKnn expects list of lists as matches.</span></span><br><span class="line">img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, flags=<span class="number">2</span>)</span><br><span class="line">​</span><br><span class="line">plt.imshow(img3), plt.show()</span><br></pre></td></tr></table></figure>
<p>See the result below:</p>
<p><img src="/2019/03/06/opencv和图像处理/Feature Matching/2.png"></p>
<h3 id="FLANN-based-Matcher"><a href="#FLANN-based-Matcher" class="headerlink" title="FLANN based Matcher"></a>FLANN based Matcher</h3><p>&emsp;&emsp;<code>FLANN</code> stands for <code>Fast Library</code> for <code>Approximate Nearest Neighbors</code>. It contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. It works more faster than <code>BFMatcher</code> for large datasets. We will see the second example with <code>FLANN</code> based matcher.<br>&emsp;&emsp;For <code>FLANN</code> based matcher, we need to pass two dictionaries which specifies the algorithm to be used, its related parameters etc. First one is <code>IndexParams</code>. For various algorithms, the information to be passed is explained in <code>FLANN</code> docs. As a summary, for algorithms like <code>SIFT</code>, <code>SURF</code> etc. you can pass following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;While using <code>ORB</code>, you can pass the following. The commented values are recommended as per the docs, but it didn’t provide required results in some cases. Other values worked fine.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">index_params = dict(algorithm=FLANN_INDEX_LSH,</span><br><span class="line">                    table_number=<span class="number">6</span>,  <span class="comment"># 12</span></span><br><span class="line">                    key_size=<span class="number">12</span>,  <span class="comment"># 20</span></span><br><span class="line">                    multi_probe_level=<span class="number">1</span>)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Second dictionary is the <code>SearchParams</code>. It specifies the number of times the trees in the index should be recursively traversed. Higher values gives better precision, but also takes more time. If you want to change the value, pass <code>search_params = dict(checks=100)</code>.<br>&emsp;&emsp;With these informations, we are good to go.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">img1 = cv2.imread(<span class="string">'box.png'</span>, <span class="number">0</span>)  <span class="comment"># queryImage</span></span><br><span class="line">img2 = cv2.imread(<span class="string">'box_in_scene.png'</span>, <span class="number">0</span>)  <span class="comment"># trainImage</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># Initiate SIFT detector</span></span><br><span class="line">sift = cv2.SIFT()</span><br><span class="line">​</span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1, <span class="keyword">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2, <span class="keyword">None</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># FLANN parameters</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line">index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=<span class="number">5</span>)</span><br><span class="line">search_params = dict(checks=<span class="number">50</span>)  <span class="comment"># or pass empty dictionary</span></span><br><span class="line">​</span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params, search_params)</span><br><span class="line">​</span><br><span class="line">matches = flann.knnMatch(des1, des2, k=<span class="number">2</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Need to draw only good matches, so create a mask</span></span><br><span class="line">matchesMask = [[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(matches))]</span><br><span class="line">​</span><br><span class="line"><span class="comment"># ratio test as per Lowe's paper</span></span><br><span class="line"><span class="keyword">for</span> i, (m, n) <span class="keyword">in</span> enumerate(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.7</span> * n.distance:</span><br><span class="line">        matchesMask[i] = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">​</span><br><span class="line">draw_params = dict(matchColor=(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), singlePointColor=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), matchesMask=matchesMask, flags=<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line">img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, matches, <span class="keyword">None</span>, **draw_params)</span><br><span class="line">​</span><br><span class="line">plt.imshow(img3, ), plt.show()</span><br></pre></td></tr></table></figure>
<p>See the result below:</p>
<p><img src="/2019/03/06/opencv和图像处理/Feature Matching/3.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/06/opencv和图像处理/cvConvertImage和cvflip函数/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/06/opencv和图像处理/cvConvertImage和cvflip函数/" itemprop="url">cvConvertImage和cvflip函数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-06T15:05:07+08:00">
                2019-03-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="cvflip"><a href="#cvflip" class="headerlink" title="cvflip"></a>cvflip</h3><p>&emsp;&emsp;对图像进行翻转或旋转可以使用<code>cvflip</code>函数，可以实现将一个二维矩阵沿<code>X</code>轴、<code>Y</code>轴或者同时沿<code>XY</code>轴翻转。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">flip</span> <span class="params">( InputArray src, OutputArray dst, <span class="keyword">int</span> ipCode )</span></span>;</span><br></pre></td></tr></table></figure>
<p>参数<code>src</code>是输入矩阵，<code>dst</code>是输出矩阵，<code>flipCode</code>是旋转码，即控制函数对矩阵进行怎样的旋转：</p>
<ul>
<li>当<code>flipCode = 0</code>时，将对矩阵沿<code>X</code>轴方向翻转。</li>
<li>当<code>flipCode &gt; 0</code>时，将对矩阵沿<code>Y</code>轴方向翻转。</li>
<li>当<code>flipCode &lt; 0</code>时，将对矩阵沿<code>XY</code>轴方向翻转。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Mat img = imread ( <span class="string">"timg1.jpg"</span>, CV_LOAD_IMAGE_ANYCOLOR );</span><br><span class="line">    imshow ( <span class="string">"Input"</span>, img );</span><br><span class="line">    cv::flip ( img, img, <span class="number">0</span> );</span><br><span class="line">    imshow ( <span class="string">"Flip"</span>, img );</span><br><span class="line">    waitKey ( <span class="number">0</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/06/opencv和图像处理/cvConvertImage和cvflip函数/1.png" height="254" width="688"></p>
<p>&emsp;&emsp;<code>Python</code>中<code>flip</code>函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flip(src, flipCode, dst=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>src</code>：原图像矩阵。</li>
<li><code>flipCode</code>：翻转方向，<code>1</code>是水平翻转，<code>0</code>是垂直翻转，<code>-1</code>是水平垂直翻转。</li>
<li><code>dst</code>：默认即可。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line">image = cv2.imread(<span class="string">"girl.jpg"</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Flipped Horizontally(水平翻转)</span></span><br><span class="line">h_flip = cv2.flip(image, <span class="number">1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"girl-h.jpg"</span>, h_flip)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Flipped Vertically(垂直翻转)</span></span><br><span class="line">v_flip = cv2.flip(image, <span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">"girl-v.jpg"</span>, v_flip)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># Flipped Horizontally &amp; Vertically(水平垂直翻转)</span></span><br><span class="line">hv_flip = cv2.flip(image, <span class="number">-1</span>)</span><br><span class="line">cv2.imshow(<span class="string">"girl-hv.jpg"</span>, hv_flip)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<h3 id="cvConvertImage"><a href="#cvConvertImage" class="headerlink" title="cvConvertImage"></a>cvConvertImage</h3><p>&emsp;&emsp;函数原型如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cvConvertImage</span> <span class="params">( <span class="keyword">const</span> CvArr *src, CvArr *dst, <span class="keyword">int</span> flags = <span class="number">0</span> )</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>src</code>：源图像的<code>IplImage</code>指针，源图像可以是单个、<code>3</code>个或者<code>4</code>个通道；</li>
<li><code>dst</code>：转换后的图像的<code>IplImage</code>指针，目标图像必须是<code>8</code>位的单通道或者<code>3</code>个通道；</li>
<li><code>flags</code>：转换的模式，可以取<code>0</code>(没有变化)、<code>1</code>(垂直翻转，即沿<code>x</code>轴翻转)和<code>2</code>(交换红蓝信道)。有时摄像机图像格式与图像显示格式会反转，设置这个参数可以在内存中彻底旋转图像。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cv.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">    IplImage *img;</span><br><span class="line">    IplImage *dst;</span><br><span class="line">    img = cvLoadImage ( <span class="string">"timg1.jpg"</span>, <span class="number">0</span> );</span><br><span class="line">    dst = cvCreateImage ( cvGetSize ( img ), IPL_DEPTH_8U, <span class="number">1</span> );</span><br><span class="line">    cvConvertImage ( img, dst, CV_CVTIMG_FLIP );</span><br><span class="line">    cvNamedWindow ( <span class="string">"Imageshow"</span>, <span class="number">1</span> );</span><br><span class="line">    cvShowImage ( <span class="string">"Imageshow"</span>, img );</span><br><span class="line">    cvNamedWindow ( <span class="string">"Converted"</span>, <span class="number">1</span> );</span><br><span class="line">    cvShowImage ( <span class="string">"Converted"</span>, dst );</span><br><span class="line">    cvWaitKey ( <span class="number">0</span> );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/06/opencv和图像处理/cvConvertImage和cvflip函数/2.png" height="254" width="688"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/06/opencv和图像处理/亚像素级角点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/06/opencv和图像处理/亚像素级角点/" itemprop="url">亚像素级角点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-06T12:28:25+08:00">
                2019-03-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;如果我们进行图像处理的目的不是用于识别特征点而是进行稽核测量，则通常需要更高的精度。而<code>cvGoodFeatureToTrack</code>只能提供简单的像素坐标值，但有时候我们会需要实际坐标值而不是整数坐标值，例如想要确定图形中一个尖锐的峰值点的位置，但是峰值点的位置一般都不会位于一个像素点的正中心，这时就可以使用亚像素检测方法。<br>&emsp;&emsp;亚像素级角点的位置在摄像机标定、跟踪并重建摄像机的轨迹或者重建被跟踪目标的三维结构时就是一个基本的测量值。通过<code>cvGoodFeaturesToTrack</code>函数可以求得角点坐标值，接下来就要讨论如何将求得的坐标值精确到亚像素级精度。方法就是向量的点积理论：一个向量和其正交的向量的点积为<code>0</code>，角点就是两个边缘的相交，可以满足这样的情况。</p>
<p><img src="/2019/03/06/opencv和图像处理/亚像素级角点/1.png"></p>
<p>&emsp;&emsp;当要求的点<code>p</code>位于一个区域的内部时，点<code>p</code>边缘是平缓的，它的梯度值为<code>0</code>，此时向量<code>pq</code>的与<code>p</code>的梯度点积为<code>0</code>；当点<code>p</code>位于区域的边缘的时候，向量<code>pq</code>与区域平行，而<code>p</code>的梯度值则与边缘垂直，此时向量<code>pq</code>的与<code>p</code>的梯度点积为<code>0</code>。<br>&emsp;&emsp;这两种情况下，向量<code>pq</code>与<code>p</code>点的梯度都是正交的。先假设起始角点<code>q</code>在实际亚像素级角点<code>p</code>附近，则我们可以在要求的<code>p</code>点的周围取到很多<code>p</code>点的梯度和相关向量<code>pq</code>。令其点积为<code>0</code>，然后就可以通过求解方程组，方程组的解就是角点<code>q</code>的亚像素精度的位置，也就是精确角点的位置。<br>&emsp;&emsp;<code>cvFindCornerSubPix</code>函数原型如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cvFindCornerSubPix</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> CvArr *image, CvPoint2D32f *corners, <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    CvSize win, CvSize zero_zone, CvTermCriteria criteria )</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>image</code>：输入图像。</li>
<li><code>corners</code>：输入角点的初始坐标，也存储精确的输出坐标。</li>
<li><code>count</code>：角点数目。</li>
<li><code>win</code>：搜索窗口的一半尺寸。如果<code>win = (5, 5)</code>，那么使用<code>(5 * 2 + 1) x (5 * 2 + 1) = 11 x 11</code>大小的搜索窗口。</li>
<li><code>zero_zone</code>：死区的一半尺寸，死区为不对搜索区的中央位置做求和运算的区域。它是用来避免自相关矩阵出现的某些可能的奇异性。值为<code>(-1, -1)</code>表示没有死区。</li>
<li><code>criteria</code>：求角点的迭代过程的终止条件。即角点位置的确定，要么迭代数大于某个设定值，或者是精确度达到某个设定值。<code>criteria</code>可以是最大迭代数目，或者是设定的精确度，也可以是它们的组合。</li>
</ul>
<p>&emsp;&emsp;函数<code>cvFindCornerSubPix</code>通过迭代来发现具有子像素精度的角点位置，或如图所示的放射鞍点(<code>radial saddle points</code>)。当找到一个<code>q</code>的新位置时，算法会以这个新的角点作为初始点进行迭代知道满足用户定义的迭代终止条件。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cv.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cxcore.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;highgui.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span> </span>&#123;</span><br><span class="line">    FILE *fp = fopen ( <span class="string">"result.txt"</span>, <span class="string">"w+"</span> ) ;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span> *filename = <span class="string">"timg1.jpg"</span> ;</span><br><span class="line">    IplImage *img = cvLoadImage ( filename, CV_LOAD_IMAGE_COLOR );</span><br><span class="line">    IplImage *img_copy = cvCloneImage ( img ) ;</span><br><span class="line">    IplImage *img_gray = cvCreateImage ( cvGetSize ( img ), IPL_DEPTH_8U, <span class="number">1</span> ) ;</span><br><span class="line">    IplImage *eig_image = cvCreateImage ( cvGetSize ( img ), IPL_DEPTH_32F, <span class="number">1</span> );</span><br><span class="line">    IplImage *temp_image = cvCloneImage ( eig_image ) ;</span><br><span class="line">    cvCvtColor ( img, img_gray, CV_BGR2GRAY );</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> MAX_CORNERS = <span class="number">1000</span> ;</span><br><span class="line">    CvPoint2D32f *corners = <span class="keyword">new</span> CvPoint2D32f[ MAX_CORNERS ];</span><br><span class="line">    <span class="keyword">int</span> corner_count = MAX_CORNERS;</span><br><span class="line">    <span class="keyword">double</span> quality_level = <span class="number">0.1</span>;</span><br><span class="line">    <span class="keyword">double</span> min_distance = <span class="number">5</span>;</span><br><span class="line">    cvGoodFeaturesToTrack (</span><br><span class="line">        img_gray, eig_image, temp_image, corners,</span><br><span class="line">        &amp;corner_count, quality_level, min_distance );</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* draw corners from cvGoodFeaturesToTrack on "img" */</span></span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; corner_count ; ++i ) &#123;</span><br><span class="line">        cvLine ( img, cvPoint ( corners[i].x, corners[i].y ), \</span><br><span class="line">                      cvPoint ( corners[i].x, corners[i].y ), \</span><br><span class="line">                      CV_RGB ( <span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span> ), <span class="number">5</span> );</span><br><span class="line">        <span class="built_in">fprintf</span> ( fp, <span class="string">"\t%f\t%f\n"</span>, corners[i].x, corners[i].y ) ;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="built_in">fprintf</span> ( fp, <span class="string">"\n\n\n\n\n"</span> ) ;</span><br><span class="line">    <span class="keyword">int</span> half_win_size = <span class="number">3</span>; <span class="comment">/* the window size will be 3+1+3 = 7 */</span></span><br><span class="line">    <span class="keyword">int</span> iteration = <span class="number">20</span>;</span><br><span class="line">    <span class="keyword">double</span> epislon = <span class="number">0.1</span>;</span><br><span class="line">    cvFindCornerSubPix (</span><br><span class="line">        img_gray, corners, corner_count,</span><br><span class="line">        cvSize ( half_win_size, half_win_size ),</span><br><span class="line">        cvSize ( <span class="number">-1</span>, <span class="number">-1</span> ), <span class="comment">/* no ignoring the neighbours of the center corner */</span></span><br><span class="line">        cvTermCriteria ( CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, iteration, epislon )</span><br><span class="line">    );</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* draw subpix corners on "img_copy" */</span></span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; corner_count; i++ ) &#123;</span><br><span class="line">        cvLine ( img_copy, cvPoint ( corners[i].x, corners[i].y ), \</span><br><span class="line">                           cvPoint ( corners[i].x, corners[i].y ), \</span><br><span class="line">                           CV_RGB ( <span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span> ), <span class="number">5</span> );</span><br><span class="line">        <span class="built_in">fprintf</span> ( fp, <span class="string">"\t%f\t%f\n"</span>, corners[i].x, corners[i].y ) ;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    cvNamedWindow ( <span class="string">"cvFindCornerSubPix"</span>, CV_WINDOW_AUTOSIZE );</span><br><span class="line">    cvShowImage ( <span class="string">"cvFindCornerSubPix"</span>, img );</span><br><span class="line">    cvNamedWindow ( <span class="string">"cvGoodFeaturesToTrack"</span>, CV_WINDOW_AUTOSIZE );</span><br><span class="line">    cvShowImage ( <span class="string">"cvGoodFeaturesToTrack"</span>, img_copy );</span><br><span class="line">    cvWaitKey ( <span class="number">0</span> );</span><br><span class="line">    cvReleaseImage ( &amp;img_gray );</span><br><span class="line">    cvReleaseImage ( &amp;img );</span><br><span class="line">    cvReleaseImage ( &amp;img_copy );</span><br><span class="line">    cvDestroyWindow ( <span class="string">"cvGoodFeaturesToTrack"</span> );</span><br><span class="line">    cvDestroyWindow ( <span class="string">"cvFindCornerSubPix"</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/06/opencv和图像处理/亚像素级角点/2.png" height="252" width="693"></p>
<p>&emsp;&emsp;<code>CvTermCriteria</code>是迭代算法的终止准则：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 迭代算法的终止条件 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CV_TERMCRIT_ITER   1 <span class="comment">/* 在完成最大的迭代次数之后，停止算法 */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CV_TERMCRIT_NUMBER CV_TERMCRIT_ITER</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CV_TERMCRIT_EPS    2 <span class="comment">/* 当算法的精确度小于参数“double epsilon”指定的精确度时，停止算法 */</span></span></span><br><span class="line">​</span><br><span class="line"><span class="comment">// CV_TERMCRIT_ITER + CV_TERMCRIT_EPS -- 无论是哪一个条件先达到，都停止算法</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">CvTermCriteria</span> &#123;</span></span><br><span class="line">    <span class="comment">/* the type of the termination criteria 迭代算法终止条件的类型 */</span></span><br><span class="line">    <span class="keyword">int</span> type; <span class="comment">/* may be combination of CV_TERMCRIT_ITER, CV_TERMCRIT_EPS */</span></span><br><span class="line">    <span class="keyword">int</span> max_iter; <span class="comment">/* Maximum number of iterations 最大的迭代次数 */</span></span><br><span class="line">    <span class="keyword">double</span> epsilon; <span class="comment">/* Required accuracy 所要求的精确度 */</span></span><br><span class="line">&#125; CvTermCriteria;</span><br><span class="line">​</span><br><span class="line"><span class="comment">/* 下面这个函数的功能类似于构造函数，但实际上它并不是 */</span></span><br><span class="line"><span class="function">CV_INLINE CvTermCriteria <span class="title">cvTermCriteria</span> <span class="params">( <span class="keyword">int</span> type, <span class="keyword">int</span> max_iter, <span class="keyword">double</span> epsilon )</span> </span>&#123;</span><br><span class="line">    CvTermCriteria t;</span><br><span class="line">    t.type = type;</span><br><span class="line">    t.max_iter = max_iter;</span><br><span class="line">    t.epsilon = ( <span class="keyword">float</span> ) epsilon;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="comment">/* Termination criteria in iterative algorithms 迭代算法中的终止条件 */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CV_EXPORTS</span> <span class="title">TermCriteria</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> &#123;</span><br><span class="line">        COUNT = <span class="number">1</span>, <span class="comment">/* the maximum number of iterations or elements to compute */</span></span><br><span class="line">        MAX_ITER = COUNT, <span class="comment">/* ditto */</span></span><br><span class="line">        EPS = <span class="number">2</span> <span class="comment">/* the desired accuracy or change in parameters at which the iterative algorithm stops */</span></span><br><span class="line">    &#125;;</span><br><span class="line">​</span><br><span class="line">    TermCriteria(); <span class="comment">/* default constructor 默认构造函数 */</span></span><br><span class="line">    TermCriteria ( <span class="keyword">int</span> type, <span class="keyword">int</span> maxCount, <span class="keyword">double</span> epsilon ); <span class="comment">/* full constructor 完全构造函数 */</span></span><br><span class="line">    <span class="comment">/* conversion from CvTermCriteria CvTermCriteria结构体和TermCriteria类的转换构造函数 */</span></span><br><span class="line">    TermCriteria ( <span class="keyword">const</span> CvTermCriteria &amp;criteria );</span><br><span class="line">    <span class="function"><span class="keyword">operator</span> <span class="title">CvTermCriteria</span><span class="params">()</span> <span class="keyword">const</span></span>; <span class="comment">/* conversion to CvTermCriteria */</span></span><br><span class="line">    <span class="comment">/* TermCriteria类的三个数据成员 -- 终止条件的类型、最大迭代次数、所期望的精度 */</span></span><br><span class="line">    <span class="keyword">int</span> type; <span class="comment">/* the type of termination criteria: COUNT, EPS or COUNT + EPS */</span></span><br><span class="line">    <span class="keyword">int</span> maxCount; <span class="comment">/* the maximum number of iterations/elements */</span></span><br><span class="line">    <span class="keyword">double</span> epsilon; <span class="comment">/* the desired accuracy */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<hr>
<p>&emsp;&emsp;<code>OpenCV</code>为我们提供了函数<code>cv2.cornerSubPix</code>，它可以提供亚像素级别的角点检测。首先要找到<code>Harris</code>角点，然后将角点的重心传给这个函数进行修正。<code>Harris</code>角点用红色像素标出，绿色像素是修正后的像素。在使用这个函数时，我们要定义一个迭代停止条件，当迭代次数达到或者精度条件满足后迭代就会停止。我们同样需要定义进行角点搜索的邻域大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​</span><br><span class="line">filename = <span class="string">'timg1.jpg'</span></span><br><span class="line">img = cv2.imread(filename)</span><br><span class="line">cv2.imshow(<span class="string">'img'</span>, img)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># find Harris corners</span></span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv2.cornerHarris(gray, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0.04</span>)</span><br><span class="line">dst = cv2.dilate(dst, <span class="keyword">None</span>)</span><br><span class="line">ret, dst = cv2.threshold(dst, <span class="number">0.01</span> * dst.max(), <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">dst = np.uint8(dst)</span><br><span class="line"><span class="comment"># find centroids</span></span><br><span class="line"><span class="comment"># connectedComponentsWithStats(InputArray image, OutputArray labels, OutputArray stats,</span></span><br><span class="line"><span class="comment"># OutputArray centroids, int connectivity=8, int ltype=CV_32S)</span></span><br><span class="line">ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)</span><br><span class="line"><span class="comment"># define the criteria to stop and refine the corners</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">100</span>, <span class="number">0.001</span>)</span><br><span class="line"><span class="comment"># Python: cv2.cornerSubPix(image, corners, winSize, zeroZone, criteria)</span></span><br><span class="line"><span class="comment"># zeroZone -- Half of the size of the dead region in the middle of the search zone</span></span><br><span class="line"><span class="comment"># over which the summation in the formula below is not done. It is used sometimes</span></span><br><span class="line"><span class="comment"># to avoid possible singularities of the autocorrelation matrix. The value of (-1,-1)</span></span><br><span class="line"><span class="comment"># indicates that there is no such a size.</span></span><br><span class="line"><span class="comment"># 返回值由角点坐标组成的一个数组(而非图像)</span></span><br><span class="line">corners = cv2.cornerSubPix(gray, np.float32(centroids), (<span class="number">5</span>, <span class="number">5</span>), (<span class="number">-1</span>, <span class="number">-1</span>), criteria)</span><br><span class="line"><span class="comment"># Now draw them</span></span><br><span class="line">res = np.hstack((centroids, corners))</span><br><span class="line"><span class="comment"># np.int0 可以用来省略小数点后面的数字(非四舍五入)</span></span><br><span class="line">res = np.int0(res)</span><br><span class="line">img[res[:, <span class="number">1</span>], res[:, <span class="number">0</span>]] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]</span><br><span class="line">img[res[:, <span class="number">3</span>], res[:, <span class="number">2</span>]] = [<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>]</span><br><span class="line">cv2.imshow(<span class="string">'target'</span>, img)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/06/opencv和图像处理/亚像素级角点/2.png" height="254" width="710"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/93/">93</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">930</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
