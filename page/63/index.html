<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="暴徒">
<meta property="og:url" content="http://fukangwei.gitee.io/page/63/index.html">
<meta property="og:site_name" content="暴徒">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="暴徒">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/page/63/">





  <title>暴徒</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">暴徒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/TensorFlow之参数初始化/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/TensorFlow之参数初始化/" itemprop="url">TensorFlow之参数初始化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T14:23:16+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;CNN中最重要的就是参数了，包括<code>W</code>和<code>b</code>。训练<code>CNN</code>的最终目的就是得到最好的参数，使得目标函数取得最小值。参数的初始化也同样重要，因此微调受到很多人的重视。<code>tf</code>提供的所有初始化方法都定义在<code>tensorflow/python/ops/init_ops.py</code>。</p>
<h3 id="tf-constant-initializer"><a href="#tf-constant-initializer" class="headerlink" title="tf.constant_initializer"></a>tf.constant_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.Constant</code>，初始化为常数，通常偏置项就是用它初始化的。由它衍生出两个初始化方法：</p>
<ul>
<li><code>tf.zeros_initializer</code>：可以简写为<code>tf.Zeros</code>。</li>
<li><code>tf.ones_initializer</code>：可以简写为<code>tf.Ones</code>。</li>
</ul>
<p>在卷积层中，将偏置项<code>b</code>初始化为<code>0</code>，有多种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conv1 = tf.layers.conv2d(  <span class="comment"># 方法1</span></span><br><span class="line">    batch_images, filters=<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, activation=tf.nn.relu,</span><br><span class="line">    kernel_initializer=tf.TruncatedNormal(stddev=<span class="number">0.01</span>), bias_initializer=tf.Constant(<span class="number">0</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">bias_initializer = tf.constant_initializer(<span class="number">0</span>)  <span class="comment"># 方法2</span></span><br><span class="line">bias_initializer = tf.zeros_initializer()  <span class="comment"># 方法3</span></span><br><span class="line">bias_initializer = tf.Zeros()  <span class="comment"># 方法4</span></span><br></pre></td></tr></table></figure>
<p>将<code>W</code>初始化成拉普拉斯算子的方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">value = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">-8</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">init = tf.constant_initializer(value)</span><br><span class="line">W = tf.get_variable(<span class="string">'W'</span>, shape=[<span class="number">3</span>, <span class="number">3</span>], initializer=init)</span><br></pre></td></tr></table></figure>
<h3 id="tf-truncated-normal-initializer"><a href="#tf-truncated-normal-initializer" class="headerlink" title="tf.truncated_normal_initializer"></a>tf.truncated_normal_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.TruncatedNormal</code>，生成截断正态分布的随机数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.TruncatedNormal(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=<span class="keyword">None</span>, dtype=dtypes.float32)</span><br></pre></td></tr></table></figure>
<p>这四个参数分别用于指定均值、标准差、随机数种子和随机数的数据类型，一般只需要设置<code>stddev</code>这一个参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conv1 = tf.layers.conv2d(  <span class="comment"># 代码示例1</span></span><br><span class="line">    batch_images, filters=<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, activation=tf.nn.relu,</span><br><span class="line">    kernel_initializer=tf.TruncatedNormal(stddev=<span class="number">0.01</span>), bias_initializer=tf.Constant(<span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line">conv1 = tf.layers.conv2d(  <span class="comment"># 代码示例2</span></span><br><span class="line">    batch_images, filters=<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, activation=tf.nn.relu,</span><br><span class="line">    kernel_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">    bias_initializer=tf.zero_initializer())</span><br></pre></td></tr></table></figure>
<h3 id="tf-random-normal-initializer"><a href="#tf-random-normal-initializer" class="headerlink" title="tf.random_normal_initializer"></a>tf.random_normal_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.RandomNormal</code>，生成标准正态分布的随机数，参数和<code>truncated_normal_initializer</code>一样。</p>
<h3 id="tf-random-uniform-initializer"><a href="#tf-random-uniform-initializer" class="headerlink" title="tf.random_uniform_initializer"></a>tf.random_uniform_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.RandomUniform</code>，生成均匀分布的随机数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.RandomUniform(minval=<span class="number">0</span>, maxval=<span class="keyword">None</span>, seed=<span class="keyword">None</span>, dtype=dtypes.float32)</span><br></pre></td></tr></table></figure>
<p>这四个参数分别用于指定最小值、最大值、随机数种子和类型。</p>
<h3 id="tf-uniform-unit-scaling-initializer"><a href="#tf-uniform-unit-scaling-initializer" class="headerlink" title="tf.uniform_unit_scaling_initializer"></a>tf.uniform_unit_scaling_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.UniformUnitScaling</code>，和均匀分布差不多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.UniformUnitScaling(factor=<span class="number">1.0</span>, seed=<span class="keyword">None</span>, dtype=dtypes.float32)</span><br></pre></td></tr></table></figure>
<p>只是这个初始化方法不需要指定最小最大值，它们是通过计算得到的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">max_val = math.sqrt(<span class="number">3</span> / input_size) * factor</span><br><span class="line">min_val = - max_val</span><br></pre></td></tr></table></figure>
<p>这里的<code>input_size</code>是指输入数据的维数，假设输入为<code>x</code>，运算为<code>x * W</code>，则<code>input_size= W.shape[0]</code>，它的分布区间为<code>[-max_val, max_val]</code>。</p>
<h3 id="tf-variance-scaling-initializer"><a href="#tf-variance-scaling-initializer" class="headerlink" title="tf.variance_scaling_initializer"></a>tf.variance_scaling_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.VarianceScaling</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.VarianceScaling(scale=<span class="number">1.0</span>, mode=<span class="string">"fan_in"</span>, distribution=<span class="string">"normal"</span>, seed=<span class="keyword">None</span>, dtype=dtypes.float32)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>scale</code>：缩放尺度(正浮点数)。</li>
<li><code>mode</code>：<code>fan_in</code>、<code>fan_out</code>和<code>fan_avg</code>中的一个，用于计算标准差<code>stddev</code>的值。</li>
<li><code>distribution</code>：分布类型，<code>normal</code>或<code>uniform</code>中的一个。</li>
</ul>
<ol>
<li>当<code>distribution = &quot;normal&quot;</code>时，生成<code>truncated normal distribution</code>(截断正态分布)的随机数，其中<code>stddev = sqrt(scale / n)</code>，<code>n</code>的计算与<code>mode</code>参数有关。如果<code>mode = &quot;fan_in&quot;</code>，<code>n</code>为输入单元的结点数；如果<code>mode = &quot;fan_out&quot;</code>，<code>n</code>为输出单元的结点数；如果<code>mode = &quot;fan_avg&quot;</code>，<code>n</code>为输入和输出单元结点数的平均值</li>
<li>当<code>distribution = &quot;uniform&quot;</code>时，生成均匀分布的随机数，假设分布区间为<code>[-limit, limit]</code>，则：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limit = sqrt(<span class="number">3</span> * scale / n)</span><br></pre></td></tr></table></figure>
<h3 id="tf-orthogonal-initializer"><a href="#tf-orthogonal-initializer" class="headerlink" title="tf.orthogonal_initializer"></a>tf.orthogonal_initializer</h3><p>&emsp;&emsp;可以简写为<code>tf.Orthogonal</code>，生成正交矩阵的随机数。当需要生成的参数是<code>2</code>维时，这个正交矩阵是由均匀分布的随机数矩阵经过<code>SVD</code>分解而来。</p>
<h3 id="tf-glorot-uniform-initializer"><a href="#tf-glorot-uniform-initializer" class="headerlink" title="tf.glorot_uniform_initializer"></a>tf.glorot_uniform_initializer</h3><p>&emsp;&emsp;也称为<code>Xavier uniform initializer</code>，由一个均匀分布(<code>uniform distribution</code>)来初始化数据。假设均匀分布的区间是<code>[-limit, limit]</code>，则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limit = sqrt(<span class="number">6</span> / (fan_in + fan_out))</span><br></pre></td></tr></table></figure>
<p>其中的<code>fan_in</code>和<code>fan_out</code>分别表示输入单元的结点数和输出单元的结点数。</p>
<h3 id="glorot-normal-initializer"><a href="#glorot-normal-initializer" class="headerlink" title="glorot_normal_initializer"></a>glorot_normal_initializer</h3><p>&emsp;&emsp;也称之为<code>Xavier normal initializer</code>，由一个<code>truncated normal distribution</code>来初始化数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stddev = sqrt(<span class="number">2</span> / (fan_in + fan_out))</span><br></pre></td></tr></table></figure>
<p>其中的<code>fan_in</code>和<code>fan_out</code>分别表示输入单元的结点数和输出单元的结点数。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/Keras之模型保存和加载/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/Keras之模型保存和加载/" itemprop="url">Keras之模型保存和加载</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T14:04:48+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;不建议使用<code>pickle</code>或<code>cPickle</code>来保存<code>Keras</code>模型。你可以使用<code>model.save(filepath)</code>将<code>Keras</code>模型保存到单个<code>HDF5</code>文件中，该文件将包含：</p>
<ul>
<li>模型的结构，允许重新创建模型。</li>
<li>模型的权重。</li>
<li>训练配置项(损失函数和优化器)。</li>
<li>优化器状态，允许准确地从你上次结束的地方继续训练。</li>
</ul>
<p>你可以使用<code>keras.models.load_model(filepath)</code>重新实例化模型。<code>load_model</code>还将负责使用保存的训练配置项来编译模型(除非模型从未编译过)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">​</span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)  <span class="comment"># 创建HDF5文件“my_model.h5”</span></span><br><span class="line"><span class="keyword">del</span> model  <span class="comment"># 删除现有模型</span></span><br><span class="line">model = load_model(<span class="string">'my_model.h5'</span>)  <span class="comment"># 返回一个编译好的模型，与之前那个相同</span></span><br></pre></td></tr></table></figure>
<p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">​</span><br><span class="line">np.random.seed(<span class="number">1337</span>)  <span class="comment"># for reproducibility</span></span><br><span class="line">X = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">200</span>)  <span class="comment"># create some data</span></span><br><span class="line">np.random.shuffle(X)  <span class="comment"># randomize the data</span></span><br><span class="line">Y = <span class="number">0.5</span> * X + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, (<span class="number">200</span>,))</span><br><span class="line">X_train, Y_train = X[:<span class="number">160</span>], Y[:<span class="number">160</span>]  <span class="comment"># first 160 data points</span></span><br><span class="line">X_test, Y_test = X[<span class="number">160</span>:], Y[<span class="number">160</span>:]  <span class="comment"># last 40 data points</span></span><br><span class="line">​</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(output_dim=<span class="number">1</span>, input_dim=<span class="number">1</span>))</span><br><span class="line">model.compile(loss=<span class="string">'mse'</span>, optimizer=<span class="string">'sgd'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">301</span>):</span><br><span class="line">    cost = model.train_on_batch(X_train, Y_train)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># save</span></span><br><span class="line">print(<span class="string">'test before save: '</span>, model.predict(X_test[<span class="number">0</span>:<span class="number">2</span>]))</span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)  <span class="comment"># HDF5 file, you have to pip3 install h5py if don't have it</span></span><br><span class="line"><span class="keyword">del</span> model  <span class="comment"># deletes the existing model</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = load_model(<span class="string">'my_model.h5'</span>)</span><br><span class="line">print(<span class="string">'test after load: '</span>, model.predict(X_test[<span class="number">0</span>:<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="只保存-加载模型的结构"><a href="#只保存-加载模型的结构" class="headerlink" title="只保存/加载模型的结构"></a>只保存/加载模型的结构</h3><p>&emsp;&emsp;如果你只需要保存模型的结构，而非其权重或训练配置项，则可以执行以下操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">json_string = model.to_json() <span class="comment"># 保存为JSON</span></span><br><span class="line">yaml_string = model.to_yaml() <span class="comment"># 保存为YAML</span></span><br></pre></td></tr></table></figure>
<p>生成的<code>JSON</code>或<code>YAML</code>文件是人类可读的，如果需要的话还可以手动编辑。<br>&emsp;&emsp;你可以从这些数据建立一个新的模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从JSON重建模型：</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</span><br><span class="line">model = model_from_json(json_string)</span><br><span class="line"><span class="comment"># 从YAML重建模型：</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_yaml</span><br><span class="line">model = model_from_yaml(yaml_string)</span><br></pre></td></tr></table></figure>
<h3 id="只保存-加载模型的权重"><a href="#只保存-加载模型的权重" class="headerlink" title="只保存/加载模型的权重"></a>只保存/加载模型的权重</h3><p>&emsp;&emsp;如果您只需要模型的权重，可以使用下面的代码以<code>HDF5</code>格式进行保存。请注意，首先需要安装<code>HDF5</code>的<code>Python</code>库<code>h5py</code>，它不包含在<code>Keras</code>中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>假设你有用于实例化模型的代码，则可以将保存的权重加载到具有相同结构的模型中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>如果你需要将权重加载到不同的结构(有一些共同层)的模型中，例如<code>fine-tune</code>或<code>transfer-learning</code>，则可以按层的名字来加载权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>, by_name=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>实例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">假设原始模型如下所示：</span></span><br><span class="line"><span class="string">model = Sequential()</span></span><br><span class="line"><span class="string">model.add(Dense(2, input_dim=3, name='dense_1'))</span></span><br><span class="line"><span class="string">model.add(Dense(3, name='dense_2'))</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">model.save_weights(fname)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model = Sequential()  <span class="comment"># 新模型</span></span><br><span class="line">model.add(Dense(<span class="number">2</span>, input_dim=<span class="number">3</span>, name=<span class="string">'dense_1'</span>))  <span class="comment"># 将被加载</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, name=<span class="string">'new_dense'</span>))  <span class="comment"># 将不被加载</span></span><br><span class="line">model.load_weights(fname, by_name=<span class="keyword">True</span>)  <span class="comment"># 从第一个模型加载权重，只会影响第一层(dense_1)</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/Keras之初始化方法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/Keras之初始化方法/" itemprop="url">Keras之初始化方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T13:03:30+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;初始化方法定义了对<code>Keras</code>层设置初始化权重的方法。不同的层可能使用不同的关键字来传递初始化方法，一般来说，指定初始化方法的关键字是<code>kernel_initializer</code>和<code>bias_initializer</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.add(Dense(<span class="number">64</span>, kernel_initializer=<span class="string">'random_uniform'</span>, bias_initializer=<span class="string">'zeros'</span>))</span><br></pre></td></tr></table></figure>
<p>一个初始化器可以由字符串指定(必须是下面的预定义初始化器之一)，或一个<code>callable</code>的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> initializers</span><br><span class="line">​</span><br><span class="line">model.add(Dense(<span class="number">64</span>, kernel_initializer=initializers.random_normal(stddev=<span class="number">0.01</span>)))</span><br><span class="line"><span class="comment"># also works, it will use the default parameters.</span></span><br><span class="line">model.add(Dense(<span class="number">64</span>, kernel_initializer=<span class="string">'random_normal'</span>))</span><br></pre></td></tr></table></figure>
<h3 id="Initializer"><a href="#Initializer" class="headerlink" title="Initializer"></a>Initializer</h3><p>&emsp;&emsp;<code>Initializer</code>是所有初始化方法的父类，不能直接使用，如果想要定义自己的初始化方法，请继承此类。</p>
<h3 id="预定义初始化方法"><a href="#预定义初始化方法" class="headerlink" title="预定义初始化方法"></a>预定义初始化方法</h3><h4 id="Zeros"><a href="#Zeros" class="headerlink" title="Zeros"></a>Zeros</h4><p>&emsp;&emsp;全<code>0</code>初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.Zeros()</span><br></pre></td></tr></table></figure>
<h4 id="Ones"><a href="#Ones" class="headerlink" title="Ones"></a>Ones</h4><p>&emsp;&emsp;全<code>1</code>初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.Ones()</span><br></pre></td></tr></table></figure>
<h4 id="Constant"><a href="#Constant" class="headerlink" title="Constant"></a>Constant</h4><p>&emsp;&emsp;初始化为固定值<code>value</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.Constant(value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="RandomNormal"><a href="#RandomNormal" class="headerlink" title="RandomNormal"></a>RandomNormal</h4><p>&emsp;&emsp;正态分布初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.RandomNormal(mean=<span class="number">0.0</span>, stddev=<span class="number">0.05</span>, seed=<span class="keyword">None</span>))</span><br></pre></td></tr></table></figure>
<p>参数<code>mean</code>是均值，<code>stddev</code>是标准差，<code>seed</code>是随机数种子。</p>
<h4 id="RandomUniform"><a href="#RandomUniform" class="headerlink" title="RandomUniform"></a>RandomUniform</h4><p>&emsp;&emsp;均匀分布初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.RandomUniform(minval=<span class="number">-0.05</span>, maxval=<span class="number">0.05</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>minval</code>是均匀分布下边界，<code>maxval</code>是均匀分布上边界，<code>seed</code>是随机数种子。</p>
<h4 id="TruncatedNormal"><a href="#TruncatedNormal" class="headerlink" title="TruncatedNormal"></a>TruncatedNormal</h4><p>&emsp;&emsp;截尾高斯分布初始化，该初始化方法与<code>RandomNormal</code>类似，但位于均值两个标准差以外的数据将会被丢弃并重新生成，形成截尾分布。该分布是神经网络权重和滤波器的推荐初始化方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.TruncatedNormal(mean=<span class="number">0.0</span>, stddev=<span class="number">0.05</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>mean</code>是均值，<code>stddev</code>是标准差，<code>seed</code>是随机数种子。</p>
<h4 id="VarianceScaling"><a href="#VarianceScaling" class="headerlink" title="VarianceScaling"></a>VarianceScaling</h4><p>&emsp;&emsp;该初始化方法能够自适应目标张量的<code>shape</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.VarianceScaling(scale=<span class="number">1.0</span>, mode=<span class="string">'fan_in'</span>, distribution=<span class="string">'normal'</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>scale</code>：放缩因子，正浮点数。</li>
<li><code>mode</code>：字符串，<code>fan_in</code>、<code>fan_out</code>或<code>fan_avg</code>。</li>
<li><code>distribution</code>：字符串，<code>normal</code>或<code>uniform</code>。</li>
<li><code>seed</code>：随机数种子。</li>
</ul>
<p>当<code>distribution = &quot;normal&quot;</code>时，样本从<code>0</code>均值，标准差为<code>sqrt(scale/n)</code>的截尾正态分布中产生。其中：</p>
<ul>
<li><code>mode = fan_in</code>：权重张量的输入单元数。</li>
<li><code>mode = fan_out</code>：权重张量的输出单元数。</li>
<li><code>mode = fan_avg</code>：权重张量的输入输出单元数的均值。</li>
</ul>
<p>当<code>distribution = &quot;uniform&quot;</code>时，权重从<code>[-limit, limit]</code>范围内均匀采样，其中<code>limit = limit = sqrt(3 * scale / n)</code>。</p>
<h4 id="Orthogonal"><a href="#Orthogonal" class="headerlink" title="Orthogonal"></a>Orthogonal</h4><p>&emsp;&emsp;用随机正交矩阵初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.Orthogonal(gain=<span class="number">1.0</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>gain</code>是正交矩阵的乘性系数，<code>seed</code>是随机数种子。</p>
<h4 id="Identiy"><a href="#Identiy" class="headerlink" title="Identiy"></a>Identiy</h4><p>&emsp;&emsp;使用单位矩阵初始化，仅适用于<code>2D</code>方阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.initializers.Identity(gain=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>gain</code>是单位矩阵的乘性系数。</p>
<h4 id="lecun-uniform"><a href="#lecun-uniform" class="headerlink" title="lecun_uniform"></a>lecun_uniform</h4><p>&emsp;&emsp;<code>LeCun</code>均匀分布初始化方法，参数由<code>[-limit, limit]</code>的区间中均匀采样获得，其中<code>limit = sqrt(3 / fan_in)</code>，<code>fin_in</code>是权重向量的输入单元数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lecun_uniform(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="lecun-normal"><a href="#lecun-normal" class="headerlink" title="lecun_normal"></a>lecun_normal</h4><p>&emsp;&emsp;<code>LeCun</code>正态分布初始化方法，参数由<code>0</code>均值，标准差为<code>stddev = sqrt(1 / fan_in)</code>的正态分布产生，<code>fin_in</code>是权重向量的输入单元数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lecun_normal(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="glorot-normal"><a href="#glorot-normal" class="headerlink" title="glorot_normal"></a>glorot_normal</h4><p>&emsp;&emsp;<code>Glorot</code>正态分布初始化方法，也称作<code>Xavier</code>正态分布初始化，参数由<code>0</code>均值，标准差为<code>sqrt(2 / (fan_in + fan_out))</code>的正态分布产生，其中<code>fan_in</code>和<code>fan_out</code>是权重张量的输入和输出单元数目：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">glorot_normal(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="glorot-uniform"><a href="#glorot-uniform" class="headerlink" title="glorot_uniform"></a>glorot_uniform</h4><p>&emsp;&emsp;<code>Glorot</code>均匀分布初始化方法，又称为<code>Xavier</code>均匀初始化，参数从<code>[-limit, limit]</code>的均匀分布产生，其中<code>limit = sqrt(6 / (fan_in + fan_out))</code>，<code>fan_in</code>为权值张量的输入单元数，<code>fan_out</code>是权重张量的输出单元数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">glorot_uniform(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="he-normal"><a href="#he-normal" class="headerlink" title="he_normal"></a>he_normal</h4><p>&emsp;&emsp;<code>He</code>正态分布初始化方法，参数由<code>0</code>均值，标准差为<code>sqrt(2 / fan_in)</code>的正态分布产生，其中<code>fan_in</code>是权重张量的输入单元数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">he_normal(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="he-uniform"><a href="#he-uniform" class="headerlink" title="he_uniform"></a>he_uniform</h4><p>&emsp;&emsp;<code>He</code>均匀分布初始化方法，参数由<code>[-limit, limit]</code>的区间中均匀采样获得，其中<code>limit = sqrt(6 / fan_in)</code>，<code>fin_in</code>是权重向量的输入单元数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">he_normal(seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>seed</code>是随机数种子。</p>
<h4 id="自定义初始化器"><a href="#自定义初始化器" class="headerlink" title="自定义初始化器"></a>自定义初始化器</h4><p>&emsp;&emsp;如果需要传递自定义的初始化器，则该初始化器必须是<code>callable</code>的，并且接收<code>shape</code>(将被初始化的张量<code>shape</code>)和<code>dtype</code>(数据类型)两个参数，并返回符合<code>shape</code>和<code>dtype</code>的张量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_init</span><span class="params">(shape, dtype=None)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> K.random_normal(shape, dtype=dtype)</span><br><span class="line">​</span><br><span class="line">model.add(Dense(<span class="number">64</span>, init=my_init))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/可视化CNN中间层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/可视化CNN中间层/" itemprop="url">可视化CNN中间层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T11:23:20+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;主要的实现思路如下：</p>
<p>&emsp;&emsp;1. 处理单张图片作为网络输入。<br>&emsp;&emsp;2. 根据给定的<code>layer</code>层，获取该层的输出结果<code>features</code>。<br>&emsp;&emsp;3. 考虑到<code>features</code>的形状为<code>[batch_size, filter_nums, H, W]</code>，提取其中的第一个过滤器得到的结果<code>feature</code>。<br>&emsp;&emsp;4. 以一张图片作为输入的情况下，我们得到的<code>feature</code>即为<code>[H, W]</code>大小的<code>tensor</code>。<br>&emsp;&emsp;5. 将<code>tensor</code>转为<code>numpy</code>，然后归一化到<code>[0, 1]</code>，最后乘以<code>255</code>，使得范围为<code>[0, 255]</code>。<br>&emsp;&emsp;6. 得到灰度图像并保存。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_image</span><span class="params">(cv2im, resize_im=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    function: Processes image for CNNs.</span></span><br><span class="line"><span class="string">    Args: PIL_img (PIL_img): Image to process; resize_im (bool): Resize to 224 or not.</span></span><br><span class="line"><span class="string">    returns: im_as_var (Pytorch variable): Variable that contains processed float tensor</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># mean and std list for channels (Imagenet)</span></span><br><span class="line">    mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">    std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> resize_im:  <span class="comment"># Resize image</span></span><br><span class="line">        cv2im = cv2.resize(cv2im, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">    im_as_arr = np.float32(cv2im)</span><br><span class="line">    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::<span class="number">-1</span>])</span><br><span class="line">    im_as_arr = im_as_arr.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># Convert array to D,W,H</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> channel, _ <span class="keyword">in</span> enumerate(im_as_arr):  <span class="comment"># Normalize the channels</span></span><br><span class="line">        im_as_arr[channel] /= <span class="number">255</span></span><br><span class="line">        im_as_arr[channel] -= mean[channel]</span><br><span class="line">        im_as_arr[channel] /= std[channel]</span><br><span class="line">​</span><br><span class="line">    im_as_ten = torch.from_numpy(im_as_arr).float()  <span class="comment"># Convert to float tensor</span></span><br><span class="line">    im_as_ten.unsqueeze_(<span class="number">0</span>)  <span class="comment"># Add one more channel to the beginning. Tensor shape = 1,3,224,224</span></span><br><span class="line">    im_as_var = Variable(im_as_ten, requires_grad=<span class="keyword">True</span>)  <span class="comment"># Convert to Pytorch variable</span></span><br><span class="line">    <span class="keyword">return</span> im_as_var</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureVisualization</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, img_path, selected_layer)</span>:</span></span><br><span class="line">        self.img_path = img_path</span><br><span class="line">        self.selected_layer = selected_layer</span><br><span class="line">        self.pretrained_model = models.vgg16(pretrained=<span class="keyword">True</span>).features</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_image</span><span class="params">(self)</span>:</span></span><br><span class="line">        img = cv2.imread(self.img_path)</span><br><span class="line">        img = preprocess_image(img)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_feature</span><span class="params">(self)</span>:</span></span><br><span class="line">        input = self.process_image()</span><br><span class="line">        print(<span class="string">"get_feature:"</span>, input.shape)</span><br><span class="line">        x = input</span><br><span class="line">        <span class="keyword">for</span> index, layer <span class="keyword">in</span> enumerate(self.pretrained_model):</span><br><span class="line">            x = layer(x)</span><br><span class="line">            <span class="keyword">if</span> (index == self.selected_layer):</span><br><span class="line">                <span class="keyword">return</span> x</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_single_feature</span><span class="params">(self)</span>:</span></span><br><span class="line">        features = self.get_feature()</span><br><span class="line">        print(<span class="string">"get_single_feature_1:"</span>, features.shape)</span><br><span class="line">        feature = features[:, <span class="number">0</span>, :, :]</span><br><span class="line">        print(<span class="string">"get_single_feature_2:"</span>, feature.shape)</span><br><span class="line">        feature = feature.view(feature.shape[<span class="number">1</span>], feature.shape[<span class="number">2</span>])</span><br><span class="line">        print(<span class="string">"get_single_feature_3:"</span>, feature.shape)</span><br><span class="line">        <span class="keyword">return</span> feature</span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_feature_to_img</span><span class="params">(self)</span>:</span></span><br><span class="line">        feature = self.get_single_feature()</span><br><span class="line">        feature = feature.data.numpy()</span><br><span class="line">        feature = <span class="number">1.0</span> / (<span class="number">1</span> + np.exp(<span class="number">-1</span> * feature))  <span class="comment"># use sigmod to [0, 1]</span></span><br><span class="line">        feature = np.round(feature * <span class="number">255</span>)  <span class="comment"># to [0, 255]</span></span><br><span class="line">        cv2.imwrite(<span class="string">'./img.jpg'</span>, feature)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    myClass = FeatureVisualization(<span class="string">'./tu.jpg'</span>, <span class="number">5</span>)</span><br><span class="line">    print(myClass.pretrained_model)</span><br><span class="line">    myClass.save_feature_to_img()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/Keras之优化器/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/Keras之优化器/" itemprop="url">Keras之优化器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T10:04:12+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;优化器(<code>optimizer</code>)是编译<code>Keras</code>模型的所需的两个参数之一：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line">​</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">64</span>, kernel_initializer=<span class="string">'uniform'</span>, input_shape=(<span class="number">10</span>,)))</span><br><span class="line">model.add(Activation(<span class="string">'tanh'</span>))</span><br><span class="line">model.add(Activation(<span class="string">'softmax'</span>))</span><br><span class="line">​</span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="keyword">True</span>)</span><br><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=sgd)</span><br></pre></td></tr></table></figure>
<p>你可以先实例化一个优化器对象，然后将它传入<code>model.compile</code>，像上述示例中一样；或者你可以通过名称来调用优化器。在后一种情况下，将使用优化器的默认参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'sgd'</span>)  <span class="comment"># 传入优化器名称，默认参数将被采用</span></span><br></pre></td></tr></table></figure>
<h3 id="Keras优化器的公共参数"><a href="#Keras优化器的公共参数" class="headerlink" title="Keras优化器的公共参数"></a>Keras优化器的公共参数</h3><p>&emsp;&emsp;参数<code>clipnorm</code>和<code>clipvalue</code>能在所有的优化器中使用，用于控制梯度裁剪(<code>Gradient Clipping</code>)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="comment"># 所有参数梯度将被裁剪，让其l2范数最大为1：“g * 1 / max(1, l2_norm)”</span></span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, clipnorm=<span class="number">1.</span>)</span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="comment"># 所有参数d梯度将被裁剪到数值范围内：最大值0.5，最小值“-0.5”</span></span><br><span class="line">sgd = optimizers.SGD(lr=<span class="number">0.01</span>, clipvalue=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>&emsp;&emsp;该函数是随机梯度下降优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.SGD(lr=<span class="number">0.01</span>, momentum=<span class="number">0.0</span>, decay=<span class="number">0.0</span>, nesterov=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>包含扩展功能的支持：动量(<code>momentum</code>)优化、学习率衰减(每次参数更新后)和<code>Nestrov</code>动量(<code>NAG</code>)优化。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>momentum</code>：<code>float &gt;= 0</code>，用于加速<code>SGD</code>在相关方向上前进，并抑制震荡。</li>
<li><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</li>
<li><code>nesterov</code>：<code>boolean</code>型，是否使用<code>Nesterov</code>动量。</li>
</ul>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>&emsp;&emsp;该函数是<code>RMSProp</code>优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.RMSprop(lr=<span class="number">0.001</span>, rho=<span class="number">0.9</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>建议使用优化器的默认参数(除了学习率<code>lr</code>，它可以被自由调节)，这个优化器通常是训练循环神经网络<code>RNN</code>的不错选择。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>rho</code>：<code>float &gt;= 0</code>，<code>RMSProp</code>梯度平方的移动均值的衰减率。</li>
<li><code>epsilon</code>：<code>float &gt;= 0</code>，模糊因子。若为<code>None</code>，默认为<code>K.epsilon</code>。</li>
<li><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</li>
</ul>
<h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>&emsp;&emsp;该函数是<code>Adagrad</code>优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adagrad(lr=<span class="number">0.01</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>建议使用优化器的默认参数。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>epsilon</code>：<code>float &gt;= 0</code>，若为<code>None</code>，默认为<code>K.epsilon</code>。</li>
<li><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</li>
</ul>
<h3 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h3><p>&emsp;&emsp;该函数是<code>Adagrad</code>优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adadelta(lr=<span class="number">1.0</span>, rho=<span class="number">0.95</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>建议使用优化器的默认参数。</p>
<p><code>lr</code>：<code>float &gt;= 0</code>，学习率，建议保留默认值。<br><code>rho</code>：<code>float &gt;= 0</code>，<code>Adadelta</code>梯度平方移动均值的衰减率。<br><code>epsilon</code>：<code>float &gt;= 0</code>，模糊因子。若为<code>None</code>，默认为<code>K.epsilon</code>。<br><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>&emsp;&emsp;该函数是<code>Adam</code>优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adam(lr=<span class="number">0.001</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>, amsgrad=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>建议使用优化器的默认参数。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>beta_1</code>：<code>float</code>型，<code>0 &lt; beta &lt; 1</code>，通常接近于<code>1</code>。</li>
<li><code>beta_2</code>：<code>float</code>型，<code>0 &lt; beta &lt; 1</code>，通常接近于<code>1</code>。</li>
<li><code>epsilon</code>：<code>float &gt;= 0</code>，模糊因子。若为<code>None</code>，默认为<code>K.epsilon</code>。</li>
<li><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</li>
<li><code>amsgrad</code>：<code>boolean</code>型，是否应用此算法的<code>AMSGrad</code>变种，来自论文<code>On the Convergence of Adam and Beyond</code>。</li>
</ul>
<h3 id="Adamax"><a href="#Adamax" class="headerlink" title="Adamax"></a>Adamax</h3><p>&emsp;&emsp;该函数是<code>Adamax</code>优化器，来自<code>Adam</code>论文(<code>Adam - A Method for Stochastic Optimization</code>)的第七小节：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adamax(lr=<span class="number">0.002</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="keyword">None</span>, decay=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>它是<code>Adam</code>算法基于无穷范数(<code>infinity norm</code>)的变种。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>beta_1/beta_2</code>：<code>float</code>型，<code>0 &lt; beta &lt; 1</code>，通常接近于1。</li>
<li><code>epsilon</code>：<code>float &gt;= 0</code>，模糊因子。若为<code>None</code>，默认为<code>K.epsilon</code>。</li>
<li><code>decay</code>：<code>float &gt;= 0</code>，每次参数更新后学习率衰减值。</li>
</ul>
<h3 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h3><p>&emsp;&emsp;该函数是<code>Nesterov</code>版本<code>Adam</code>优化器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Nadam(lr=<span class="number">0.002</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="keyword">None</span>, schedule_decay=<span class="number">0.004</span>)</span><br></pre></td></tr></table></figure>
<p>正像<code>Adam</code>本质上是<code>RMSProp</code>与动量<code>momentum</code>的结合，<code>Nadam</code>是采用<code>Nesterov momentum</code>版本的<code>Adam</code>优化器。建议使用优化器的默认参数。</p>
<ul>
<li><code>lr</code>：<code>float &gt;= 0</code>，学习率。</li>
<li><code>beta_1/beta_2</code>：<code>float</code>型，<code>0 &lt; beta &lt; 1</code>，通常接近于<code>1</code>。</li>
<li><code>epsilon</code>：<code>float &gt;= 0</code>，模糊因子。若为<code>None</code>，默认为<code>K.epsilon</code>。</li>
</ul>
<h3 id="TFOptimizer"><a href="#TFOptimizer" class="headerlink" title="TFOptimizer"></a>TFOptimizer</h3><p>&emsp;&emsp;该函数是原生<code>TensorFlow</code>优化器的包装类(<code>wrapper class</code>)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.TFOptimizer(optimizer)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/01/01/深度学习/Keras之高级激活层和Keras层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/01/深度学习/Keras之高级激活层和Keras层/" itemprop="url">Keras之高级激活层和Keras层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-01T09:28:54+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="高级激活层"><a href="#高级激活层" class="headerlink" title="高级激活层"></a>高级激活层</h3><h4 id="LeakyReLU"><a href="#LeakyReLU" class="headerlink" title="LeakyReLU"></a>LeakyReLU</h4><p>&emsp;&emsp;<code>LeakyRelU</code>是修正线性单元(<code>Rectified Linear Unit</code>，<code>ReLU</code>)的特殊版本，当不激活时，<code>LeakyReLU</code>仍然会有非零输出值，从而获得一个小梯度，避免<code>ReLU</code>可能出现的<code>神经元死亡</code>现象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.LeakyReLU(alpha=<span class="number">0.3</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>alpha</code>(<code>float</code>型，并且<code>≥ 0</code>)是负斜率系数。当神经元未激活时，它仍可以赋予其一个很小的梯度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f(x) = alpha * x <span class="keyword">for</span> x &lt; <span class="number">0</span></span><br><span class="line">f(x) = x <span class="keyword">for</span> x &gt;= <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：可以是任意的。如果将该层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h4 id="PReLU"><a href="#PReLU" class="headerlink" title="PReLU"></a>PReLU</h4><p>&emsp;&emsp;该函数是参数化的修正线性单元：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.PReLU(alpha_initializer=<span class="string">'zeros'</span>, alpha_regularizer=<span class="keyword">None</span>, alpha_constraint=<span class="keyword">None</span>, shared_axes=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>alpha_initializer</code>：权重的初始化函数。</li>
<li><code>alpha_regularizer</code>：权重的正则化方法。</li>
<li><code>alpha_constraint</code>：权重的约束。</li>
<li><code>shared_axes</code>：激活函数共享可学习参数的轴。例如假如输入特征图是从<code>2D</code>卷积过来的，具有形如<code>(batch, height, width, channels)</code>这样的<code>shape</code>；或许你会希望在空域共享参数，这样每个<code>filter</code>就只有一组参数，设定<code>shared_axes = [1, 2]</code>可完成该目标。</li>
</ul>
<p>&emsp;&emsp;形式如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f(x) = alpha * x <span class="keyword">for</span> x &lt; <span class="number">0</span></span><br><span class="line">f(x) = x <span class="keyword">for</span> x &gt;= <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>其中<code>alpha</code>是一个可学习的数组，尺寸与<code>x</code>相同。<br>&emsp;&emsp;输入尺寸：可以是任意的。如果将这一层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h4 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h4><p>&emsp;&emsp;该函数是指数线性单元：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ELU(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>alpha</code>是负因子的尺度。形式如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f(x) = alpha * (exp(x) - <span class="number">1</span>) <span class="keyword">for</span> x &lt; <span class="number">0</span></span><br><span class="line">f(x) = x <span class="keyword">for</span> x &gt;= <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：可以是任意的。如果将这一层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h4 id="ThresholdedReLU"><a href="#ThresholdedReLU" class="headerlink" title="ThresholdedReLU"></a>ThresholdedReLU</h4><p>&emsp;&emsp;该函数是带阈值的修正线性单元：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ThresholdedReLU(theta=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p>该函数<code>theta</code>(float型，并且<code>≥ 0</code>)是激活的阈值位。形式如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(x) = x <span class="keyword">for</span> x &gt; theta, f(x) = <span class="number">0</span> otherwise.</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：可以是任意的。如果将这一层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h4 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h4><p>&emsp;&emsp;该函数是<code>Softmax</code>激活函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Softmax(axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>axis</code>是整数，即应用<code>softmax</code>标准化的轴。<br>&emsp;&emsp;输入尺寸：可以是任意的。如果将这一层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="Keras层"><a href="#Keras层" class="headerlink" title="Keras层"></a>Keras层</h3><p>&emsp;&emsp;所有<code>Keras</code>层都有很多共同的函数：</p>
<ul>
<li><code>layer.get_weights()</code>：以<code>Numpy</code>矩阵的形式返回层的权重。</li>
<li><code>layer.set_weights(weights)</code>：从<code>Numpy</code>矩阵中设置层的权重(与<code>get_weights</code>的输出形状相同)。</li>
<li><code>layer.get_config()</code>：返回包含层配置的字典。此图层可以通过以下方式重置：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">layer = Dense(<span class="number">32</span>)</span><br><span class="line">config = layer.get_config()</span><br><span class="line">reconstructed_layer = Dense.from_config(config)</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">config = layer.get_config()</span><br><span class="line">layer = layers.deserialize(&#123;<span class="string">'class_name'</span>: layer.__class__.__name__, <span class="string">'config'</span>: config&#125;)</span><br></pre></td></tr></table></figure>
<p>如果一个层具有单个节点(例如如果它不是共享层)，你可以得到它的输入张量、输出张量、输入尺寸和输出尺寸：</p>
<ul>
<li><code>layer.input</code></li>
<li><code>layer.output</code></li>
<li><code>layer.input_shape</code></li>
<li><code>layer.output_shape</code></li>
</ul>
<p>如果层有多个节点，您可以使用以下函数：</p>
<ul>
<li><code>layer.get_input_at(node_index)</code></li>
<li><code>layer.get_output_at(node_index)</code></li>
<li><code>layer.get_input_shape_at(node_index)</code></li>
<li><code>layer.get_output_shape_at(node_index)</code></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2018/12/31/深度学习/TensorFlow张量/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/31/深度学习/TensorFlow张量/" itemprop="url">TensorFlow张量(需要修改)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-31T09:48:10+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>TensorFlow</code>用张量这种数据结构来表示所有的数据，你可以把一个张量想象成一个<code>n</code>维的数组或列表。一个张量有一个静态类型和动态类型的维数。张量可以在图中的节点之间流通。</p>
<h3 id="阶"><a href="#阶" class="headerlink" title="阶"></a>阶</h3><p>&emsp;&emsp;在<code>TensorFlow</code>系统中，张量的维数来被描述为<code>阶</code>，但是张量的阶和矩阵的阶并不是同一个概念。张量的阶是张量维数的一个数量描述，例如下面的张量(使用<code>Python</code>中<code>list</code>定义的)就是<code>2</code>阶：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">     [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br></pre></td></tr></table></figure>
<p>你可以认为一个二阶张量就是我们平常所说的矩阵，一阶张量可以认为是一个向量。对于一个二阶张量，你可以用语句<code>t[i, j]</code>来访问其中的任何元素，而对于三阶张量你可以用<code>t[i, j, k]</code>来访问其中的任何元素：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>数学实例</th>
<th>Python例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td>纯量(只有大小)</td>
<td><code>s = 483</code></td>
</tr>
<tr>
<td><code>1</code></td>
<td>向量(大小和方向)</td>
<td><code>v = [1.1, 2.2, 3.3]</code></td>
</tr>
<tr>
<td><code>2</code></td>
<td>矩阵(数据表)</td>
<td><code>m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]</code></td>
</tr>
<tr>
<td><code>3</code></td>
<td><code>3</code>阶张量(数据立体)</td>
<td><code>t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]</code></td>
</tr>
<tr>
<td><code>n</code></td>
<td><code>n</code>阶(自己想象)</td>
<td><code>...</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="形状"><a href="#形状" class="headerlink" title="形状"></a>形状</h3><p>&emsp;&emsp;<code>TensorFlow</code>文档中使用了三种记号来方便地描述张量的维度：阶、形状以及维数。下表展示了它们之间的关系：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>阶</th>
<th>形状</th>
<th>维数</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td><code>[ ]</code></td>
<td><code>0-D</code></td>
<td>一个<code>0</code>维张量，即一个纯量</td>
</tr>
<tr>
<td><code>1</code></td>
<td><code>[D0]</code></td>
<td><code>1-D</code></td>
<td>一个<code>1</code>维张量的形式<code>[5]</code></td>
</tr>
<tr>
<td><code>2</code></td>
<td><code>[D0, D1]</code></td>
<td><code>2-D</code></td>
<td>一个<code>2</code>维张量的形式<code>[3, 4]</code></td>
</tr>
<tr>
<td><code>3</code></td>
<td><code>[D0, D1, D2]</code></td>
<td><code>3-D</code></td>
<td>一个<code>3</code>维张量的形式<code>[1, 4, 3]</code></td>
</tr>
<tr>
<td><code>n</code></td>
<td><code>[D0, D1, ... Dn]</code></td>
<td><code>n-D</code></td>
<td>一个<code>n</code>维张量的形式<code>[D0, D1, ... Dn]</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>&emsp;&emsp;除了维度，<code>Tensors</code>还有一个数据类型属性。你可以为一个张量指定下列数据类型中的任意一个类型：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据类型</th>
<th>Python类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DT_FLOAT</code></td>
<td><code>tf.float32</code></td>
<td><code>32</code>位浮点数</td>
</tr>
<tr>
<td><code>DT_DOUBLE</code></td>
<td><code>tf.float64</code></td>
<td><code>64</code>位浮点数</td>
</tr>
<tr>
<td><code>DT_INT64</code></td>
<td><code>tf.int64</code></td>
<td><code>64</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_INT32</code></td>
<td><code>tf.int32</code></td>
<td><code>32</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_INT16</code></td>
<td><code>tf.int16</code></td>
<td><code>16</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_INT8</code></td>
<td><code>tf.int8</code></td>
<td><code>8</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_UINT8</code></td>
<td><code>tf.uint8</code></td>
<td><code>8</code>位无符号整型</td>
</tr>
<tr>
<td><code>DT_STRING</code></td>
<td><code>tf.string</code></td>
<td>可变长度的字节数组，每一个张量元素都是一个字节数组</td>
</tr>
<tr>
<td><code>DT_BOOL</code></td>
<td><code>tf.bool</code></td>
<td>布尔型</td>
</tr>
<tr>
<td><code>DT_COMPLEX64</code></td>
<td><code>tf.complex64</code></td>
<td>由两个<code>32</code>位浮点数组成的复数：实数和虚数</td>
</tr>
<tr>
<td><code>DT_QINT32</code></td>
<td><code>tf.qint32</code></td>
<td>用于量化<code>Ops</code>的<code>32</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_QINT8</code></td>
<td><code>tf.qint8</code></td>
<td>用于量化<code>Ops</code>的<code>8</code>位有符号整型</td>
</tr>
<tr>
<td><code>DT_QUINT8</code></td>
<td><code>tf.quint8</code></td>
<td>用于量化<code>Ops</code>的<code>8</code>位无符号整型</td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2018/12/31/深度学习/Keras之噪声层和标准化层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/31/深度学习/Keras之噪声层和标准化层/" itemprop="url">Keras之噪声层和标准化层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-31T09:30:48+08:00">
                2018-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="GaussianNoise"><a href="#GaussianNoise" class="headerlink" title="GaussianNoise"></a>GaussianNoise</h3><p>&emsp;&emsp;为数据施加<code>0</code>均值，标准差为<code>stddev</code>的加性高斯噪声。该层在克服过拟合时比较有用，你可以将它看作是随机的数据提升。高斯噪声是需要对输入数据进行破坏时的自然选择：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GaussianNoise(stddev)</span><br></pre></td></tr></table></figure>
<p>参数<code>stddev</code>是<code>float</code>型，即噪声分布的标准差。由于它是一个正则化层，因此它只在训练时才被激活。<br>&emsp;&emsp;输入尺寸：可以是任意的。如果将该层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="GaussianDropout"><a href="#GaussianDropout" class="headerlink" title="GaussianDropout"></a>GaussianDropout</h3><p>&emsp;&emsp;为层的输入施加以<code>1</code>为均值，标准差为<code>sqrt(rate / (1 - rate)</code>的乘性高斯噪声：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GaussianDropout(rate)</span><br></pre></td></tr></table></figure>
<p>参数<code>rate</code>是<code>float</code>型，丢弃概率(与<code>Dropout</code>相同)。由于它是一个正则化层，因此它只在训练时才被激活。<br>&emsp;&emsp;输入尺寸：可以是任意的。如果将该层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="AlphaDropout"><a href="#AlphaDropout" class="headerlink" title="AlphaDropout"></a>AlphaDropout</h3><p>&emsp;&emsp;该函数将<code>Alpha Dropout</code>应用到输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.AlphaDropout(rate, noise_shape=<span class="keyword">None</span>, seed=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>rate</code>：<code>float</code>型，丢弃概率(与<code>Dropout</code>相同)。这个乘性噪声的标准差为<code>sqrt(rate / (1 - rate))</code>。</li>
<li><code>seed</code>：用作随机种子的整数。</li>
</ul>
<p><code>Alpha Dropout</code>是一种<code>Dropout</code>，它保持输入的平均值和方差与原来的值不变，作用是在<code>dropout</code>之后仍然保证数据的自规范性。通过随机将激活设置为负饱和值，<code>Alpha Dropout</code>非常适合按比例缩放的指数线性单元(<code>SELU</code>)。<br>&emsp;&emsp;输入尺寸：可以是任意的。如果将该层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>
<h3 id="BatchNormalization"><a href="#BatchNormalization" class="headerlink" title="BatchNormalization"></a>BatchNormalization</h3><p>&emsp;&emsp;该函数是批量标准化层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.BatchNormalization(</span><br><span class="line">    axis=<span class="number">-1</span>, momentum=<span class="number">0.99</span>, epsilon=<span class="number">0.001</span>, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>, beta_initializer=<span class="string">'zeros'</span>,</span><br><span class="line">    gamma_initializer=<span class="string">'ones'</span>, moving_mean_initializer=<span class="string">'zeros'</span>, moving_variance_initializer=<span class="string">'ones'</span>,</span><br><span class="line">    beta_regularizer=<span class="keyword">None</span>, gamma_regularizer=<span class="keyword">None</span>, beta_constraint=<span class="keyword">None</span>, gamma_constraint=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>该层在每个<code>batch</code>上将前一层的激活值重新规范化，即使得其输出数据的均值接近<code>0</code>，其标准差接近<code>1</code>。</p>
<ul>
<li><code>axis</code>：整数，需要标准化的轴(通常是特征轴)。例如在进行<code>data_format = &#39;channels_first&#39;</code>的<code>2D</code>卷积后，一般会设<code>axis</code>为<code>1</code>。</li>
<li><code>momentum</code>：动态均值的动量。</li>
<li><code>epsilon</code>：大于<code>0</code>的小浮点数，用于防止除<code>0</code>错误。</li>
<li><code>center</code>：如果为<code>True</code>，把<code>beta</code>的偏移量加到标准化的张量上；如果为<code>False</code>，<code>beta</code>被忽略。</li>
<li><code>scale</code>：如果为<code>True</code>，乘以<code>gamma</code>；如果为<code>False</code>，<code>gamma</code>不使用。当下一层为线性层(或者<code>nn.relu</code>)，这可以被禁用，因为缩放将由下一层完成。</li>
<li><code>beta_initializer</code>：<code>beta</code>权重的初始化方法。</li>
<li><code>gamma_initializer</code>：<code>gamma</code>权重的初始化方法。</li>
<li><code>moving_mean_initializer</code>：动态均值的初始化方法。</li>
<li><code>moving_variance_initializer</code>：动态方差的初始化方法。</li>
<li><code>beta_regularizer</code>：可选的<code>beta</code>权重的正则化方法。</li>
<li><code>gamma_regularizer</code>：可选的<code>gamma</code>权重的正则化方法。</li>
<li><code>beta_constraint</code>：可选的<code>beta</code>权重的约束方法。</li>
<li><code>gamma_constraint</code>：可选的<code>gamma</code>权重的约束方法。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：可以是任意的。如果将这一层作为模型的第一层，则需要指定<code>input_shape</code>参数(整数元组，不包含样本数量的维度)。<br>&emsp;&emsp;输出尺寸：与输入相同。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2018/12/30/深度学习/OpenPose的使用/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/30/深度学习/OpenPose的使用/" itemprop="url">OpenPose的使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-30T22:15:58+08:00">
                2018-12-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Windows版本"><a href="#Windows版本" class="headerlink" title="Windows版本"></a>Windows版本</h3><p>&emsp;&emsp;首先确保计算机中有显卡，并安装好<code>CUDA</code>模块。然后下载<code>OpenPose</code>的<code>Windows</code>版本，并进行解压操作。<br>&emsp;&emsp;查看<code>OpenPose</code>的参数可以使用如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用OpenPose分析视频文件如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --video .\examples\media\video.avi</span><br></pre></td></tr></table></figure>
<p>如果只需要显示一个人的姿态，可以使用参数<code>number_people_max</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --video .\examples\media\video.avi --number_people_max 1</span><br></pre></td></tr></table></figure>
<p>保存视频可以使用参数<code>write_video</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --video .\examples\media\video.avi --write_video .\examples\video.avi</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;保存人体姿态的图像使用参数<code>write_images</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --image_dir .\examples\media\ --write_images .\examples\media\images\</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;将人体关键点保存为<code>json</code>文件可以使用参数<code>write_keypoint_json</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin\OpenPoseDemo.exe --image_dir .\examples\media\ --write_keypoint_json .\examples\media\json\</span><br></pre></td></tr></table></figure>
<p>保存的<code>json</code>文件如下所示：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>: <span class="number">1.2</span>,</span><br><span class="line">    <span class="attr">"people"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"pose_keypoints_2d"</span>: [</span><br><span class="line">                <span class="number">385.895</span>, <span class="number">130.626</span>, <span class="number">0.784749</span>,</span><br><span class="line">                <span class="number">429.924</span>, <span class="number">246.015</span>, <span class="number">0.480111</span>,</span><br><span class="line">                <span class="number">334.069</span>, <span class="number">253.87</span>, <span class="number">0.492662</span>,</span><br><span class="line">                <span class="number">303.744</span>, <span class="number">357.555</span>, <span class="number">0.417447</span>,</span><br><span class="line">                <span class="number">268.541</span>, <span class="number">309.6</span>, <span class="number">0.721677</span>,</span><br><span class="line">                <span class="number">510.142</span>, <span class="number">239.183</span>, <span class="number">0.364753</span>,</span><br><span class="line">                <span class="number">564.929</span>, <span class="number">294.949</span>, <span class="number">0.189901</span>,</span><br><span class="line">                <span class="number">528.75</span>, <span class="number">197.12</span>, <span class="number">0.278824</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">369.297</span>, <span class="number">113.999</span>, <span class="number">0.89678</span>,</span><br><span class="line">                <span class="number">418.163</span>, <span class="number">115.94</span>, <span class="number">0.88171</span>,</span><br><span class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                <span class="number">473.962</span>, <span class="number">159.959</span>, <span class="number">0.743814</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"face_keypoints_2d"</span>: [ ],</span><br><span class="line">            <span class="attr">"hand_left_keypoints_2d"</span>: [ ],</span><br><span class="line">            <span class="attr">"hand_right_keypoints_2d"</span>: [ ],</span><br><span class="line">            <span class="attr">"pose_keypoints_3d"</span>: [ ],</span><br><span class="line">            <span class="attr">"face_keypoints_3d"</span>: [ ],</span><br><span class="line">            <span class="attr">"hand_left_keypoints_3d"</span>: [ ],</span><br><span class="line">            <span class="attr">"hand_right_keypoints_3d"</span>: [ ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>pose_keypoints</code>即为当前图像中人体<code>18</code>个关节点的数据信息，一个关节点信息包括<code>(x, y, score)</code>三个信息，<code>x</code>和<code>y</code>即为图像中的坐标信息，取值范围为<code>(0, image.size)</code>；而<code>score</code>则表示预测评分，取值范围为<code>(0, 1)</code>，越接近<code>1</code>值表示预测得越准确，其关节点的还原度就越高，同时姿态的还原度也就越高。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2018/12/30/深度学习/Keras之池化层/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴徒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/30/深度学习/Keras之池化层/" itemprop="url">Keras之池化层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-30T21:31:39+08:00">
                2018-12-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="MaxPooling1D"><a href="#MaxPooling1D" class="headerlink" title="MaxPooling1D"></a>MaxPooling1D</h3><p>&emsp;&emsp;该函数用于时序数据的最大池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.MaxPooling1D(pool_size=<span class="number">2</span>, strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：整数，最大池化的窗口大小。</li>
<li><code>strides</code>：整数或者是<code>None</code>，作为缩小比例的因数，例如<code>2</code>会使得输入张量缩小一半。如果是<code>None</code>，那么默认值是<code>pool_size</code>。</li>
<li><code>padding</code>：<code>valid</code>或者<code>same</code>。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：尺寸是<code>(batch_size, steps, features)</code>的<code>3D</code>张量。<br>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, downsampled_steps, features)</code>的<code>3D</code>张量。</p>
<h3 id="MaxPooling2D"><a href="#MaxPooling2D" class="headerlink" title="MaxPooling2D"></a>MaxPooling2D</h3><p>&emsp;&emsp;该函数用于空域数据的最大池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：整数或者<code>2</code>个整数元组，代表在两个方向<code>(垂直方向, 水平方向)</code>缩小比例的因数。<code>(2, 2)</code>会把输入张量的两个维度都缩小一半。如果只使用一个整数，那么两个维度都会使用同样的窗口长度。</li>
<li><code>strides</code>：整数、整数元组或者是<code>None</code>，步长值。如果是<code>None</code>，那么默认值是<code>pool_size</code>。</li>
<li><code>data_format</code>：一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，代表图像的通道维的位置。<code>channels_last</code>代表尺寸是<code>(batch, height, width, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, height, width)</code>的输入张量。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, rows, cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, rows, cols)</code>的<code>4D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, pooled_rows, pooled_cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, pooled_rows, pooled_cols)</code>的<code>4D</code>张量。</li>
</ul>
<h3 id="MaxPooling3D"><a href="#MaxPooling3D" class="headerlink" title="MaxPooling3D"></a>MaxPooling3D</h3><p>&emsp;&emsp;该函数用于3D(空域或时空域)数据的最大池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.MaxPooling3D(pool_size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：<code>3</code>个整数的元组，代表缩小<code>(维度1, 维度2, 维度3)</code>比例的因数。<code>(2, 2, 2)</code>会把<code>3D</code>输入张量的每个维度缩小一半。</li>
<li><code>strides</code>：<code>3</code>个整数的元组或者是<code>None</code>，步长值。</li>
<li><code>data_format</code>：一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，代表数据的通道维的位置。<code>channels_last</code>代表尺寸是<code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>的输入张量。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>的<code>5D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>的<code>5D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)</code>的<code>5D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)</code>的<code>5D</code>张量。</li>
</ul>
<h3 id="AveragePooling1D"><a href="#AveragePooling1D" class="headerlink" title="AveragePooling1D"></a>AveragePooling1D</h3><p>&emsp;&emsp;该函数用于时序数据的平均池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.AveragePooling1D(pool_size=<span class="number">2</span>, strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：整数，平均池化的窗口大小。</li>
<li><code>strides</code>：整数或者是<code>None</code>，作为缩小比例的因数，例如<code>2</code>会使得输入张量缩小一半。如果是<code>None</code>，那么默认值是<code>pool_size</code>。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：尺寸是<code>(batch_size, steps, features)</code>的<code>3D</code>张量。<br>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, downsampled_steps, features)</code>的<code>3D</code>张量。</p>
<h3 id="AveragePooling2D"><a href="#AveragePooling2D" class="headerlink" title="AveragePooling2D"></a>AveragePooling2D</h3><p>&emsp;&emsp;该函数用于空域数据的平均池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：整数或者<code>2</code>个整数元组，代表在两个方向<code>(垂直方向, 水平方向)</code>缩小比例的因数。<code>(2, 2)</code>会把输入张量的两个维度都缩小一半。如果只使用一个整数，那么两个维度都会使用同样的窗口长度。</li>
<li><code>strides</code>：整数、整数元组或者是<code>None</code>，步长值。如果是<code>None</code>，那么默认值是<code>pool_size</code>。</li>
<li><code>data_format</code>：一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，输入张量中的维度顺序。<code>channels_last</code>代表尺寸是<code>(batch, height, width, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, height, width)</code>的输入张量。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, rows, cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, rows, cols)</code>的<code>4D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, pooled_rows, pooled_cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, pooled_rows, pooled_cols)</code>的<code>4D</code>张量。</li>
</ul>
<h3 id="AveragePooling3D"><a href="#AveragePooling3D" class="headerlink" title="AveragePooling3D"></a>AveragePooling3D</h3><p>&emsp;&emsp;该函数用于<code>3D</code>(空域或者时空域)数据的平均池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.AveragePooling3D(pool_size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>), strides=<span class="keyword">None</span>, padding=<span class="string">'valid'</span>, data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>pool_size</code>：<code>3</code>个整数的元组，代表缩小<code>(维度1, 维度2, 维度3)</code>比例的因数。<code>(2, 2, 2)</code>会把<code>3D</code>输入张量的每个维度缩小一半。</li>
<li><code>strides</code>：<code>3</code>个整数的元组或者是<code>None</code>，步长值。</li>
<li><code>data_format</code>：一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，代表数据的通道维的位置。<code>channels_last</code>代表尺寸是<code>(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>的输入张量。</li>
</ul>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)</code>的<code>5D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)</code>的<code>5D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)</code>的<code>5D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)</code>的<code>5D</code>张量。</li>
</ul>
<h3 id="GlobalMaxPooling1D"><a href="#GlobalMaxPooling1D" class="headerlink" title="GlobalMaxPooling1D"></a>GlobalMaxPooling1D</h3><p>&emsp;&emsp;该函数用于时序数据的全局最大池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GlobalMaxPooling1D()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：尺寸是<code>(batch_size, steps, features)</code>的<code>3D</code>张量。<br>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, features)</code>的<code>2D</code>张量。</p>
<h3 id="GlobalAveragePooling1D"><a href="#GlobalAveragePooling1D" class="headerlink" title="GlobalAveragePooling1D"></a>GlobalAveragePooling1D</h3><p>&emsp;&emsp;该函数用于时序数据的全局平均池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GlobalAveragePooling1D()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;输入尺寸：尺寸是<code>(batch_size, steps, features)</code>的<code>3D</code>张量。<br>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, features)</code>的<code>2D</code>张量。</p>
<h3 id="GlobalMaxPooling2D"><a href="#GlobalMaxPooling2D" class="headerlink" title="GlobalMaxPooling2D"></a>GlobalMaxPooling2D</h3><p>&emsp;&emsp;该函数用于空域数据的全局最大池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GlobalMaxPooling2D(data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>data_format</code>是一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，代表图像的通道维的位置。<code>channels_last</code>代表尺寸是<code>(batch, height, width, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, height, width)</code>的输入张量。<br>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, rows, cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, rows, cols)</code>的<code>4D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, channels)</code>的<code>2D</code>张量。</p>
<h3 id="GlobalAveragePooling2D"><a href="#GlobalAveragePooling2D" class="headerlink" title="GlobalAveragePooling2D"></a>GlobalAveragePooling2D</h3><p>&emsp;&emsp;该函数用于空域数据的全局平均池化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.GlobalAveragePooling2D(data_format=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数<code>data_format</code>是一个字符串，<code>channels_last</code>(默认值)或者<code>channels_first</code>，代表图像的通道维的位置。<code>channels_last</code>代表尺寸是<code>(batch, height, width, channels)</code>的输入张量，而<code>channels_first</code>代表尺寸是<code>(batch, channels, height, width)</code>的输入张量。</p>
<p>&emsp;&emsp;输入尺寸：</p>
<ul>
<li>如果<code>data_format = &#39;channels_last&#39;</code>，尺寸是<code>(batch_size, rows, cols, channels)</code>的<code>4D</code>张量。</li>
<li>如果<code>data_format = &#39;channels_first&#39;</code>，尺寸是<code>(batch_size, channels, rows, cols)</code>的<code>4D</code>张量。</li>
</ul>
<p>&emsp;&emsp;输出尺寸：尺寸是<code>(batch_size, channels)</code>的<code>2D</code>张量。</p>
<p>&emsp;&emsp;<strong>补充说明</strong>：<code>pooling</code>和<code>unpooling</code>对应到神经网络的技术上就是<code>downsampling</code>和<code>unsampling</code>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/62/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/62/">62</a><span class="page-number current">63</span><a class="page-number" href="/page/64/">64</a><span class="space">&hellip;</span><a class="page-number" href="/page/94/">94</a><a class="extend next" rel="next" href="/page/64/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">934</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
