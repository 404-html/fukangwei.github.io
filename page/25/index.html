<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="泥腿子出身">
<meta property="og:url" content="http://fukangwei.gitee.io/page/25/index.html">
<meta property="og:site_name" content="泥腿子出身">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="泥腿子出身">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/page/25/">





  <title>泥腿子出身</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泥腿子出身</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/13/深度学习/Keras之Regressor回归/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/13/深度学习/Keras之Regressor回归/" itemprop="url">Keras之Regressor回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T11:00:46+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;神经网络可以用来模拟回归问题(<code>regression</code>)，例如给一组数据，用一条线来对数据进行拟合，并可以预测新输入x的输出值。</p>
<h3 id="导入模块并创建数据"><a href="#导入模块并创建数据" class="headerlink" title="导入模块并创建数据"></a>导入模块并创建数据</h3><p>&emsp;&emsp;<code>models.Sequential</code>用来一层一层地去建立神经层，<code>layers.Dense</code>意思是这个神经层是全连接层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 可视化模块</span></span><br><span class="line">​</span><br><span class="line">np.random.seed(<span class="number">1337</span>)  <span class="comment"># for reproducibility</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># create some data</span></span><br><span class="line">X = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">200</span>)</span><br><span class="line">np.random.shuffle(X)  <span class="comment"># randomize the data</span></span><br><span class="line">Y = <span class="number">0.5</span> * X + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, (<span class="number">200</span>,))</span><br><span class="line"><span class="comment"># plot data</span></span><br><span class="line">plt.scatter(X, Y)</span><br><span class="line">plt.show()</span><br><span class="line">​</span><br><span class="line">X_train, Y_train = X[:<span class="number">160</span>], Y[:<span class="number">160</span>]  <span class="comment"># train前160个“data points”</span></span><br><span class="line">X_test, Y_test = X[<span class="number">160</span>:], Y[<span class="number">160</span>:]  <span class="comment"># test后40个“data points”</span></span><br></pre></td></tr></table></figure>
<h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><p>&emsp;&emsp;使用<code>Sequential</code>建立<code>model</code>，再用<code>model.add</code>添加神经层，第二行添加的是<code>Dense</code>全连接神经层。<code>Dense</code>的参数有两个，分别是输入数据和输出数据的维度，本例中的<code>x</code>和<code>y</code>是一维的。<br>&emsp;&emsp;如果需要添加下一个神经层，则不用再定义输入的维度，因为它默认就把前一层的输出作为当前层的输入。在这个例子里，只需要一层就够了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(output_dim=<span class="number">1</span>, input_dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h3 id="激活模型"><a href="#激活模型" class="headerlink" title="激活模型"></a>激活模型</h3><p>&emsp;&emsp;接下来要激活神经网络，上一步只是定义模型。在<code>compile</code>的参数中，误差函数用的是<code>mse</code>均方误差；优化器用的是<code>sgd</code>随机梯度下降法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># choose loss function and optimizing method</span></span><br><span class="line">model.compile(loss=<span class="string">'mse'</span>, optimizer=<span class="string">'sgd'</span>)</span><br></pre></td></tr></table></figure>
<p>于是就构建好了一个神经网络，它比<code>Tensorflow</code>要少了很多代码。</p>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>&emsp;&emsp;训练的时候用<code>model.train_on_batch</code>一批一批地训练<code>X_train</code>、<code>Y_train</code>。默认的返回值是<code>cost</code>，每<code>100</code>步输出一下结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training</span></span><br><span class="line">print(<span class="string">'Training -----------'</span>)</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">301</span>):</span><br><span class="line">    cost = model.train_on_batch(X_train, Y_train)</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'train cost: '</span>, cost)</span><br></pre></td></tr></table></figure>
<h3 id="检验模型"><a href="#检验模型" class="headerlink" title="检验模型"></a>检验模型</h3><p>&emsp;&emsp;检验用到的函数是<code>model.evaluate</code>，输入测试集的<code>x</code>和<code>y</code>，输出<code>cost</code>、<code>weights</code>和<code>biases</code>，其中<code>weights</code>和<code>biases</code>是取在模型的第一层<code>model.layers[0]</code>学习到的参数。从学习到的结果可以看到，<code>weights</code>比较接近<code>0.5</code>，<code>bias</code>接近<code>2</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">print(<span class="string">'\nTesting ------------'</span>)</span><br><span class="line">cost = model.evaluate(X_test, Y_test, batch_size=<span class="number">40</span>)</span><br><span class="line">print(<span class="string">'test cost:'</span>, cost)</span><br><span class="line">W, b = model.layers[<span class="number">0</span>].get_weights()</span><br><span class="line">print(<span class="string">'Weights='</span>, W, <span class="string">'\nbiases='</span>, b)</span><br></pre></td></tr></table></figure>
<h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><p>&emsp;&emsp;最后可以画出预测结果，与测试集的值进行对比：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plotting the prediction</span></span><br><span class="line">Y_pred = model.predict(X_test)</span><br><span class="line">plt.scatter(X_test, Y_test)</span><br><span class="line">plt.plot(X_test, Y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/13/深度学习/Keras之Regressor回归/1.png" height="299" width="399"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/13/深度学习/tf.profiler.ProfileOptionBuilder/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/13/深度学习/tf.profiler.ProfileOptionBuilder/" itemprop="url">tf.profiler.ProfileOptionBuilder</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T00:23:29+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Class-ProfileOptionBuilder"><a href="#Class-ProfileOptionBuilder" class="headerlink" title="Class ProfileOptionBuilder"></a>Class ProfileOptionBuilder</h3><p>&emsp;&emsp;Defined in <code>tensorflow/python/profiler/option_builder.py</code>. Option builder for profiling <code>API</code>. For tutorial on the options, see <code>https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Users can use pre-built options:</span></span><br><span class="line">opts = (tf.profiler.ProfileOptionBuilder.trainable_variables_parameter())</span><br><span class="line"><span class="comment"># Or, build your own options:</span></span><br><span class="line">opts = (tf.profiler.ProfileOptionBuilder().with_max_depth(<span class="number">10</span>).with_min_micros(<span class="number">1000</span>) \</span><br><span class="line">        .select([<span class="string">'accelerator_micros'</span>]).with_stdout_output().build())</span><br><span class="line"><span class="comment"># Or customize the pre-built options:</span></span><br><span class="line">opts = (tf.profiler.ProfileOptionBuilder(tf.profiler.ProfileOptionBuilder.time_and_memory()) \</span><br><span class="line">        .with_displaying_options(show_name_regexes=[<span class="string">'.*rnn.*'</span>]).build())</span><br><span class="line"><span class="comment"># Finally, profiling with the options:</span></span><br><span class="line">_ = tf.profiler.profile(tf.get_default_graph(), run_meta=run_meta, cmd=<span class="string">'scope'</span>, options=opts)</span><br></pre></td></tr></table></figure>
<h3 id="init"><a href="#init" class="headerlink" title="__init__"></a>__init__</h3><p>&emsp;&emsp;Constructor:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__init__(options=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>options</code>: Optional initial option dict to start with.</li>
</ul>
<h3 id="account-displayed-op-only"><a href="#account-displayed-op-only" class="headerlink" title="account_displayed_op_only"></a>account_displayed_op_only</h3><p>&emsp;&emsp;Whether only account the statistics of displayed profiler nodes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">account_displayed_op_only(is_true)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>is_true</code>: If <code>true</code>, only account statistics of nodes eventually displayed by the outputs. Otherwise, a node’s statistics are accounted by its parents as long as it’s types match <code>account_type_regexes</code>, even if it is hidden from the output, say, by <code>hide_name_regexes</code>.</li>
</ul>
<h3 id="build"><a href="#build" class="headerlink" title="build"></a>build</h3><p>&emsp;&emsp;Build a profiling option:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">build()</span><br></pre></td></tr></table></figure>
<p>Return a dict of profiling options.</p>
<h3 id="float-operation"><a href="#float-operation" class="headerlink" title="float_operation"></a>float_operation</h3><p>&emsp;&emsp;Options used to profile float operations:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line">float_operation()</span><br></pre></td></tr></table></figure>
<p>Please see <code>https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/profile_model_architecture.md</code> on the caveats of calculating <code>float</code> operations. Return a dict of profiling options.</p>
<h3 id="order-by"><a href="#order-by" class="headerlink" title="order_by"></a>order_by</h3><p>&emsp;&emsp;Order the displayed profiler nodes based on a attribute:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order_by(attribute)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>attribute</code>: An attribute the profiler node has.</li>
</ul>
<p>Supported attribute includes <code>micros</code>, <code>bytes</code>, <code>occurrence</code>, <code>params</code>, etc. See <code>https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md</code> for supported attributes.</p>
<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>&emsp;&emsp;Select the attributes to display:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select(attributes)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>attributes</code>: A list of attribute the profiler node has.</li>
</ul>
<h3 id="time-and-memory"><a href="#time-and-memory" class="headerlink" title="time_and_memory"></a>time_and_memory</h3><p>&emsp;&emsp;Show operation time and memory consumptions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line">time_and_memory(</span><br><span class="line">        min_micros=<span class="number">1</span>, min_bytes=<span class="number">1</span>, min_accelerator_micros=<span class="number">0</span>, min_cpu_micros=<span class="number">0</span>,</span><br><span class="line">        min_peak_bytes=<span class="number">0</span>, min_residual_bytes=<span class="number">0</span>, min_output_bytes=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>min_micros</code>: Only show profiler nodes with execution time no less than this. It sums accelerator and cpu times.</li>
<li><code>min_bytes</code>: Only show profiler nodes requested to allocate no less bytes than this.</li>
<li><code>min_accelerator_micros</code>: Only show profiler nodes spend no less than this time on accelerator (e.g. <code>GPU</code>).</li>
<li><code>min_cpu_micros</code>: Only show profiler nodes spend no less than this time on cpu.</li>
<li><code>min_peak_bytes</code>: Only show profiler nodes using no less than this bytes at peak (high watermark). For profiler nodes consist of multiple graph nodes, it sums the graph nodes’ <code>peak_bytes</code>.</li>
<li><code>min_residual_bytes</code>: Only show profiler nodes have no less than this bytes not being <code>de-allocated</code> after <code>Compute()</code> ends. For profiler nodes consist of multiple graph nodes, it sums the graph nodes’ <code>residual_bytes</code>.</li>
<li><code>min_output_bytes</code>: Only show profiler nodes have no less than this bytes output. The output are not necessarily allocated by this profiler nodes.</li>
</ul>
<p>Return a dict of profiling options.</p>
<h3 id="trainable-variables-parameter"><a href="#trainable-variables-parameter" class="headerlink" title="trainable_variables_parameter"></a>trainable_variables_parameter</h3><p>&emsp;&emsp;Options used to profile trainable variable parameters:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line">trainable_variables_parameter()</span><br></pre></td></tr></table></figure>
<p>Normally used together with <code>scope</code> view. Return a dict of profiling options.</p>
<h3 id="with-accounted-types"><a href="#with-accounted-types" class="headerlink" title="with_accounted_types"></a>with_accounted_types</h3><p>&emsp;&emsp;Selectively counting statistics based on node types:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_accounted_types(account_type_regexes)</span><br></pre></td></tr></table></figure>
<p>Here, <code>types</code> means the profiler nodes’ properties. Profiler by default consider device name (e.g. <code>/job:xx/.../device:GPU:0</code>) and operation type (e.g. <code>MatMul</code>) as profiler nodes’ properties. User can also associate customized <code>types</code> to profiler nodes through <code>OpLogProto</code> proto.<br>&emsp;&emsp;For example, user can select profiler nodes placed on <code>gpu:0</code> with <code>account_type_regexes=[&#39;.*gpu:0.*&#39;]</code><br>&emsp;&emsp;If none of a node’s properties match the specified regexes, the node is not displayed nor accounted.</p>
<ul>
<li><code>account_type_regexes</code>: A list of regexes specifying the types.</li>
</ul>
<h3 id="with-empty-output"><a href="#with-empty-output" class="headerlink" title="with_empty_output"></a>with_empty_output</h3><p>&emsp;&emsp;Do not generate <code>side-effect</code> outputs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_empty_output()</span><br></pre></td></tr></table></figure>
<h3 id="with-file-output"><a href="#with-file-output" class="headerlink" title="with_file_output"></a>with_file_output</h3><p>&emsp;&emsp;Print the result to a file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_file_output(outfile)</span><br></pre></td></tr></table></figure>
<h3 id="with-max-depth"><a href="#with-max-depth" class="headerlink" title="with_max_depth"></a>with_max_depth</h3><p>&emsp;&emsp;Set the maximum depth of display:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_max_depth(max_depth)</span><br></pre></td></tr></table></figure>
<p>The depth depends on profiling view. For <code>scope</code> view, it’s the depth of name scope hierarchy (<code>tree</code>), for <code>op</code> view, it’s the number of operation types (<code>list</code>), etc.</p>
<ul>
<li><code>max_depth</code>: Maximum depth of the data structure to display.</li>
</ul>
<h3 id="with-min-execution-time"><a href="#with-min-execution-time" class="headerlink" title="with_min_execution_time"></a>with_min_execution_time</h3><p>&emsp;&emsp;Only show profiler nodes consuming no less than <code>min_micros</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_min_execution_time(min_micros=<span class="number">0</span>, min_accelerator_micros=<span class="number">0</span>, min_cpu_micros=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>min_micros</code>: Only show profiler nodes with execution time no less than this. It sums accelerator and cpu times.</li>
<li><code>min_accelerator_micros</code>: Only show profiler nodes spend no less than this time on accelerator (e.g. <code>GPU</code>).</li>
<li><code>min_cpu_micros</code>: Only show profiler nodes spend no less than this time on cpu.</li>
</ul>
<h3 id="with-min-float-operations"><a href="#with-min-float-operations" class="headerlink" title="with_min_float_operations"></a>with_min_float_operations</h3><p>&emsp;&emsp;Only show profiler nodes consuming no less than <code>min_float_ops</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_min_float_operations(min_float_ops)</span><br></pre></td></tr></table></figure>
<p>Please see <code>https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/profile_model_architecture.md</code> on the caveats of calculating float operations.</p>
<ul>
<li><code>min_float_ops</code>: Only show profiler nodes with float operations no less than this.</li>
</ul>
<h3 id="with-min-memory"><a href="#with-min-memory" class="headerlink" title="with_min_memory"></a>with_min_memory</h3><p>&emsp;&emsp;Only show profiler nodes consuming no less than <code>min_bytes</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_min_memory(min_bytes=<span class="number">0</span>, min_peak_bytes=<span class="number">0</span>, min_residual_bytes=<span class="number">0</span>, min_output_bytes=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>min_bytes</code>: Only show profiler nodes requested to allocate no less bytes than this.</li>
<li><code>min_peak_bytes</code>: Only show profiler nodes using no less than this bytes at peak (high watermark). For profiler nodes consist of multiple graph nodes, it sums the graph nodes’ <code>peak_bytes</code>.</li>
<li><code>min_residual_bytes</code>: Only show profiler nodes have no less than this bytes not being <code>de-allocated</code> after <code>Compute()</code> ends. For profiler nodes consist of multiple graph nodes, it sums the graph nodes’ <code>residual_bytes</code>.</li>
<li><code>min_output_bytes</code>: Only show profiler nodes have no less than this bytes output. The output are not necessarily allocated by this profiler nodes.</li>
</ul>
<h3 id="with-min-occurrence"><a href="#with-min-occurrence" class="headerlink" title="with_min_occurrence"></a>with_min_occurrence</h3><p>&emsp;&emsp;Only show profiler nodes including no less than <code>min_occurrence</code> graph nodes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_min_occurrence(min_occurrence)</span><br></pre></td></tr></table></figure>
<p>A <code>node</code> means a profiler output node, which can be a python line (code view), an operation type (op view), or a graph node (<code>graph/scope</code> view). A python line includes all graph nodes created by that line, while an operation type includes all graph nodes of that type.</p>
<ul>
<li><code>min_occurrence</code>: Only show nodes including no less than this.</li>
</ul>
<h3 id="with-min-parameters"><a href="#with-min-parameters" class="headerlink" title="with_min_parameters"></a>with_min_parameters</h3><p>&emsp;&emsp;Only show profiler nodes holding no less than <code>min_params</code> parameters:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_min_parameters(min_params)</span><br></pre></td></tr></table></figure>
<p><code>Parameters</code> normally refers the weights of in <code>TensorFlow</code> variables. It reflects the <code>capacity</code> of models.</p>
<ul>
<li><code>min_params</code>: Only show profiler nodes holding number parameters no less than this.</li>
</ul>
<h3 id="with-node-names"><a href="#with-node-names" class="headerlink" title="with_node_names"></a>with_node_names</h3><p>&emsp;&emsp;Regular expressions used to select profiler nodes to display:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_node_names(start_name_regexes=<span class="keyword">None</span>, show_name_regexes=<span class="keyword">None</span>, hide_name_regexes=<span class="keyword">None</span>, trim_name_regexes=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>After <code>with_accounted_types</code> is evaluated, <code>with_node_names</code> are evaluated as follows:<br>&emsp;&emsp;For a profile data structure, profiler first finds the profiler nodes matching <code>start_name_regexes</code>, and starts displaying profiler nodes from there. Then, if a node matches <code>show_name_regexes</code> and doesn’t match <code>hide_name_regexes</code>, it’s displayed. If a node matches <code>trim_name_regexes</code>, profiler stops further searching that branch.</p>
<ul>
<li><code>start_name_regexes</code>: list of node name regexes to start displaying.</li>
<li><code>show_name_regexes</code>: list of node names regexes to display.</li>
<li><code>hide_name_regexes</code>: list of node_names regexes that should be hidden.</li>
<li><code>trim_name_regexes</code>: list of node name regexes from where to stop.</li>
</ul>
<h3 id="with-pprof-output"><a href="#with-pprof-output" class="headerlink" title="with_pprof_output"></a>with_pprof_output</h3><p>&emsp;&emsp;Generate a pprof profile <code>gzip</code> file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_pprof_output(pprof_file)</span><br></pre></td></tr></table></figure>
<p>To use the pprof file: <code>pprof -png --nodecount=100 --sample_index=1</code>.</p>
<ul>
<li><code>pprof_file</code>: filename for output, usually suffixed with <code>.pb.gz</code>.</li>
</ul>
<h3 id="with-stdout-output"><a href="#with-stdout-output" class="headerlink" title="with_stdout_output"></a>with_stdout_output</h3><p>&emsp;&emsp;Print the result to <code>stdout</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_stdout_output()</span><br></pre></td></tr></table></figure>
<h3 id="with-step"><a href="#with-step" class="headerlink" title="with_step"></a>with_step</h3><p>&emsp;&emsp;Which profile step to use for profiling:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_step(step)</span><br></pre></td></tr></table></figure>
<p>The <code>step</code> here refers to the step defined by <code>Profiler.add_step() API</code>.</p>
<ul>
<li><code>step</code>: When multiple steps of profiles are available, select which step’s profile to use. If <code>-1</code>, use average of all available steps.</li>
</ul>
<h3 id="with-timeline-output"><a href="#with-timeline-output" class="headerlink" title="with_timeline_output"></a>with_timeline_output</h3><p>&emsp;&emsp;Generate a timeline json file：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with_timeline_output(timeline_file)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="How-to-calculate-a-net’s-FLOPs-in-CNN"><a href="#How-to-calculate-a-net’s-FLOPs-in-CNN" class="headerlink" title="How to calculate a net’s FLOPs in CNN"></a>How to calculate a net’s FLOPs in CNN</h3><p>&emsp;&emsp;Problem: I want to design a convolutional neural network which occupy <code>GPU</code> resource no more than <code>Alexnet</code>. I want to use <code>FLOPs</code> to measure it but I don’t know how to calculate it. Is there any tools to do it, please?<br>&emsp;&emsp;Answer: For future visitors, if you use <code>Keras</code> and <code>TensorFlow</code> as Backend, then you can try the following example. It calculates the <code>FLOPs</code> for the <code>MobileNet</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.applications.mobilenet <span class="keyword">import</span> MobileNet</span><br><span class="line">​</span><br><span class="line">run_meta = tf.RunMetadata()</span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    K.set_session(sess)</span><br><span class="line">    net = MobileNet(alpha=<span class="number">.75</span>, input_tensor=tf.placeholder(<span class="string">'float32'</span>, shape=(<span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">    opts = tf.profiler.ProfileOptionBuilder.float_operation()</span><br><span class="line">    flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd=<span class="string">'op'</span>, options=opts)</span><br><span class="line">    opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()</span><br><span class="line">    params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd=<span class="string">'op'</span>, options=opts)</span><br><span class="line">    print(<span class="string">"&#123;:,&#125; --- &#123;:,&#125;"</span>.format(flops.total_float_ops, params.total_parameters))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/深度学习/TensorFlow优化器/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/深度学习/TensorFlow优化器/" itemprop="url">TensorFlow优化器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T17:59:27+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;深度学习常见的是对于梯度的优化，优化器最后其实就是各种对于梯度下降算法的优化。<code>TensorFLow</code>提供了很多优化器的支持。</p>
<h3 id="tf-train-GradientDescentOptimizer"><a href="#tf-train-GradientDescentOptimizer" class="headerlink" title="tf.train.GradientDescentOptimizer"></a>tf.train.GradientDescentOptimizer</h3><p>&emsp;&emsp;这个类是实现梯度下降算法的优化器。</p>
<h3 id="tf-train-AdadeltaOptimizer"><a href="#tf-train-AdadeltaOptimizer" class="headerlink" title="tf.train.AdadeltaOptimizer"></a>tf.train.AdadeltaOptimizer</h3><p>&emsp;&emsp;实现了<code>Adadelta</code>算法的优化器，该算法不需要手动调优学习速率，抗噪声能力强，可以选择不同的模型结构。<code>Adadelta</code>是对<code>Adagrad</code>的扩展。<code>Adadelta</code>只累加固定大小的项，并且也不直接存储这些项，仅仅是计算对应的平均值。</p>
<h3 id="tf-train-AdagradOptimizer"><a href="#tf-train-AdagradOptimizer" class="headerlink" title="tf.train.AdagradOptimizer"></a>tf.train.AdagradOptimizer</h3><p>&emsp;&emsp;实现了<code>AdagradOptimizer</code>算法的优化器，<code>Adagrad</code>会累加之前所有的梯度平方。它用于处理大的稀疏矩阵，<code>Adagrad</code>可以自动变更学习速率，只是需要设定一个全局的学习速率，但这并非是实际学习速率，实际的速率是与以往参数的模之和的开方成反比的。这样使得每个参数都有一个自己的学习率。</p>
<h3 id="tf-train-MomentumOptimizer"><a href="#tf-train-MomentumOptimizer" class="headerlink" title="tf.train.MomentumOptimizer"></a>tf.train.MomentumOptimizer</h3><p>&emsp;&emsp;实现了<code>MomentumOptimizer</code>算法的优化器，如果梯度长时间保持一个方向，则增大参数更新幅度；反之，如果频繁发生符号翻转，则说明这是要减小参数更新幅度。可以把这一过程理解成从山顶放下一个球，会滑的越来越快。</p>
<h3 id="tf-train-RMSPropOptimizer"><a href="#tf-train-RMSPropOptimizer" class="headerlink" title="tf.train.RMSPropOptimizer"></a>tf.train.RMSPropOptimizer</h3><p>&emsp;&emsp;实现了<code>RMSPropOptimizer</code>算法的优化器，它与<code>Adam</code>类似，只是使用了不同的滑动均值。</p>
<h3 id="tf-train-AdamOptimizer"><a href="#tf-train-AdamOptimizer" class="headerlink" title="tf.train.AdamOptimizer"></a>tf.train.AdamOptimizer</h3><p>&emsp;&emsp;实现了<code>AdamOptimizer</code>算法的优化器，它综合了<code>Momentum</code>和<code>RMSProp</code>方法，对每个参数保留一个学习率与一个根据过去梯度信息求得的指数衰减均值。</p>
<h3 id="如何选用optimizer"><a href="#如何选用optimizer" class="headerlink" title="如何选用optimizer"></a>如何选用optimizer</h3><p>&emsp;&emsp;对于稀疏数据，使用学习率可自适应的优化方法，不用手动调节，而且最好采用默认值。<code>SGD</code>通常训练时间更长，容易陷入鞍点，但是在好的初始化和学习率调度方案的情况下，结果更可靠。<br>&emsp;&emsp;如果在意更快的收敛，并且需要训练较深较复杂的网络时，推荐使用学习率自适应的优化方法。<code>Adadelta</code>、<code>RMSprop</code>和<code>Adam</code>是比较相近的算法，在相似的情况下表现差不多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line">train_X = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">train_Y = <span class="number">2</span> * train_X + np.random.randn(*train_X.shape) * <span class="number">0.33</span> + <span class="number">10</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># Define the model</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">Y = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">w = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"weight"</span>)</span><br><span class="line">b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias"</span>)</span><br><span class="line">loss = tf.square(Y - X * w - b)</span><br><span class="line">train_op = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(loss)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    epoch = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> (x, y) <span class="keyword">in</span> zip(train_X, train_Y):</span><br><span class="line">            _, w_value, b_value = sess.run([train_op, w, b], feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">        print(<span class="string">"Epoch: &#123;&#125;, w: &#123;&#125;, b: &#123;&#125;"</span>.format(epoch, w_value, b_value))</span><br><span class="line">        epoch += <span class="number">1</span></span><br><span class="line">​</span><br><span class="line">plt.plot(train_X, train_Y, <span class="string">"+"</span>)</span><br><span class="line">plt.plot(train_X, train_X.dot(w_value) + b_value)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">1</span>, w: <span class="number">-0.9016109108924866</span>, b: <span class="number">9.692331314086914</span></span><br><span class="line">Epoch: <span class="number">2</span>, w: <span class="number">0.23304520547389984</span>, b: <span class="number">10.46933364868164</span></span><br><span class="line">Epoch: <span class="number">3</span>, w: <span class="number">1.0166758298873901</span>, b: <span class="number">10.325897216796875</span></span><br><span class="line">Epoch: <span class="number">4</span>, w: <span class="number">1.4419575929641724</span>, b: <span class="number">10.183098793029785</span></span><br><span class="line">Epoch: <span class="number">5</span>, w: <span class="number">1.6616896390914917</span>, b: <span class="number">10.101426124572754</span></span><br><span class="line">Epoch: <span class="number">6</span>, w: <span class="number">1.7738741636276245</span>, b: <span class="number">10.058719635009766</span></span><br><span class="line">Epoch: <span class="number">7</span>, w: <span class="number">1.8309777975082397</span>, b: <span class="number">10.036850929260254</span></span><br><span class="line">Epoch: <span class="number">8</span>, w: <span class="number">1.860023021697998</span>, b: <span class="number">10.025708198547363</span></span><br><span class="line">Epoch: <span class="number">9</span>, w: <span class="number">1.8747929334640503</span>, b: <span class="number">10.020042419433594</span></span><br><span class="line">Epoch: <span class="number">10</span>, w: <span class="number">1.8823031187057495</span>, b: <span class="number">10.017163276672363</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/12/深度学习/TensorFlow优化器/1.png" height="263" width="352"></p>
<hr>
<p>&emsp;&emsp;这里使用<code>tensorflow</code>的优化器解决最优化问题。定义目标函数<code>loss = (x - 3)^2</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">​</span><br><span class="line">x = tf.Variable(tf.truncated_normal([<span class="number">1</span>]), name=<span class="string">"x"</span>)</span><br><span class="line">goal = tf.pow(x - <span class="number">3</span>, <span class="number">2</span>, name=<span class="string">"goal"</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x.initializer.run()</span><br><span class="line">    print(x.eval())</span><br><span class="line">    print(goal.eval())</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.20199603</span>]</span><br><span class="line">[<span class="number">7.828826</span>]</span><br></pre></td></tr></table></figure>
<p>求<code>goal</code>最小时的<code>x</code>值，使用梯度下降优化器可以解决问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">​</span><br><span class="line">x = tf.Variable(tf.truncated_normal([<span class="number">1</span>]), name=<span class="string">"x"</span>)</span><br><span class="line">goal = tf.pow(x - <span class="number">3</span>, <span class="number">2</span>, name=<span class="string">"goal"</span>)</span><br><span class="line">​</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.1</span>)</span><br><span class="line">train_step = optimizer.minimize(goal)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        x.initializer.run()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            print(<span class="string">"x:"</span>, x.eval())</span><br><span class="line">            train_step.run()</span><br><span class="line">            print(<span class="string">"goal:"</span>, goal.eval())</span><br><span class="line">​</span><br><span class="line">train()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x: [<span class="number">-0.83802974</span>]</span><br><span class="line">goal: [<span class="number">9.427503</span>]</span><br><span class="line">x: [<span class="number">-0.07042378</span>]</span><br><span class="line">goal: [<span class="number">6.033601</span>]</span><br><span class="line">x: [<span class="number">0.543661</span>]</span><br><span class="line">goal: [<span class="number">3.8615048</span>]</span><br><span class="line">x: [<span class="number">1.0349288</span>]</span><br><span class="line">goal: [<span class="number">2.4713633</span>]</span><br><span class="line">x: [<span class="number">1.427943</span>]</span><br><span class="line">goal: [<span class="number">1.5816724</span>]</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>minimize</code>实际上是<code>compute_gradients</code>与<code>apply_gradients</code>的和，即拆分成计算梯度和应用梯度两个步骤：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">​</span><br><span class="line">x = tf.Variable(tf.truncated_normal([<span class="number">1</span>]), name=<span class="string">"x"</span>)</span><br><span class="line">goal = tf.pow(x - <span class="number">3</span>, <span class="number">2</span>, name=<span class="string">"goal"</span>)</span><br><span class="line">​</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># compute_gradients返回的是“A list of (gradient, variable) pairs”</span></span><br><span class="line">gra_and_var = optimizer.compute_gradients(goal)</span><br><span class="line">train_step = optimizer.apply_gradients(gra_and_var)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        x.initializer.run()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            print(<span class="string">"x: "</span>, x.eval())</span><br><span class="line">            train_step.run()</span><br><span class="line">            print(<span class="string">"goal:"</span>, goal.eval())</span><br><span class="line">​</span><br><span class="line">train()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x: [<span class="number">-0.10070122</span>]</span><br><span class="line">goal: [<span class="number">6.153183</span>]</span><br><span class="line">x: [<span class="number">0.51943904</span>]</span><br><span class="line">goal: [<span class="number">3.938037</span>]</span><br><span class="line">x: [<span class="number">1.0155512</span>]</span><br><span class="line">goal: [<span class="number">2.5203435</span>]</span><br><span class="line">x: [<span class="number">1.412441</span>]</span><br><span class="line">goal: [<span class="number">1.6130198</span>]</span><br><span class="line">x: [<span class="number">1.7299528</span>]</span><br><span class="line">goal: [<span class="number">1.0323327</span>]</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/深度学习/tensorpack函数总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/深度学习/tensorpack函数总结/" itemprop="url">tensorpack函数总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T15:46:41+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="dataflow-TestDataSpeed"><a href="#dataflow-TestDataSpeed" class="headerlink" title="dataflow.TestDataSpeed"></a>dataflow.TestDataSpeed</h3><p>&emsp;&emsp;class <code>dataflow.TestDataSpeed(ds, size=5000, warmup=0)</code>: Test the speed of some <code>DataFlow</code>.<br>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): the <code>DataFlow</code> to test.</li>
<li><code>size</code> (<code>int</code>): number of datapoints to fetch.</li>
<li><code>warmup</code> (<code>int</code>): warmup iterations</li>
</ul>
<p>&emsp;&emsp;Function:</p>
<ul>
<li><code>get_data()</code>: Will run testing at the beginning, then produce data normally.</li>
<li><code>start()</code>: Alias of <code>start_test</code>.</li>
<li><code>start_test()</code>: Start testing with a progress bar.</li>
</ul>
<h3 id="dataflow-MultiThreadMapData"><a href="#dataflow-MultiThreadMapData" class="headerlink" title="dataflow.MultiThreadMapData"></a>dataflow.MultiThreadMapData</h3><p>&emsp;&emsp;class <code>dataflow.MultiThreadMapData(ds, nr_thread, map_func, buffer_size=200, strict=False)</code>: Same as <code>MapData</code>, but start threads to run the mapping function. This is useful when the mapping function is the bottleneck, but you don’t want to start processes for the entire dataflow pipeline.<br>&emsp;&emsp;<strong>Note</strong>: There is tiny communication overhead with threads, but you should avoid starting many threads in your main process to reduce GIL contention.<br>&emsp;&emsp;The threads will only start in the process which calls <code>reset_state()</code>. Therefore you can use <code>PrefetchDataZMQ(MultiThreadMapData(...), 1)</code> to reduce <code>GIL</code> contention.<br>&emsp;&emsp;Threads run in parallel and can take different time to run the mapping function. Therefore the order of datapoints won’t be preserved, and datapoints from one pass of <code>df.get_data()</code> might get mixed with datapoints from the next pass.<br>&emsp;&emsp;You can use strict mode, where <code>MultiThreadMapData.get_data()</code> is guaranteed to produce the exact set which <code>df.get_data()</code> produces. Although the order of data still isn’t preserved.</p>
<p>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): the dataflow to map.</li>
<li><code>nr_thread</code> (<code>int</code>): number of threads to use.</li>
<li><code>map_func</code> (<code>callable</code>): <code>datapoint -&gt; datapoint | None</code>.</li>
<li><code>buffer_size</code> (<code>int</code>): number of datapoints in the buffer.</li>
<li><code>strict</code> (<code>bool</code>): use <code>strict mode</code>.</li>
</ul>
<h3 id="dataflow-MapDataComponent"><a href="#dataflow-MapDataComponent" class="headerlink" title="dataflow.MapDataComponent"></a>dataflow.MapDataComponent</h3><p>&emsp;&emsp;class <code>dataflow.MapDataComponent(ds, func, index=0)</code>: Apply a <code>mapper/filter</code> on a datapoint component.<br>&emsp;&emsp;<strong>Note</strong>: This dataflow itself doesn’t modify the datapoints. But please make sure func doesn’t modify the components unless you’re certain it’s safe.<br>&emsp;&emsp;If you discard some datapoints, <code>ds.size()</code> will be incorrect.</p>
<p>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): input DataFlow.</li>
<li><code>func</code> (<code>TYPE -&gt; TYPE | None</code>): takes <code>dp[index]</code>, returns a new value for <code>dp[index]</code>. return <code>None</code> to discard this datapoint.</li>
<li><code>index</code> (<code>int</code>): index of the component.</li>
</ul>
<h3 id="dataflow-BatchData"><a href="#dataflow-BatchData" class="headerlink" title="dataflow.BatchData"></a>dataflow.BatchData</h3><p>&emsp;&emsp;class <code>dataflow.BatchData(ds, batch_size, remainder=False, use_list=False)</code>: Stack datapoints into batches. It produces datapoints of the same number of components as <code>ds</code>, but each component has one new extra dimension of size <code>batch_size</code>. The batch can be either a list of original components, or (by default) a numpy array of original components.</p>
<p>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): When <code>use_list=False</code>, the components of <code>ds</code> must be either scalars or <code>np.ndarray</code>, and have to be consistent in shapes.</li>
<li><code>batch_size</code> (<code>int</code>): batch size.</li>
<li><code>remainder</code> (<code>bool</code>): When the remaining datapoints in <code>ds</code> is not enough to form a batch, whether or not to also produce the remaining data as a smaller batch. If set to <code>False</code>, all produced datapoints are guaranteed to have the same batch size. If set to <code>True</code>, <code>ds.size()</code> must be accurate.</li>
<li><code>use_list</code> (<code>bool</code>): if <code>True</code>, each component will contain a list of datapoints instead of an numpy array of an extra dimension.</li>
</ul>
<p>&emsp;&emsp;Function:</p>
<ul>
<li><code>get_data()</code>: Yields: Batched data by stacking each component on an extra 0th dimension.</li>
</ul>
<h3 id="dataflow-MapData"><a href="#dataflow-MapData" class="headerlink" title="dataflow.MapData"></a>dataflow.MapData</h3><p>&emsp;&emsp;class <code>dataflow.MapData(ds, func)</code>: Apply a <code>mapper/filter</code> on the <code>DataFlow</code>.<br>&emsp;&emsp;<strong>Note</strong>: Please make sure <code>func</code> doesn’t modify the components unless you’re certain it’s safe.<br>&emsp;&emsp;If you discard some datapoints, <code>ds.size()</code> will be incorrect.<br>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): input <code>DataFlow</code>.</li>
<li><code>func</code> (<code>datapoint -&gt; datapoint | None</code>): takes a datapoint and returns a new datapoint. Return <code>None</code> to discard this datapoint.</li>
</ul>
<h3 id="dataflow-PrefetchData"><a href="#dataflow-PrefetchData" class="headerlink" title="dataflow.PrefetchData"></a>dataflow.PrefetchData</h3><p>&emsp;&emsp;alias of <code>tensorpack.dataflow.parallel.MultiProcessPrefetchData</code>.</p>
<h3 id="dataflow-MultiProcessPrefetchData"><a href="#dataflow-MultiProcessPrefetchData" class="headerlink" title="dataflow.MultiProcessPrefetchData"></a>dataflow.MultiProcessPrefetchData</h3><p>&emsp;&emsp;class <code>dataflow.MultiProcessPrefetchData(ds, nr_prefetch, nr_proc)</code>: Prefetch data from a <code>DataFlow</code> using <code>Python</code> multiprocessing utilities. It will fork the process calling <code>__init__()</code>, collect datapoints from <code>ds</code> in each process by a <code>Python multiprocessing.Queue</code>.<br>&emsp;&emsp;<strong>Note</strong>: An iterator cannot run faster automatically, what’s happening is that the underlying dataflow will be forked <code>nr_proc</code> times. As a result, we have the following guarantee on the dataflow correctness:<br>&emsp;&emsp;When <code>nr_proc = 1</code>, the dataflow produces the same data as <code>ds</code> in the same order.<br>&emsp;&emsp;When <code>nr_proc &gt; 1</code>, the dataflow produces the same distribution of data as <code>ds</code> if each sample from <code>ds</code> is <code>i.i.d.</code> (e.g. fully shuffled). You probably only want to use it for training.<br>&emsp;&emsp;This has more serialization overhead than <code>PrefetchDataZMQ</code> when data is large.<br>&emsp;&emsp;You can nest like this: <code>PrefetchDataZMQ(PrefetchData(df, nr_proc = a), nr_proc = b)</code>. A total of a instances of df worker processes will be created.<br>&emsp;&emsp;fork happens in <code>__init__</code>. <code>reset_state()</code> is a <code>no-op</code>. The worker processes won’t get called.<br>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>ds</code> (<code>DataFlow</code>): input <code>DataFlow</code>.</li>
<li><code>nr_prefetch</code> (<code>int</code>): size of the queue to hold prefetched datapoints.</li>
<li><code>nr_proc</code> (<code>int</code>): number of processes to use.</li>
</ul>
<h3 id="dataflow-RNGDataFlow"><a href="#dataflow-RNGDataFlow" class="headerlink" title="dataflow.RNGDataFlow"></a>dataflow.RNGDataFlow</h3><p>&emsp;&emsp;class <code>dataflow.RNGDataFlow</code>: A <code>DataFlow</code> with <code>RNG</code>.<br>&emsp;&emsp;Function:</p>
<ul>
<li><code>reset_state()</code>: Reset the <code>RNG</code>.</li>
</ul>
<h3 id="dataflow-DataFlowTerminated"><a href="#dataflow-DataFlowTerminated" class="headerlink" title="dataflow.DataFlowTerminated"></a>dataflow.DataFlowTerminated</h3><p>&emsp;&emsp;exception <code>dataflow.DataFlowTerminated</code>: An exception indicating that the <code>DataFlow</code> is unable to produce any more data, i.e. something wrong happened so that <code>calling get_data()</code> cannot give a valid iterator any more. In most <code>DataFlow</code> this will never be raised.</p>
<h3 id="dataflow-RemoteDataZMQ"><a href="#dataflow-RemoteDataZMQ" class="headerlink" title="dataflow.RemoteDataZMQ"></a>dataflow.RemoteDataZMQ</h3><p>&emsp;&emsp;class <code>dataflow.RemoteDataZMQ(addr1, addr2=None, hwm=50, bind=True)</code>: Produce data from <code>ZMQ PULL socket(s)</code>. It is the <code>receiver-side</code> counterpart of <code>send_dataflow_zmq()</code>, which uses <code>tensorpack.utils.serialize</code> for serialization. See <code>http://tensorpack.readthedocs.io/en/latest/tutorial/efficient-dataflow.html#distributed-dataflow</code>.<br>&emsp;&emsp;Parameters:</p>
<ul>
<li><code>addr1</code>, <code>addr2</code> (<code>str</code>): addr of the <code>zmq</code> endpoint to connect to. Use both if you need two protocols (e.g. both <code>IPC</code> and <code>TCP</code>). I don’t think you’ll ever need <code>3</code>.</li>
<li><code>hwm</code> (<code>int</code>): <code>ZMQ</code> <code>high-water</code> mark (buffer size).</li>
<li><code>bind</code> (<code>bool</code>): whether to connect or bind the endpoint.</li>
</ul>
<p>&emsp;&emsp;Function:</p>
<ul>
<li><code>bind_or_connect(socket, addr)</code></li>
</ul>
<h3 id="dataflow-imgaug-RotationAndCropValid"><a href="#dataflow-imgaug-RotationAndCropValid" class="headerlink" title="dataflow.imgaug.RotationAndCropValid"></a>dataflow.imgaug.RotationAndCropValid</h3><p>&emsp;&emsp;class <code>dataflow.imgaug.RotationAndCropValid(max_deg, interp=cv2.INTER_LINEAR, step_deg=None)</code>: Random rotate and then crop the largest possible rectangle. Note that this will produce images of different shapes.</p>
<p>&emsp;&emsp;Function:</p>
<ul>
<li><code>largest_rotated_rect(w, h, angle)</code>: Get largest rectangle after rotation.</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/机器学习/Logistic回归sklearn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/机器学习/Logistic回归sklearn/" itemprop="url">Logistic回归sklearn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T14:04:32+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>sklearn.linear_model</code>模块提供了很多模型供我们使用，比如<code>Logistic</code>回归、<code>Lasso</code>回归、贝叶斯脊回归等：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>linear_model.ARDRegression([n_iter, tol, ...])</code></td>
<td><code>Bayesian ARD regression</code></td>
</tr>
<tr>
<td><code>linear_model.BayesianRidge([n_iter, tol, ...])</code></td>
<td><code>Bayesian ridge regression</code></td>
</tr>
<tr>
<td><code>linear_model.ElasticNet([alpha, l1_ratio, ...])</code></td>
<td><code>Linear regression</code> with combined <code>L1</code> and <code>L2</code> priors as regularizer</td>
</tr>
<tr>
<td><code>linear_model.ElasticNetCV([l1_ratio, eps, ...])</code></td>
<td><code>Elastic Net model</code> with iterative fitting along a regularization path</td>
</tr>
<tr>
<td><code>linear_model.HuberRegressor([epsilon, ...])</code></td>
<td><code>Linear regression</code> model that is robust to outliers</td>
</tr>
<tr>
<td><code>linear_model.Lars([fit_intercept, verbose, ...])</code></td>
<td><code>Least Angle Regression</code> model <code>a.k.a</code></td>
</tr>
<tr>
<td><code>linear_model.LarsCV([fit_intercept, ...])</code></td>
<td><code>Cross-validated Least Angle Regression</code> model</td>
</tr>
<tr>
<td><code>linear_model.Lasso([alpha, fit_intercept, ...])</code></td>
<td><code>Linear Model</code> trained with <code>L1</code> prior as regularizer</td>
</tr>
<tr>
<td><code>linear_model.LassoCV([eps, n_alphas, ...])</code></td>
<td><code>Lasso</code> linear model with iterative fitting along a regularization path</td>
</tr>
<tr>
<td><code>linear_model.LassoLars([alpha, ...])</code></td>
<td><code>Lasso</code> model fit with <code>Least Angle Regression</code></td>
</tr>
<tr>
<td><code>linear_model.LassoLarsCV([fit_intercept, ...])</code></td>
<td><code>Cross-validated Lasso</code>, using the <code>LARS</code> algorithm</td>
</tr>
<tr>
<td><code>linear_model.LassoLarsIC([criterion, ...])</code></td>
<td><code>Lasso</code> model fit with <code>Lars</code> using <code>BIC</code> or <code>AIC</code> for model selection</td>
</tr>
<tr>
<td><code>linear_model.LinearRegression([...])</code></td>
<td>Ordinary least squares <code>Linear Regression</code></td>
</tr>
<tr>
<td><code>linear_model.LogisticRegression([penalty, ...])</code></td>
<td><code>Logistic Regression</code> (<code>aka logit</code>, <code>MaxEnt</code>) classifier</td>
</tr>
<tr>
<td><code>linear_model.LogisticRegressionCV([Cs, ...])</code></td>
<td><code>Logistic Regression CV</code> (<code>aka logit</code>, <code>MaxEnt</code>) classifier</td>
</tr>
<tr>
<td><code>linear_model.MultiTaskLasso([alpha, ...])</code></td>
<td><code>Multi-task Lasso</code> model trained with <code>L1/L2</code> <code>mixed-norm</code> as regularizer</td>
</tr>
<tr>
<td><code>linear_model.MultiTaskElasticNet([alpha, ...])</code></td>
<td><code>Multi-task ElasticNet</code> model trained with <code>L1/L2</code> <code>mixed-norm</code> as regularizer</td>
</tr>
<tr>
<td><code>linear_model.MultiTaskLassoCV([eps, ...])</code></td>
<td><code>Multi-task L1/L2 Lasso</code> with <code>built-in</code> <code>cross-validation</code></td>
</tr>
<tr>
<td><code>linear_model.MultiTaskElasticNetCV([...])</code></td>
<td><code>Multi-task L1/L2 ElasticNet</code> with <code>built-in</code> <code>cross-validation</code></td>
</tr>
<tr>
<td><code>linear_model.OrthogonalMatchingPursuit([...])</code></td>
<td><code>Orthogonal Matching Pursuit</code> model</td>
</tr>
<tr>
<td><code>linear_model.OrthogonalMatchingPursuitCV([...])</code></td>
<td><code>Cross-validated</code> <code>Orthogonal Matching Pursuit</code> model</td>
</tr>
<tr>
<td><code>linear_model.PassiveAggressiveClassifier([...])</code></td>
<td><code>Passive Aggressive Classifier</code></td>
</tr>
<tr>
<td><code>linear_model.PassiveAggressiveRegressor([C, ...])</code></td>
<td><code>Passive Aggressive Regressor</code></td>
</tr>
<tr>
<td><code>linear_model.RANSACRegressor([...])</code></td>
<td><code>RANSAC</code> (<code>RANdom SAmple Consensus</code>) algorithm</td>
</tr>
<tr>
<td><code>linear_model.Ridge([alpha, fit_intercept, ...])</code></td>
<td><code>Linear</code> least squares with <code>l2</code> regularization</td>
</tr>
<tr>
<td><code>linear_model.RidgeClassifier([alpha, ...])</code></td>
<td>Classifier using <code>Ridge</code> regression</td>
</tr>
<tr>
<td><code>linear_model.RidgeClassifierCV([alphas, ...])</code></td>
<td>Ridge classifier with <code>built-in</code> <code>cross-validation</code></td>
</tr>
<tr>
<td><code>linear_model.RidgeCV([alphas, ...])</code></td>
<td>Ridge regression with <code>built-in</code> <code>cross-validation</code></td>
</tr>
<tr>
<td><code>linear_model.SGDClassifier([loss, penalty, ...])</code></td>
<td><code>Linear</code> classifiers (<code>SVM</code>, <code>logistic regression</code>) with <code>SGD</code> training</td>
</tr>
<tr>
<td><code>linear_model.SGDRegressor([loss, penalty, ...])</code></td>
<td><code>Linear</code> model fitted by minimizing a regularized empirical loss with <code>SGD</code></td>
</tr>
<tr>
<td><code>linear_model.TheilSenRegressor([...])</code></td>
<td><code>Theil-Sen Estimator</code>: robust multivariate regression model</td>
</tr>
<tr>
<td><code>linear_model.enet_path(X, y[, l1_ratio, ...])</code></td>
<td>Compute elastic net path with coordinate descent</td>
</tr>
<tr>
<td><code>linear_model.lars_path(X, y[, Xy, Gram, ...])</code></td>
<td>Compute <code>Least Angle Regression</code> or <code>Lasso</code> path using <code>LARS</code> algorithm</td>
</tr>
<tr>
<td><code>linear_model.lasso_path(X, y[, eps, ...])</code></td>
<td>Compute <code>Lasso</code> path with coordinate descent</td>
</tr>
<tr>
<td><code>linear_model.logistic_regression_path(X, y)</code></td>
<td>Compute a <code>Logistic Regression</code> model for a list of regularization parameters</td>
</tr>
<tr>
<td><code>linear_model.orthogonal_mp(X, y[, ...])</code></td>
<td><code>Orthogonal Matching Pursuit</code></td>
</tr>
<tr>
<td><code>linear_model.orthogonal_mp_gram(Gram, Xy[, ...])</code></td>
<td><code>Gram Orthogonal Matching Pursuit</code></td>
</tr>
</tbody>
</table>
</div>
<p>先看一下<code>LogisticRegression</code>这个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">linear_model</span>.<span class="title">LogisticRegression</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    penalty=<span class="string">"l2"</span>, dual=False, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>, fit_intercept=True, intercept_scaling=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    class_weight=None, random_state=None, solver=<span class="string">"liblinear"</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">"ovr"</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    verbose=<span class="number">0</span>, warm_start=False, n_jobs=<span class="number">1</span>)</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>penalty</code>：惩罚项，<code>str</code>类型，可选参数为<code>l1</code>和<code>l2</code>，用于指定惩罚项中使用的规范。<code>newton-cg</code>、<code>sag</code>和<code>lbfgs</code>求解算法只支持<code>L2</code>规范。<code>L1</code>规范假设的是模型的参数满足拉普拉斯分布，<code>L2</code>假设的模型参数满足高斯分布。所谓的规范就是加上对参数的约束，使得模型更不会过拟合(<code>overfit</code>)，但是如果要说是不是加了约束就会好，这个没有人能回答，只能说在加约束的情况下，理论上应该可以获得泛化能力更强的结果。</li>
<li><code>dual</code>：对偶或原始方法，<code>bool</code>类型。对偶方法只用在求解线性多核(<code>liblinear</code>)的<code>L2</code>惩罚项上。当样本数量大于样本特征的时候，<code>dual</code>通常设置为<code>False</code>。</li>
<li><code>tol</code>：停止求解的标准，<code>float</code>类型。就是求解到多少的时候停止，认为已经求出最优解。</li>
<li><code>c</code>：正则化系数λ的倒数，<code>float</code>类型，必须是正浮点型数。像<code>SVM</code>一样，越小的数值表示越强的正则化。</li>
<li><code>fit_intercept</code>：是否存在截距或偏差，<code>bool</code>类型。</li>
<li><code>intercept_scaling</code>：<code>float</code>类型。仅在正则化项为<code>liblinear</code>且<code>fit_intercept</code>设置为<code>True</code>时有用。</li>
<li><code>class_weight</code>：用于标示分类模型中各种类型的权重，可以是一个字典或者<code>balanced</code>字符串，默认为不输入，也就是不考虑权重。如果选择输入的话，可以选择<code>balanced</code>让类库自己计算类型权重，或者自己输入各个类型的权重。举个例子，比如对于<code>0</code>和<code>1</code>的二元模型，我们可以定义<code>class_weight = {0:0.9, 1:0.1}</code>，这样类型<code>0</code>的权重为<code>90%</code>，而类型<code>1</code>的权重为<code>10%</code>；如果<code>class_weight</code>选择<code>balanced</code>，那么类库会根据训练样本量来计算权重。某种类型样本量越多，则权重越低；样本量越少，则权重越高。当<code>class_weight</code>为<code>balanced</code>时，类权重计算方法为<code>n_samples / (n_classes * np.bincount(y))</code>，<code>n_samples</code>为样本数，<code>n_classes</code>为类别数量，<code>np.bincount(y)</code>会输出每个类的样本数，例如<code>y = [1, 0, 0, 1, 1]</code>，则<code>np.bincount(y) = [2, 3]</code>。</li>
</ul>
<p>&emsp;&emsp;那么<code>class_weight</code>有什么作用呢？在分类模型中，我们经常会遇到两类问题：</p>
<ol>
<li>误分类的代价很高。比如对合法用户和非法用户进行分类，将非法用户分类为合法用户的代价很高，我们宁愿将合法用户分类为非法用户，这时可以人工再甄别，但是却不愿将非法用户分类为合法用户。这时我们可以适当提高非法用户的权重。</li>
<li>样本是高度失衡。比如我们有合法用户和非法用户的二元样本数据<code>10000</code>条，里面合法用户有<code>9995</code>条，非法用户只有<code>5</code>条，如果我们不考虑权重，则可以将所有的测试集都预测为合法用户，这样预测准确率理论上有<code>99.95%</code>，但是却没有任何意义。这时我们可以选择<code>balanced</code>，让类库自动提高非法用户样本的权重。提高了某种分类的权重，相比不考虑权重，会有更多的样本分类划分到高权重的类别，从而可以解决上面两类问题。</li>
</ol>
<ul>
<li><code>random_state</code>：随机数种子，<code>int</code>类型，可选参数，仅在正则化优化算法为<code>sag</code>、<code>liblinear</code>时有用。</li>
<li><code>solver</code>：优化算法选择参数，只有五个可选参数，即<code>newton-cg</code>、<code>lbfgs</code>、<code>liblinear</code>、<code>sag</code>和<code>saga</code>，默认为<code>liblinear</code>。<code>solver</code>参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择，分别是：</li>
</ul>
<ol>
<li><code>liblinear</code>：使用了开源的<code>liblinear</code>库实现，内部使用了坐标轴下降法来迭代优化损失函数。</li>
<li><code>lbfgs</code>：拟牛顿法的一种，利用损失函数二阶导数矩阵(即海森矩阵)来迭代优化损失函数。</li>
<li><code>newton-cg</code>：也是牛顿法家族的一种，利用损失函数二阶导数矩阵(即海森矩阵)来迭代优化损失函数。</li>
<li><code>sag</code>：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。</li>
<li><code>saga</code>：线性收敛的随机优化算法的的变重。</li>
</ol>
<p>&emsp;&emsp;<code>liblinear</code>适用于小数据集，而<code>sag</code>和<code>saga</code>适用于大数据集，因为速度更快。<br>&emsp;&emsp;对于多分类问题，只有<code>newton-cg</code>、<code>sag</code>、<code>saga</code>和<code>lbfgs</code>能够处理多项损失，而<code>liblinear</code>受限于一对剩余(<code>OvR</code>)。意思就是用<code>liblinear</code>的时候，如果是多分类问题，得先把一种类别作为一个类别，剩余的所有类别作为另外一个类别。依次类推，最终遍历所有类别，进行分类。<br>&emsp;&emsp;<code>newton-cg</code>、<code>sag</code>和<code>lbfgs</code>这三种优化算法时都需要损失函数的一阶或者二阶连续导数，因此不能用于没有连续导数的<code>L1</code>正则化，只能用于<code>L2</code>正则化。而<code>liblinear</code>和<code>saga</code>通吃<code>L1</code>正则化和<code>L2</code>正则化。<br>&emsp;&emsp;同时，<code>sag</code>每次仅仅使用了部分样本进行梯度迭代，所以当样本量少的时候不要选择它。而如果样本量非常大，比如大于<code>10</code>万，<code>sag</code>是第一选择。但是<code>sag</code>不能用于<code>L1</code>正则化，所以当你有大量的样本又需要<code>L1</code>正则化的话，就要自己做取舍了。要么通过对样本采样来降低样本量，要么回到<code>L2</code>正则化。<br>&emsp;&emsp;从上面的描述，大家可能觉得既然<code>newton-cg</code>、<code>lbfgs</code>和<code>sag</code>这么多限制，如果不是大样本，我们选择<code>liblinear</code>不就行了吗？这是错误的，因为<code>liblinear</code>也有自己的弱点！我们知道，逻辑回归有二元逻辑回归和多元逻辑回归。对于多元逻辑回归常见的有<code>one-vs-rest</code>(<code>OvR</code>)和<code>many-vs-many</code>(<code>MvM</code>)两种，而<code>MvM</code>一般比<code>OvR</code>分类相对准确一些。郁闷的是<code>liblinear</code>只支持<code>OvR</code>却不支持<code>MvM</code>，这样如果我们需要相对精确的多元逻辑回归时，就不能选择<code>liblinear</code>了，即不能使用<code>L1</code>正则化。</p>
<ul>
<li><code>max_iter</code>：算法收敛最大迭代次数，<code>int</code>类型。仅在正则化优化算法为<code>newton-cg</code>、<code>sag</code>和<code>lbfgs</code>才有用，算法收敛的最大迭代次数。</li>
<li><code>multi_class</code>：分类方式选择参数，<code>str</code>类型，可选参数为<code>ovr</code>和<code>multinomial</code>。<code>ovr</code>即<code>one-vs-rest</code>，而<code>multinomial</code>即<code>many-vs-many</code>。如果是二元逻辑回归，<code>ovr</code>和<code>multinomial</code>并没有任何区别，区别主要在多元逻辑回归上。</li>
</ul>
<p>&emsp;&emsp;<code>OvR</code>和<code>MvM</code>有什么不同？<code>OvR</code>的思想很简单，无论你是多少元逻辑回归，我们都可以看做二元逻辑回归。具体做法是，对于第<code>K</code>类的分类决策，我们把所有第<code>K</code>类的样本作为正例，除了第<code>K</code>类样本以外的所有样本都作为负例，然后在上面做二元逻辑回归，得到第<code>K</code>类的分类模型。其他类的分类模型获得以此类推。而<code>MvM</code>则相对复杂，这里举<code>MvM</code>的特例<code>one-vs-one</code>(<code>OvO</code>)作讲解。如果模型有<code>T</code>类，我们每次在所有的<code>T</code>类样本里面选择两类样本出来，不妨记为<code>T1</code>类和<code>T2</code>类，把所有的输出为<code>T1</code>和<code>T2</code>的样本放在一起，把<code>T1</code>作为正例，<code>T2</code>作为负例，进行二元逻辑回归，得到模型参数，一共需要<code>T(T - 1) / 2</code>次分类。可以看出<code>OvR</code>相对简单，但分类效果相对略差(这里指大多数样本分布情况，某些样本分布下<code>OvR</code>可能更好)；<code>MvM</code>分类相对精确，但是分类速度没有<code>OvR</code>快。如果选择了<code>ovr</code>，则<code>4</code>种损失函数的优化方法<code>liblinear</code>、<code>newton-cg</code>、<code>lbfgs</code>和<code>sag</code>都可以选择。但是如果选择了<code>multinomial</code>，则只能选择<code>newton-cg</code>、<code>lbfgs</code>和<code>sag</code>了。</p>
<ul>
<li><code>verbose</code>：日志冗长度，<code>int</code>类型，就是不输出训练过程；<code>1</code>的时候偶尔输出结果；如果大于<code>1</code>，对于每个子模型都输出。</li>
<li><code>warm_start</code>：热启动参数，<code>bool</code>类型。如果为<code>True</code>，则下一次训练是以追加树的形式进行(重新使用上一次的调用作为初始化)。</li>
<li><code>n_jobs</code>：并行数，<code>int</code>类型。<code>1</code>的时候，用<code>CPU</code>的一个内核运行程序；<code>2</code>的时候，用<code>CPU</code>的<code>2</code>个内核运行程序；<code>-1</code>的时候，用所有<code>CPU</code>的内核运行程序。</li>
</ul>
<p>&emsp;&emsp;<code>LogisticRegression</code>也提供了一些方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>decision_function(X)</code></td>
<td>Predict confidence scores for samples</td>
</tr>
<tr>
<td><code>densify()</code></td>
<td>Convert coefficient matrix to dense array format</td>
</tr>
<tr>
<td><code>fit(X, y[, sample_weight])</code></td>
<td>Fit the model according to the given training data</td>
</tr>
<tr>
<td><code>get_params([deep])</code></td>
<td>Get parameters for this estimator</td>
</tr>
<tr>
<td><code>predict(X)</code></td>
<td>Predict class labels for samples in <code>X</code></td>
</tr>
<tr>
<td><code>predict_log_proba(X)</code></td>
<td>Log of probability estimates</td>
</tr>
<tr>
<td><code>predict_proba(X)</code></td>
<td>Probability estimates</td>
</tr>
<tr>
<td><code>score(X, y[, sample_weight])</code></td>
<td>Returns the mean accuracy on the given test data and labels</td>
</tr>
<tr>
<td><code>set_params(**params)</code></td>
<td>Set the parameters of this estimator</td>
</tr>
<tr>
<td><code>sparsify()</code></td>
<td>Convert coefficient matrix to sparse format</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;针对从疝气病症状预测病马的死亡率的案例，使用<code>sklearn</code>的解决方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">​</span><br><span class="line"><span class="string">""" 使用Sklearn构建Logistic回归分类器 """</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicSklearn</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain = open(<span class="string">'horseColicTraining.txt'</span>)  <span class="comment"># 打开训练集</span></span><br><span class="line">    frTest = open(<span class="string">'horseColicTest.txt'</span>)  <span class="comment"># 打开测试集</span></span><br><span class="line">    trainingSet = []</span><br><span class="line">    trainingLabels = []</span><br><span class="line">    testSet = []</span><br><span class="line">    testLabels = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(currLine) - <span class="number">1</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">-1</span>]))</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(currLine) - <span class="number">1</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        testSet.append(lineArr)</span><br><span class="line">        testLabels.append(float(currLine[<span class="number">-1</span>]))</span><br><span class="line">    classifier = LogisticRegression(solver=<span class="string">'liblinear'</span>, max_iter=<span class="number">10</span>).fit(trainingSet, trainingLabels)</span><br><span class="line">    test_accurcy = classifier.score(testSet, testLabels) * <span class="number">100</span></span><br><span class="line">    print(<span class="string">'正确率:%f%%'</span> % test_accurcy)  <span class="comment"># 正确率:73.134328%</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    colicSklearn()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/机器学习/sklearn的数据预处理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/机器学习/sklearn的数据预处理/" itemprop="url">sklearn的数据预处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T12:04:27+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>klearn.preprocessing</code>提供了各种公共函数，用于将<code>raw feature vector</code>转换成另外一种更适合评估器工作的格式。</p>
<h3 id="标准化-Standardization-、平均移除法-mean-removal-和方差归一化-variance-scaling"><a href="#标准化-Standardization-、平均移除法-mean-removal-和方差归一化-variance-scaling" class="headerlink" title="标准化(Standardization)、平均移除法(mean removal)和方差归一化(variance scaling)"></a>标准化(Standardization)、平均移除法(mean removal)和方差归一化(variance scaling)</h3><p>&emsp;&emsp;<code>scale</code>函数提供了一个快速而简单的方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>              [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled = preprocessing.scale(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled</span><br><span class="line">array([[ <span class="number">0.</span>  ..., <span class="number">-1.22</span>...,  <span class="number">1.33</span>...],</span><br><span class="line">       [ <span class="number">1.22</span>...,  <span class="number">0.</span>  ..., <span class="number">-0.26</span>...],</span><br><span class="line">       [<span class="number">-1.22</span>...,  <span class="number">1.22</span>..., <span class="number">-1.06</span>...]])</span><br></pre></td></tr></table></figure>
<p>归一化后的数据其均值为<code>0</code>，方差为<code>1</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled.mean(axis=<span class="number">0</span>)</span><br><span class="line">array([ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_scaled.std(axis=<span class="number">0</span>)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>])</span><br></pre></td></tr></table></figure>
<p>一般会把<code>train</code>和<code>test</code>集放在一起做标准化，或者在<code>train</code>集上做标准化后，用同样的标准化器去标准化<code>test</code>集，此时可以用<code>StandardScaler</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = preprocessing.StandardScaler().fit(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler</span><br><span class="line">StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler.mean_</span><br><span class="line">array([ <span class="number">1.</span> ...,  <span class="number">0.</span> ...,  <span class="number">0.33</span>...])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler.scale_</span><br><span class="line">array([ <span class="number">0.81</span>...,  <span class="number">0.81</span>...,  <span class="number">1.24</span>...])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler.transform(X)</span><br><span class="line">array([[ <span class="number">0.</span>  ..., <span class="number">-1.22</span>...,  <span class="number">1.33</span>...],</span><br><span class="line">       [ <span class="number">1.22</span>...,  <span class="number">0.</span>  ..., <span class="number">-0.26</span>...],</span><br><span class="line">       [<span class="number">-1.22</span>...,  <span class="number">1.22</span>..., <span class="number">-1.06</span>...]])</span><br></pre></td></tr></table></figure>
<p>通过在<code>StandardScaler</code>的构造函数中设置<code>with_mean=False</code>或者<code>with_std=False</code>，可以禁止均值中心化(<code>centering</code>)和归一化(<code>scaling</code>)。</p>
<h3 id="将feature归一化到一个范围内"><a href="#将feature归一化到一个范围内" class="headerlink" title="将feature归一化到一个范围内"></a>将feature归一化到一个范围内</h3><p>&emsp;&emsp;另一种标准化方式是将<code>feature</code>归一化到给定的范围内(比如<code>[0, 1]</code>之间)，可以使用<code>MinMaxScaler</code>或者<code>MaxAbsScaler</code>函数。<br>&emsp;&emsp;归一化至<code>[0, 1]</code>的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>                    [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_minmax = min_max_scaler.fit_transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_minmax</span><br><span class="line">array([[ <span class="number">0.5</span>       ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ],</span><br><span class="line">       [ <span class="number">1.</span>        ,  <span class="number">0.5</span>       ,  <span class="number">0.33333333</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">1.</span>        ,  <span class="number">0.</span>        ]])</span><br></pre></td></tr></table></figure>
<p>如果<code>MinMaxScaler</code>给出了显式的范围，例如<code>feature_range=(min, max)</code>，那么对应的公式为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_std = (X - X.min(axis=<span class="number">0</span>)) / (X.max(axis=<span class="number">0</span>) - X.min(axis=<span class="number">0</span>))</span><br><span class="line">X_scaled = X_std / (max - min) + min</span><br></pre></td></tr></table></figure>
<p><code>MaxAbsScaler</code>以类似的方式工作，它的归一化范围在<code>[-1, 1]</code>之间：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>                    [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>max_abs_scaler = preprocessing.MaxAbsScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_maxabs = max_abs_scaler.fit_transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_maxabs</span><br><span class="line">array([[ <span class="number">0.5</span>, <span class="number">-1.</span> ,  <span class="number">1.</span> ],</span><br><span class="line">       [ <span class="number">1.</span> ,  <span class="number">0.</span> ,  <span class="number">0.</span> ],</span><br><span class="line">       [ <span class="number">0.</span> ,  <span class="number">1.</span> , <span class="number">-0.5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_test = np.array([[ <span class="number">-3.</span>, <span class="number">-1.</span>,  <span class="number">4.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_test_maxabs = max_abs_scaler.transform(X_test)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_test_maxabs</span><br><span class="line">array([[<span class="number">-1.5</span>, <span class="number">-1.</span> ,  <span class="number">2.</span> ]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>max_abs_scaler.scale_</span><br><span class="line">array([ <span class="number">2.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br></pre></td></tr></table></figure>
<h3 id="正态分布化-Normalization"><a href="#正态分布化-Normalization" class="headerlink" title="正态分布化(Normalization)"></a>正态分布化(Normalization)</h3><p>&emsp;&emsp;<code>Normalization</code>用于将各个样本归一化为正态分布，函数<code>normalize</code>提供了这一功能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>     [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>     [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_normalized = preprocessing.normalize(X, norm=<span class="string">'l2'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_normalized</span><br><span class="line">array([[ <span class="number">0.40</span>..., <span class="number">-0.40</span>...,  <span class="number">0.81</span>...],</span><br><span class="line">       [ <span class="number">1.</span>  ...,  <span class="number">0.</span>  ...,  <span class="number">0.</span>  ...],</span><br><span class="line">       [ <span class="number">0.</span>  ...,  <span class="number">0.70</span>..., <span class="number">-0.70</span>...]])</span><br></pre></td></tr></table></figure>
<p><code>Normalizer</code>类也可以实现这一功能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalizer = preprocessing.Normalizer().fit(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalizer</span><br><span class="line">Normalizer(copy=<span class="keyword">True</span>, norm=<span class="string">'l2'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalizer.transform(X)</span><br><span class="line">array([[ <span class="number">0.40</span>..., <span class="number">-0.40</span>...,  <span class="number">0.81</span>...],</span><br><span class="line">       [ <span class="number">1.</span>  ...,  <span class="number">0.</span>  ...,  <span class="number">0.</span>  ...],</span><br><span class="line">       [ <span class="number">0.</span>  ...,  <span class="number">0.70</span>..., <span class="number">-0.70</span>...]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalizer.transform([[<span class="number">-1.</span>,  <span class="number">1.</span>, <span class="number">0.</span>]])</span><br><span class="line">array([[<span class="number">-0.70</span>...,  <span class="number">0.70</span>...,  <span class="number">0.</span>  ...]])</span><br></pre></td></tr></table></figure>
<h3 id="二值化-Binarization"><a href="#二值化-Binarization" class="headerlink" title="二值化(Binarization)"></a>二值化(Binarization)</h3><p>&emsp;&emsp;二值化可以将数值形(<code>numerical</code>)的<code>feature</code>进行阀值化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>],</span><br><span class="line"><span class="meta">... </span>     [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line"><span class="meta">... </span>     [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>binarizer = preprocessing.Binarizer().fit(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>binarizer</span><br><span class="line">Binarizer(copy=<span class="keyword">True</span>, threshold=<span class="number">0.0</span>)  <span class="comment"># 调整binarizer的threshold</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>binarizer.transform(X)</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="补充缺失值"><a href="#补充缺失值" class="headerlink" title="补充缺失值"></a>补充缺失值</h3><p>&emsp;&emsp;现实世界中有许多数据集中包含着缺失值(<code>missing values</code>)，经常被编码成空格、<code>NaN</code>或者其它占位符。这样的数据集对于<code>sklearn</code>来说是不兼容的，因为它的输入数据必须是全是数值型的。<br>&emsp;&emsp;一个基本策略是使用不完整的数据，即抛弃掉那些带缺失值的行。然而，缺失的数据中也可能包含有价值的信息。一个更好地策略是补充缺失值，比如从已知的数据中去模拟它们。<br>&emsp;&emsp;<code>Imputer</code>类提供了基本策略来补充缺失值，或者使用均值、中值，或者是行中或列中最常用的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp = Imputer(missing_values=<span class="string">'NaN'</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp.fit([[<span class="number">1</span>, <span class="number">2</span>], [np.nan, <span class="number">3</span>], [<span class="number">7</span>, <span class="number">6</span>]])</span><br><span class="line">Imputer(axis=<span class="number">0</span>, copy=<span class="keyword">True</span>, missing_values=<span class="string">'NaN'</span>, strategy=<span class="string">'mean'</span>, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[np.nan, <span class="number">2</span>], [<span class="number">6</span>, np.nan], [<span class="number">7</span>, <span class="number">6</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(imp.transform(X))</span><br><span class="line">[[ <span class="number">4.</span>          <span class="number">2.</span>        ]</span><br><span class="line"> [ <span class="number">6.</span>          <span class="number">3.666</span>...]</span><br><span class="line"> [ <span class="number">7.</span>          <span class="number">6.</span>        ]]</span><br></pre></td></tr></table></figure>
<h3 id="多项式特征生成"><a href="#多项式特征生成" class="headerlink" title="多项式特征生成"></a>多项式特征生成</h3><p>&emsp;&emsp;很多情况下，考虑输入数据中的非线性特征来增加模型的复杂性是非常有效的。一个简单常用的方法就是使用多项式特征，它能捕捉到特征中高阶和相互作用的项。<code>PolynomialFeatures</code>类可以实现该功能：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly = PolynomialFeatures(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly.fit_transform(X)</span><br><span class="line">array([[  <span class="number">1.</span>,   <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">1.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">2.</span>,   <span class="number">3.</span>,   <span class="number">4.</span>,   <span class="number">6.</span>,   <span class="number">9.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">4.</span>,   <span class="number">5.</span>,  <span class="number">16.</span>,  <span class="number">20.</span>,  <span class="number">25.</span>]])</span><br></pre></td></tr></table></figure>
<p>特征向量<code>X</code>从<code>(X1, X2)</code>被转换成<code>(1, X1, X2, X1^2, X1*X2, X2^2)</code>。<br>&emsp;&emsp;在一些情况下，我们只需要特征中的相互作用项(<code>interaction terms</code>)，它可以通过传入参数<code>interaction_only=True</code>获得：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly = PolynomialFeatures(degree=<span class="number">3</span>, interaction_only=<span class="keyword">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>poly.fit_transform(X)</span><br><span class="line">array([[   <span class="number">1.</span>,    <span class="number">0.</span>,    <span class="number">1.</span>,    <span class="number">2.</span>,    <span class="number">0.</span>,    <span class="number">0.</span>,    <span class="number">2.</span>,    <span class="number">0.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">3.</span>,    <span class="number">4.</span>,    <span class="number">5.</span>,   <span class="number">12.</span>,   <span class="number">15.</span>,   <span class="number">20.</span>,   <span class="number">60.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">6.</span>,    <span class="number">7.</span>,    <span class="number">8.</span>,   <span class="number">42.</span>,   <span class="number">48.</span>,   <span class="number">56.</span>,  <span class="number">336.</span>]])</span><br></pre></td></tr></table></figure>
<p>特征向量<code>X</code>从<code>(X1, X2, X3)</code>被转换成<code>(1, X1, X2, X3, X1*X2, X1*X3, X2*X3, X1*X2*X3)</code>。</p>
<hr>
<h3 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h3><p>&emsp;&emsp;<code>One-Hot</code>编码又称为<code>一位有效编码</code>，主要是采用位状态寄存器来对个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。<br>&emsp;&emsp;在实际的机器学习任务中，特征有时候并不总是连续值，有可能是一些分类值，例如性别可分为<code>male</code>和<code>female</code>。对于这样的特征，通常需要对其进行特征数字化：</p>
<ul>
<li>性别：<code>[male, female]</code></li>
<li>地区：<code>[Europe, US, Asia]</code></li>
<li>浏览器：<code>[Firefox, Chrome, Safari, Internet Explorer]</code></li>
</ul>
<p>对于某一个样本，如<code>[male, US, Internet Explorer]</code>，我们需要将这个分类值的特征数字化，最直接的方法就是采用序列化的方式，即<code>[0, 1, 3]</code>。但是，这样的特征处理并不能直接放入机器学习算法中。<br>&emsp;&emsp;对于上述问题，<code>性别</code>属性是二维的，<code>地区</code>属性是三维的，而<code>浏览器</code>属性则是四维的。我们可以采用<code>One-Hot</code>编码的方式对上述的样本<code>[male, US, Internet Explorer]</code>进行编码，例如<code>male</code>对应<code>[1, 0]</code>，<code>US</code>对应<code>[0, 1, 0]</code>，<code>Internet Explorer</code>对应<code>[0, 0, 0, 1]</code>，则完整的特征数字化的结果为<code>[1, 0, 0, 1, 0, 0, 0, 0, 1]</code>。这样导致的一个结果就是数据会变得非常得稀疏。<br>&emsp;&emsp;可以这样理解：对于每一个特征，如果它有<code>m</code>个可能值，那么经过独热编码后，就变成了<code>m</code>个二元特征，并且这些特征互斥，每次只有一个激活，因此数据会变成稀疏的。这样做的好处主要有：解决了分类器不好处理属性数据的问题；一定程度上也起到了扩充特征的作用。<br>&emsp;&emsp;实际的<code>Python</code>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line">​</span><br><span class="line">enc = preprocessing.OneHotEncoder()</span><br><span class="line">enc.fit([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]])</span><br><span class="line">array = enc.transform([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>]]).toarray()</span><br><span class="line">print(array)</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure>
<p>我们将矩阵排起来看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">0</span> <span class="number">0</span> <span class="number">3</span> ];</span><br><span class="line"> [ <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> ];</span><br><span class="line"> [ <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> ];</span><br><span class="line"> [ <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> ]]</span><br></pre></td></tr></table></figure>
<p>该矩阵的每一列代表一个特征：</p>
<ul>
<li>第一列只有<code>0</code>或<code>1</code>出现，共有两种情况，所以<code>one-hot</code>编码前两维代表第一个特征，也恰好说明了是性别的分类。</li>
<li>第二列有<code>0</code>、<code>1</code>和<code>2</code>出现，共有三种情况，所以<code>one-hot</code>编码中间三维代表第二个特征，恰好证明了地区所对应的特征。</li>
<li>第三列有<code>0</code>、<code>1</code>、<code>2</code>和<code>3</code>出现，共有四种情况，所以<code>one-hot</code>编码最后四维代表第三个特征，也是最后一个特征，证明了浏览器的对应的特征。</li>
</ul>
<p>这里也很好地解释了<code>一定程度上也起到了扩充特征的作用</code>这句话，其实就是将所有的特征都融入到一个向量里面构成<code>one-hot</code>意义下的特征，一下子变成了<code>9</code>维的向量。特征列如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[male, female, Europe, US, Asia, Firefox, Chrome, Safari, Internet Explorer]]</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/机器学习/K近邻算法sklearn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/机器学习/K近邻算法sklearn/" itemprop="url">K近邻算法sklearn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T11:28:15+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>sklearn.neighbors</code>模块实现了<code>k</code>近邻算法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>neighbors.NearestNeighbors([n_neighbors, ...])</code></td>
<td>Unsupervised learner for implementing neighbor searches</td>
</tr>
<tr>
<td><code>neighbors.KNeighborsClassifier([...])</code></td>
<td>Classifier implementing the <code>k-nearest</code> neighbors vote</td>
</tr>
<tr>
<td><code>neighbors.RadiusNeighborsClassifier([...])</code></td>
<td>Classifier implementing a vote among neighbors within a given radius</td>
</tr>
<tr>
<td><code>neighbors.KNeighborsRegressor([n_neighbors, ...])</code></td>
<td>Regression based on <code>k-nearest</code> neighbors</td>
</tr>
<tr>
<td><code>neighbors.RadiusNeighborsRegressor([radius, ...])</code></td>
<td>Regression based on neighbors within a fixed <code>radius</code></td>
</tr>
<tr>
<td><code>neighbors.NearestCentroid([metric, ...])</code></td>
<td>Nearest centroid classifier</td>
</tr>
<tr>
<td><code>neighbors.BallTree</code></td>
<td><code>BallTree</code> for fast generalized <code>N-point</code> problems</td>
</tr>
<tr>
<td><code>neighbors.KDTree</code></td>
<td><code>KDTree</code> for fast generalized <code>N-point</code> problems</td>
</tr>
<tr>
<td><code>neighbors.LSHForest([n_estimators, radius, ...])</code></td>
<td>Performs approximate nearest neighbor search using <code>LSH</code> forest</td>
</tr>
<tr>
<td><code>neighbors.DistanceMetric</code></td>
<td>DistanceMetric class</td>
</tr>
<tr>
<td><code>neighbors.KernelDensity([bandwidth, ...])</code></td>
<td><code>Kernel Density Estimation</code></td>
</tr>
<tr>
<td><code>neighbors.kneighbors_graph(X, n_neighbors[, ...])</code></td>
<td>Computes the (weighted) graph of <code>k-Neighbors</code> for points in <code>X</code></td>
</tr>
<tr>
<td><code>neighbors.radius_neighbors_graph(X, radius)</code></td>
<td>Computes the (weighted) graph of <code>Neighbors</code> for points in <code>X</code></td>
</tr>
</tbody>
</table>
</div>
<p>使用<code>sklearn.neighbors.KNeighborsClassifier</code>就可以实现k近邻算法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">neighbors</span>.<span class="title">KNeighborsClassifier</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    n_neighbors=<span class="number">5</span>, weights=<span class="string">"uniform"</span>, algorithm=<span class="string">"auto"</span>, leaf_size=<span class="number">30</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    p=<span class="number">2</span>, metric=<span class="string">"minkowski"</span>, metric_params=None, n_jobs=<span class="number">1</span>, **kwargs)</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>n_neighbors</code>：默认为<code>5</code>，就是<code>kNN</code>的<code>k</code>的值，选取最近的k个点。</li>
<li><code>weights</code>：默认是<code>uniform</code>，参数可以是<code>uniform</code>、<code>distance</code>，也可以是用户自己定义的函数。<code>uniform</code>是均等的权重，就说所有的邻近点的权重都是相等的；<code>distance</code>是不均等的权重，距离近的点比距离远的点的影响大。如果是用户自定义的函数，则接收距离的数组，返回一组维数相同的权重。</li>
<li><code>algorithm</code>：快速<code>k</code>近邻搜索算法，默认参数为<code>auto</code>，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法，例如<code>ball_tree</code>、<code>kd_tree</code>、<code>brute</code>：<code>brute</code>是蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时；对于<code>kd_tree</code>，构造<code>kd</code>树存储数据以便对其进行快速检索的树形数据结构，<code>kd</code>树也就是数据结构中的二叉树，以中值切分构造的树，每个结点是一个超矩形，在维数小于<code>20</code>时效率高；<code>ball_tree</code>是为了克服<code>kd</code>树高维失效而发明的，其构造过程是以质心<code>C</code>和半径<code>r</code>分割样本空间，每个节点是一个超球体。</li>
<li><code>leaf_size</code>：默认是<code>30</code>，这个是构造的<code>kd</code>树和<code>ball</code>树的大小。这个值的设置会影响树构建的速度和搜索速度，同样也影响着存储树所需的内存大小。需要根据问题的性质选择最优的大小。</li>
<li><code>metric</code>：用于距离度量，默认度量是<code>minkowski</code>，也就是<code>p = 2</code>的欧氏距离(欧几里德度量)。</li>
<li><code>p</code>：距离度量公式。可以使用欧氏距离公式进行距离度量，除此之外还有其他的度量方法，例如曼哈顿距离。这个参数默认为<code>2</code>，也就是默认使用欧式距离公式进行距离度量。也可以设置为<code>1</code>，使用曼哈顿距离公式进行距离度量。</li>
<li><code>metric_params</code>：距离公式的其他关键参数，这个可以不管，使用默认的<code>None</code>即可。</li>
<li><code>n_jobs</code>：并行处理设置。默认为<code>1</code>，临近点搜索并行工作数。如果为<code>-1</code>，那么<code>CPU</code>的所有<code>cores</code>都用于并行工作。</li>
</ul>
<p>&emsp;&emsp;<code>KNeighborsClassifier</code>提供了一些方法供我们使用：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>fit(X, y)</code></td>
<td>Fit the model using <code>X</code> as training data and <code>y</code> as target values</td>
</tr>
<tr>
<td><code>get_params([deep])</code></td>
<td>Get parameters for this estimator</td>
</tr>
<tr>
<td><code>kneighbors([X, n_neighbors, return_distance])</code></td>
<td>Finds the <code>K-neighbors</code> of a point</td>
</tr>
<tr>
<td><code>kneighbors_graph([X, n_neighbors, mode])</code></td>
<td>Computes the (weighted) graph of <code>k-Neighbors</code> for points in <code>X</code></td>
</tr>
<tr>
<td><code>predict(X)</code></td>
<td>Predict the class labels for the provided data</td>
</tr>
<tr>
<td><code>predict_proba(X)</code></td>
<td>Return probability estimates for the test data <code>X</code></td>
</tr>
<tr>
<td><code>score(X, y[, sample_weight])</code></td>
<td>Returns the mean accuracy on the given test data and labels</td>
</tr>
<tr>
<td><code>set_params(**params)</code></td>
<td>Set the parameters of this estimator</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;代码一如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">​</span><br><span class="line">knn = neighbors.KNeighborsClassifier()</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">print(iris)</span><br><span class="line">knn.fit(iris.data, iris.target)</span><br><span class="line">predictedLabel = knn.predict([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>]])</span><br><span class="line">print(predictedLabel)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;不使用<code>sklearn</code>的<code>KNN</code>算法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataset</span><span class="params">(filename, split, trainingSet=[], testSet=[])</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'rt'</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">        lines = csv.reader(csvfile)</span><br><span class="line">        dataset = list(lines)</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(len(dataset) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">                dataset[x][y] = float(dataset[x][y])</span><br><span class="line">            <span class="keyword">if</span> random.random() &lt; split:</span><br><span class="line">                trainingSet.append(dataset[x])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                testSet.append(dataset[x])</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclideanDistance</span><span class="params">(instance1, instance2, length)</span>:</span></span><br><span class="line">    distance = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(length):</span><br><span class="line">        distance += pow((instance1[x] - instance2[x]), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> math.sqrt(distance)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNeighbors</span><span class="params">(trainingSet, testInstance, k)</span>:</span></span><br><span class="line">    distances = []</span><br><span class="line">    length = len(testInstance) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len(trainingSet)):</span><br><span class="line">        dist = euclideanDistance(testInstance, trainingSet[x], length)</span><br><span class="line">        distances.append((trainingSet[x], dist))</span><br><span class="line">    distances.sort(key=operator.itemgetter(<span class="number">1</span>))</span><br><span class="line">    neighbors = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(k):</span><br><span class="line">        neighbors.append(distances[x][<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> neighbors</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getResponse</span><span class="params">(neighbors)</span>:</span></span><br><span class="line">    classVotes = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len(neighbors)):</span><br><span class="line">        response = neighbors[x][<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> response <span class="keyword">in</span> classVotes:</span><br><span class="line">            classVotes[response] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            classVotes[response] = <span class="number">1</span></span><br><span class="line">    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedVotes[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAccuracy</span><span class="params">(testSet, predictions)</span>:</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len(testSet)):</span><br><span class="line">        <span class="keyword">if</span> testSet[x][<span class="number">-1</span>] == predictions[x]:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> (correct / float(len(testSet))) * <span class="number">100.0</span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    trainingSet = []</span><br><span class="line">    testSet = []</span><br><span class="line">    split = <span class="number">0.67</span></span><br><span class="line">    loadDataset(<span class="string">r'irisdata.txt'</span>, split, trainingSet, testSet)</span><br><span class="line">    print(<span class="string">'Train set: '</span> + repr(len(trainingSet)))</span><br><span class="line">    print(<span class="string">'Test set: '</span> + repr(len(testSet)))</span><br><span class="line">    predictions = []</span><br><span class="line">    k = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len(testSet)):</span><br><span class="line">        neighbors = getNeighbors(trainingSet, testSet[x], k)</span><br><span class="line">        result = getResponse(neighbors)</span><br><span class="line">        predictions.append(result)</span><br><span class="line">        print(<span class="string">'&gt;predicted='</span> + repr(result) + <span class="string">', actual='</span> + repr(testSet[x][<span class="number">-1</span>]))</span><br><span class="line">    print(<span class="string">'predictions: '</span> + repr(predictions))</span><br><span class="line">    accuracy = getAccuracy(testSet, predictions)</span><br><span class="line">    print(<span class="string">'Accuracy: '</span> + repr(accuracy) + <span class="string">'%'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<hr>
<p>&emsp;&emsp;本次测试就使用<code>Python</code>自带的<code>iris</code>数据集，这个数据集里面有<code>150</code>个实例，每个实例里有如下<code>4</code>个特征值如下：萼片长度(<code>sepal length</code>)、萼片宽度(<code>sepal width</code>)、花盘长度(<code>petal length</code>)、花盘宽度(<code>petal width</code>)。类别(<code>label</code>)有如下三种：<code>Iris setosa</code>、<code>Iris versicolor</code>和<code>Iris virginica</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors, metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">​</span><br><span class="line">knn = neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>)  <span class="comment"># 实例化KNN对象，选择K为5</span></span><br><span class="line">iris = load_iris()  <span class="comment"># 加载iris数据集</span></span><br><span class="line">print(iris)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 对数据集进行切割分类，分别为训练数据、测试数据、训练标记、测试标记，比例是“4:1”。</span></span><br><span class="line"><span class="comment"># random_state设置为零可以保证每次的随机数是一样的。如果是1，每次结果都不一样</span></span><br><span class="line">train_data, test_data, train_target, test_target = \</span><br><span class="line">    train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line">knn.fit(train_data, train_target)  <span class="comment"># 建立模型</span></span><br><span class="line">print(knn)</span><br><span class="line">print(knn.classes_)  <span class="comment"># 打印种类</span></span><br><span class="line">print(iris.target_names)  <span class="comment"># 打印三类花的名字</span></span><br><span class="line">​</span><br><span class="line">test_res = knn.predict(test_data)  <span class="comment"># 开始预测</span></span><br><span class="line"><span class="comment"># 打印准确的标记和预测的标记</span></span><br><span class="line">print(test_target)</span><br><span class="line">print(test_res)</span><br><span class="line">print(metrics.accuracy_score(test_res, test_target))  <span class="comment"># 打印预测准确率</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/12/机器学习/AdaBoost之sklearn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/12/机器学习/AdaBoost之sklearn/" itemprop="url">AdaBoost之sklearn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-12T09:55:30+08:00">
                2019-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;<code>sklearn.ensemble</code>模块提供了很多集成方法，例如<code>AdaBoost</code>、<code>Bagging</code>、随机森林等：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ensemble.AdaBoostClassifier([...])</code></td>
<td>An <code>AdaBoost</code> classifier</td>
</tr>
<tr>
<td><code>ensemble.AdaBoostRegressor([base_estimator, ...])</code></td>
<td>An <code>AdaBoost</code> regressor</td>
</tr>
<tr>
<td><code>ensemble.BaggingClassifier([base_estimator, ...])</code></td>
<td>A <code>Bagging</code> classifier</td>
</tr>
<tr>
<td><code>ensemble.BaggingRegressor([base_estimator, ...])</code></td>
<td>A <code>Bagging</code> regressor</td>
</tr>
<tr>
<td><code>ensemble.ExtraTreesClassifier([...])</code></td>
<td>An <code>extra-trees</code> classifier</td>
</tr>
<tr>
<td><code>ensemble.ExtraTreesRegressor([n_estimators, ...])</code></td>
<td>An <code>extra-trees</code> regressor</td>
</tr>
<tr>
<td><code>ensemble.GradientBoostingClassifier([loss, ...])</code></td>
<td><code>Gradient Boosting</code> for classification</td>
</tr>
<tr>
<td><code>ensemble.GradientBoostingRegressor([loss, ....])</code></td>
<td><code>Gradient Boosting</code> for regression</td>
</tr>
<tr>
<td><code>ensemble.IsolationForest([n_estimators, ...])</code></td>
<td><code>Isolation Forest Algorithm</code></td>
</tr>
<tr>
<td><code>ensemble.RandomForestClassifier([...])</code></td>
<td>A random forest classifier</td>
</tr>
<tr>
<td><code>ensemble.RandomForestRegressor([...])</code></td>
<td>A random forest regressor</td>
</tr>
<tr>
<td><code>ensemble.RandomTreesEmbedding([...])</code></td>
<td>An ensemble of totally random trees</td>
</tr>
<tr>
<td><code>ensemble.VotingClassifier(estimators[, ...])</code></td>
<td><code>Soft Voting/Majority Rule</code> classifier for unfitted estimators</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;<code>sklearn.ensemble.AdaBoostClassifier</code>函数原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">ensemble</span>.<span class="title">AdaBoostClassifier</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    base_estimator=None, n_estimators=<span class="number">50</span>, learning_rate=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    algorithm=<span class="string">'SAMME.R'</span>, random_state=None)</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>base_estimator</code>：可选参数，默认为<code>DecisionTreeClassifier</code>。理论上可以选择任何一个分类或者回归学习器，不过需要支持样本权重。我们常用的一般是<code>CART</code>决策树或者神经网络<code>MLP</code>。默认是决策树，即<code>AdaBoostClassifier</code>默认使用<code>CART</code>分类树<code>DecisionTreeClassifier</code>，而<code>AdaBoostRegressor</code>默认使用<code>CART</code>回归树<code>DecisionTreeRegressor</code>。</li>
<li><code>algorithm</code>：可选参数，默认为<code>SAMME.R</code>。<code>scikit-learn</code>实现了两种<code>Adaboost</code>分类算法，即<code>SAMME</code>和<code>SAMME.R</code>。两者的主要区别是弱学习器权重的度量，<code>SAMME</code>使用对样本集分类效果作为弱学习器权重，而<code>SAMME.R</code>使用了对样本集分类的预测概率大小来作为弱学习器权重。由于<code>SAMME.R</code>使用了概率度量的连续值，迭代一般比<code>SAMME</code>快，因此<code>AdaBoostClassifier</code>的默认算法<code>algorithm</code>的值也是<code>SAMME.R</code>。我们一般使用默认的<code>SAMME.R</code>就够了，但是要注意的是使用了<code>SAMME.R</code>，则弱分类学习器参数<code>base_estimator</code>必须限制使用支持概率预测的分类器。<code>SAMME</code>算法则没有这个限制。</li>
<li><code>n_estimators</code>：整数型，可选参数，默认为<code>50</code>。弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说<code>n_estimators</code>太小，容易欠拟合；<code>n_estimators</code>太大，又容易过拟合，一般使用默认值即可。在实际调参的过程中，我们常常将<code>n_estimators</code>和下面介绍的参数<code>learning_rate</code>一起考虑。</li>
<li><code>learning_rate</code>：浮点型，可选参数，默认为<code>1.0</code>。每个弱学习器的权重缩减系数，取值范围为<code>0</code>到<code>1</code>。对于同样的训练集拟合效果，较小的<code>learning_rate</code>意味着需要更多的弱学习器迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果，所以<code>n_estimators</code>和<code>learning_rate</code>这两个参数要一起调参。一般来说，可以从一个小的<code>learning_rate</code>开始调参。</li>
<li><code>random_state</code>：整数型，可选参数，默认为<code>None</code>。If <code>int</code>, <code>random_state</code> is the seed used by the random number generator; If <code>RandomState</code> instance, <code>random_state</code> is the random number generator; If <code>None</code>, the random number generator is the <code>RandomState</code> instance used by <code>np.random</code>.</li>
</ul>
<p>&emsp;&emsp;<code>AdaBoostClassifier</code>提供了如下方法：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>decision_function(X)</code></td>
<td>Compute the decision function of <code>X</code></td>
</tr>
<tr>
<td><code>fit(X, y[, sample_weight])</code></td>
<td>Build a boosted classifier from the training set <code>(X, y)</code></td>
</tr>
<tr>
<td><code>get_params([deep])</code></td>
<td>Get parameters for this estimator</td>
</tr>
<tr>
<td><code>predict(X)</code></td>
<td>Predict classes for <code>X</code></td>
</tr>
<tr>
<td><code>predict_log_proba(X)</code></td>
<td>Predict class <code>log-probabilities</code> for <code>X</code></td>
</tr>
<tr>
<td><code>predict_proba(X)</code></td>
<td>Predict class probabilities for <code>X</code></td>
</tr>
<tr>
<td><code>score(X, y[, sample_weight])</code></td>
<td>Returns the mean accuracy on the given test data and labels</td>
</tr>
<tr>
<td><code>set_params(**params)</code></td>
<td>Set the parameters of this estimator</td>
</tr>
<tr>
<td><code>staged_decision_function(X)</code></td>
<td>Compute decision function of <code>X</code> for each boosting iteration</td>
</tr>
<tr>
<td><code>staged_predict(X)</code></td>
<td>Return staged predictions for <code>X</code></td>
</tr>
<tr>
<td><code>staged_predict_proba(X)</code></td>
<td>Predict class probabilities for <code>X</code></td>
</tr>
<tr>
<td><code>staged_score(X, y[, sample_weight])</code></td>
<td>Return staged scores for <code>X, y</code></td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;预测病马死亡率的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    numFeat = len((open(fileName).readline().split(<span class="string">'\t'</span>)))</span><br><span class="line">    dataMat = []</span><br><span class="line">    labelMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = []</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeat - <span class="number">1</span>):</span><br><span class="line">            lineArr.append(float(curLine[i]))</span><br><span class="line">        dataMat.append(lineArr)</span><br><span class="line">        labelMat.append(float(curLine[<span class="number">-1</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat, labelMat</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataArr, classLabels = loadDataSet(<span class="string">'horseColicTraining2.txt'</span>)</span><br><span class="line">    testArr, testLabelArr = loadDataSet(<span class="string">'horseColicTest2.txt'</span>)</span><br><span class="line">    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=<span class="number">2</span>), algorithm=<span class="string">"SAMME"</span>, n_estimators=<span class="number">10</span>)</span><br><span class="line">    bdt.fit(dataArr, classLabels)</span><br><span class="line">    predictions = bdt.predict(dataArr)</span><br><span class="line">    errArr = np.mat(np.ones((len(dataArr), <span class="number">1</span>)))</span><br><span class="line">    print(<span class="string">'训练集的错误率: %.3f%%'</span> % float(errArr[predictions != classLabels].sum() / len(dataArr) * <span class="number">100</span>))</span><br><span class="line">    predictions = bdt.predict(testArr)</span><br><span class="line">    errArr = np.mat(np.ones((len(testArr), <span class="number">1</span>)))</span><br><span class="line">    print(<span class="string">'测试集的错误率: %.3f%%'</span> % float(errArr[predictions != testLabelArr].sum() / len(testArr) * <span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">训练集的错误率: <span class="number">16.054</span>%</span><br><span class="line">测试集的错误率: <span class="number">17.910</span>%</span><br></pre></td></tr></table></figure>
<p>我们使用<code>DecisionTreeClassifier</code>作为使用的弱分类器，使用<code>AdaBoost</code>算法训练分类器。可以看到训练集的错误率为<code>16.054%</code>，测试集的错误率为<code>17.910%</code>。注意，如果<code>n_enstimators</code>参数过大，会导致过拟合。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/11/数据结构和算法/归并排序/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/11/数据结构和算法/归并排序/" itemprop="url">归并排序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-11T20:41:19+08:00">
                2019-02-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;归并排序(<code>MERGE-SORT</code>)是建立在归并操作上的一种有效的排序算法，该算法是采用<code>分治法</code>(<code>Divide and Conquer</code>)的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列：即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为<code>二路归并</code>。<br>&emsp;&emsp;归并过程为：比较<code>a[i]</code>和<code>a[j]</code>的大小，若<code>a[i] ≤ a[j]</code>，则将第一个有序表中的元素<code>a[i]</code>复制到<code>r[k]</code>中，并令<code>i</code>和<code>k</code>分别加上<code>1</code>；否则将第二个有序表中的元素<code>a[j]</code>复制到<code>r[k]</code>中，并令<code>j</code>和<code>k</code>分别加上<code>1</code>，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复制到<code>r</code>中从下标<code>k</code>到下标<code>t</code>的单元。归并排序的算法我们通常用递归实现，先把待排序区间<code>[s, t]</code>以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间<code>[s, t]</code>。</p>
<p><img src="/2019/02/11/数据结构和算法/归并排序/1.png" height="230" width="367"></p>
<h3 id="归并操作"><a href="#归并操作" class="headerlink" title="归并操作"></a>归并操作</h3><p>&emsp;&emsp;归并操作指的是将两个顺序序列合并成一个顺序序列的方法。如设有数列<code>{6, 202, 100, 301, 38, 8, 1}</code>：</p>
<ol>
<li>初始状态：<code>{6, 202, 100, 301, 38, 8, 1}</code>。</li>
<li>第一次归并后：<code>{6, 202}</code>，<code>{100, 301}</code>，<code>{8, 38}</code>，<code>{1}</code>，比较次数为<code>3</code>。</li>
<li>第二次归并后：<code>{6, 100, 202, 301}</code>，<code>{1, 8, 38}</code>，比较次数为<code>4</code>。</li>
<li>第三次归并后：<code>{1, 6, 8, 38, 100, 202, 301}</code>，比较次数为<code>4</code>。</li>
</ol>
<p>总的比较次数为<code>3 + 4 + 4 = 11</code>，逆序数为<code>14</code>。</p>
<h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h3><p>&emsp;&emsp;归并操作的工作原理如下：</p>
<ol>
<li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列。</li>
<li>设定两个指针，最初位置分别为两个已经排序序列的起始位置。</li>
<li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置。</li>
<li>重复步骤<code>3</code>直到某一指针超出序列尾。将另一序列剩下的所有元素直接复制到合并序列尾。</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Merge</span> <span class="params">( <span class="keyword">int</span> sourceArr[], <span class="keyword">int</span> tempArr[], <span class="keyword">int</span> startIndex, <span class="keyword">int</span> midIndex, <span class="keyword">int</span> endIndex )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = startIndex, j = midIndex + <span class="number">1</span>, k = startIndex;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( i != midIndex + <span class="number">1</span> &amp;&amp; j != endIndex + <span class="number">1</span> ) &#123;</span><br><span class="line">        <span class="keyword">if</span> ( sourceArr[i] &gt;= sourceArr[j] ) &#123;</span><br><span class="line">            tempArr[k++] = sourceArr[j++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            tempArr[k++] = sourceArr[i++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( i != midIndex + <span class="number">1</span> ) &#123;</span><br><span class="line">        tempArr[k++] = sourceArr[i++];</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( j != endIndex + <span class="number">1</span> ) &#123;</span><br><span class="line">        tempArr[k++] = sourceArr[j++];</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( i = startIndex; i &lt;= endIndex; i++ ) &#123;</span><br><span class="line">        sourceArr[i] = tempArr[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="comment">/* 内部使用递归 */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">MergeSort</span> <span class="params">( <span class="keyword">int</span> sourceArr[], <span class="keyword">int</span> tempArr[], <span class="keyword">int</span> startIndex, <span class="keyword">int</span> endIndex )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> midIndex;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( startIndex &lt; endIndex ) &#123;</span><br><span class="line">        midIndex = ( startIndex + endIndex ) / <span class="number">2</span>;</span><br><span class="line">        MergeSort ( sourceArr, tempArr, startIndex, midIndex );</span><br><span class="line">        MergeSort ( sourceArr, tempArr, midIndex + <span class="number">1</span>, endIndex );</span><br><span class="line">        Merge ( sourceArr, tempArr, startIndex, midIndex, endIndex );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[] )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a[<span class="number">8</span>] = &#123;<span class="number">50</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">70</span>, <span class="number">40</span>, <span class="number">80</span>, <span class="number">60</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> i, b[<span class="number">8</span>];</span><br><span class="line">    MergeSort ( a, b, <span class="number">0</span>, <span class="number">7</span> );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i++ ) &#123;</span><br><span class="line">        <span class="built_in">printf</span> ( <span class="string">"%d "</span>, a[i] );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="built_in">printf</span> ( <span class="string">"\n"</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/11/数据结构和算法/八数码问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/11/数据结构和算法/八数码问题/" itemprop="url">八数码问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-11T20:15:47+08:00">
                2019-02-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;编号为<code>1</code>至<code>8</code>的<code>8</code>个正方形滑块被摆成<code>3</code>行<code>3</code>列(有一个格子空留)。每次可以把与空格相邻的滑块(有公共边才算相邻)移到空格中，而它原来的位置就成为了新的空格。给定初始局面和目标局面(用<code>0</code>表示空格)，你的任务是计算出最少的移动步数。如果无法达到目标局面，则输出<code>-1</code>。</p>
<p><img src="/2019/02/11/数据结构和算法/八数码问题/1.png" height="194" width="364"></p>
<p>输入：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span> <span class="number">6</span> <span class="number">4</span> <span class="number">1</span> <span class="number">3</span> <span class="number">7</span> <span class="number">0</span> <span class="number">5</span> <span class="number">8</span></span><br><span class="line"><span class="number">8</span> <span class="number">1</span> <span class="number">5</span> <span class="number">7</span> <span class="number">3</span> <span class="number">6</span> <span class="number">4</span> <span class="number">0</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>输出<code>31</code>。<br>&emsp;&emsp;可以把八数码问题归结为图上的最短路径问题，每个状态就是<code>9</code>个各自中的滑块编号(从上到下、从左到右把它们放到一个包含<code>9</code>个元素的数组中)。<br>&emsp;&emsp;代码示例<code>1</code>如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _CRT_SECURE_NO_DEPRECATE</span></span><br><span class="line">​</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXSIZE 1000000</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> State[<span class="number">9</span>]; <span class="comment">/* 定义“状态”类型 */</span></span><br><span class="line">State st[MAXSIZE]; <span class="comment">/* 状态数组，所有的状态都保存在这里 */</span></span><br><span class="line">State stEnd;</span><br><span class="line"><span class="keyword">int</span> iDist[MAXSIZE]; <span class="comment">/* 距离数组 */</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">int</span> go[][<span class="number">2</span>] = &#123;</span><br><span class="line">    &#123;<span class="number">-1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">-1</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">1</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">int</span> iVis[<span class="number">362880</span>], fact[<span class="number">9</span>];</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; <span class="comment">/* 初始化查找表 */</span></span><br><span class="line">    fact[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">1</span> ; i &lt; <span class="number">9</span>; i++ ) &#123;</span><br><span class="line">        fact[i] = fact[i - <span class="number">1</span>] * i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isInsert</span> <span class="params">( <span class="keyword">int</span> n )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> iCode = <span class="number">0</span>; <span class="comment">/* 把st[s]映射到整数iCode */</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">9</span> ; i++ ) &#123;</span><br><span class="line">        <span class="keyword">int</span> iCnt = <span class="number">0</span>;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ( <span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; <span class="number">9</span>; j++ ) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( st[n][j] &lt; st[n][i] ) &#123; <span class="comment">/* 统计每个排列中，后面小于前面排列的数字个数 */</span></span><br><span class="line">                iCnt++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iCode += fact[<span class="number">8</span> - i] * iCnt;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( iVis[iCode] ) &#123; <span class="comment">/* 如果已经访问过 */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        iVis[iCode] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">/* 同时完成赋值和返回值操作 */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">bfs</span><span class="params">()</span> </span>&#123; <span class="comment">/* BFS，返回目标状态在st数组 */</span></span><br><span class="line">    <span class="keyword">int</span> iRear = <span class="number">2</span>, iFront = <span class="number">1</span>; <span class="comment">/* 不使用下标0，因为0被看做“不存在” */</span></span><br><span class="line">    init();</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( iFront &lt; iRear ) &#123;</span><br><span class="line">        State &amp;state = st[iFront]; <span class="comment">/* 用“引用”简化代码 */</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( <span class="built_in">memcmp</span> ( stEnd, state, <span class="keyword">sizeof</span> ( state ) ) == <span class="number">0</span> ) &#123; <span class="comment">/* 找到目标代码，成功返回 */</span></span><br><span class="line">            <span class="keyword">return</span> iFront;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">int</span> iZ, iX, iY;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ( iZ = <span class="number">0</span> ; iZ &lt; <span class="number">9</span>; iZ++ ) &#123; <span class="comment">/* 确定0所在的位置 */</span></span><br><span class="line">            <span class="keyword">if</span> ( !state[iZ] ) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iX = iZ / <span class="number">3</span>;</span><br><span class="line">        iY = iZ % <span class="number">3</span>; <span class="comment">/* 获取行列编号 */</span></span><br><span class="line">        <span class="comment">/* 生成下一步位置 */</span></span><br><span class="line">        <span class="keyword">int</span> iNewZ, iNewX, iNewY;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++ ) &#123;</span><br><span class="line">            iNewX = go[i][<span class="number">0</span>] + iX;</span><br><span class="line">            iNewY = go[i][<span class="number">1</span>] + iY;</span><br><span class="line">            iNewZ = iNewX * <span class="number">3</span> + iNewY; <span class="comment">/* 确定0的新位置 */</span></span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> ( iNewX &gt;= <span class="number">0</span> &amp;&amp; iNewX &lt; <span class="number">3</span> &amp;&amp; iNewY &gt;= <span class="number">0</span> &amp;&amp; iNewY &lt; <span class="number">3</span> ) &#123; <span class="comment">/* 如果移动合法 */</span></span><br><span class="line">                State &amp;newState = st[iRear];</span><br><span class="line">                <span class="built_in">memcpy</span> ( &amp;newState, &amp;state, <span class="keyword">sizeof</span> ( state ) ); <span class="comment">/* 拓展新结点 */</span></span><br><span class="line">                newState[iNewZ] = state[iZ];</span><br><span class="line">                newState[iZ] = state[iNewZ];</span><br><span class="line">                iDist[iRear] = iDist[iFront] + <span class="number">1</span>; <span class="comment">/* 更新新结点的距离值 */</span></span><br><span class="line">            &#125;</span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> ( isInsert ( iRear ) ) &#123; <span class="comment">/* 如果成功插入查找表，修改队尾指针 */</span></span><br><span class="line">                iRear++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iFront++; <span class="comment">/* 拓展完毕后再修改队首指针 */</span></span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">/* 失败 */</span></span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">9</span>; i++ ) &#123; <span class="comment">/* 起始状态 */</span></span><br><span class="line">        <span class="built_in">scanf</span> ( <span class="string">"%d"</span>, &amp;st[<span class="number">1</span>][i] );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> j = <span class="number">0</span> ; j &lt; <span class="number">9</span>; j++ ) &#123; <span class="comment">/* 目标状态 */</span></span><br><span class="line">        <span class="built_in">scanf</span> ( <span class="string">"%d"</span>, &amp;stEnd[j] );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    iDist[<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">/* 设置第一步移动的距离为0 */</span></span><br><span class="line">    <span class="built_in">memset</span> ( iVis, <span class="number">0</span>, <span class="keyword">sizeof</span> ( iVis ) ); <span class="comment">/* 初始化访问内存块 */</span></span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[] )</span> </span>&#123;</span><br><span class="line">    process();</span><br><span class="line">    <span class="keyword">int</span> iRes = bfs();</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( iRes &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">        <span class="built_in">printf</span> ( <span class="string">"%d\n"</span>, iDist[iRes] );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span> ( <span class="string">"-1\n"</span> );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    system ( <span class="string">"pause"</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;代码示例<code>2</code>如下，它采用的是哈希技术：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _CRT_SECURE_NO_DEPRECATE</span></span><br><span class="line">​</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAXSIZE = <span class="number">1000000</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> State[<span class="number">9</span>];</span><br><span class="line">State st[MAXSIZE], stEnd;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAXHASHSIZE = <span class="number">100003</span>;</span><br><span class="line"><span class="keyword">int</span> iHead[MAXHASHSIZE];</span><br><span class="line"><span class="keyword">int</span> iNext[MAXSIZE];</span><br><span class="line"><span class="keyword">int</span> iDist[MAXSIZE];</span><br><span class="line">​</span><br><span class="line"><span class="keyword">int</span> go[][<span class="number">2</span>] = &#123;</span><br><span class="line">    &#123;<span class="number">-1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">-1</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">1</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">hash</span> <span class="params">( State &amp;s )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> iSum = <span class="number">0</span>;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++ ) &#123;</span><br><span class="line">        iSum = <span class="number">10</span> * iSum + s[i]; <span class="comment">/* 把9个数字组成九位数 */</span></span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> iSum % MAXHASHSIZE; <span class="comment">/* 确保hash函数值不超过hash表的大小的非负整数 */</span></span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isInsert</span> <span class="params">( <span class="keyword">int</span> x )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h = hash ( st[x] );</span><br><span class="line">    <span class="keyword">int</span> u = iHead[h]; <span class="comment">/* 向获取每条链中的链首值 */</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( u ) &#123;</span><br><span class="line">        <span class="keyword">if</span> ( <span class="built_in">memcmp</span> ( st[u], st[x], <span class="keyword">sizeof</span> ( st[x] ) ) == <span class="number">0</span> ) &#123; <span class="comment">/* 找到了，插入失败 */</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        u = iNext[u]; <span class="comment">/* 顺着链表继续找 */</span></span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    iNext[x] = iHead[h]; <span class="comment">/* 插入到链表中 */</span></span><br><span class="line">    iHead[h] = x;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">bfs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> iFront = <span class="number">1</span>, iRear = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">memset</span> ( iHead, <span class="number">0</span>, <span class="keyword">sizeof</span> ( iHead ) );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> ( iFront &lt; iRear ) &#123;</span><br><span class="line">        State &amp;state = st[iFront];</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> ( <span class="built_in">memcmp</span> ( stEnd, state, <span class="keyword">sizeof</span> ( state ) ) == <span class="number">0</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> iFront;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">int</span> iX, iY, iZ;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ( iZ = <span class="number">0</span>; iZ &lt; <span class="number">9</span>; iZ++ ) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( !state[iZ] ) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iX = iZ / <span class="number">3</span>;</span><br><span class="line">        iY = iZ % <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">int</span> iNewZ, iNewX, iNewY;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++ ) &#123;</span><br><span class="line">            iNewX = go[i][<span class="number">0</span>] + iX;</span><br><span class="line">            iNewY = go[i][<span class="number">1</span>] + iY;</span><br><span class="line">            iNewZ = iNewX * <span class="number">3</span> + iNewY;</span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> ( iNewX &gt;= <span class="number">0</span> &amp;&amp; iNewX &lt; <span class="number">3</span> &amp;&amp; iNewY &gt;= <span class="number">0</span> &amp;&amp; iNewY &lt; <span class="number">3</span> ) &#123;</span><br><span class="line">                State &amp;newState = st[iRear];</span><br><span class="line">                <span class="built_in">memcpy</span> ( &amp;newState, &amp;state, <span class="keyword">sizeof</span> ( state ) );</span><br><span class="line">                newState[iNewZ] = state[iZ];</span><br><span class="line">                newState[iZ] = state[iNewZ];</span><br><span class="line">                iDist[iRear] = iDist[iFront] + <span class="number">1</span>;</span><br><span class="line">​</span><br><span class="line">                <span class="keyword">if</span> ( isInsert ( iRear ) ) &#123;</span><br><span class="line">                    iRear++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iFront++;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    iDist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++ ) &#123;</span><br><span class="line">        <span class="built_in">scanf</span> ( <span class="string">"%d"</span>, &amp;st[<span class="number">1</span>][i] );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">9</span>; j++ ) &#123;</span><br><span class="line">        <span class="built_in">scanf</span> ( <span class="string">"%d"</span>, &amp;stEnd[j] );</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">int</span> iRes = bfs();</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( iRes &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">        <span class="built_in">printf</span> ( <span class="string">"%d\n"</span>, iDist[iRes] );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span> ( <span class="string">"-1\n"</span> );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[] )</span> </span>&#123;</span><br><span class="line">    process();</span><br><span class="line">    system ( <span class="string">"pause"</span> );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;代码示例<code>3</code>如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _CRT_SECURE_NO_DEPRECATE</span></span><br><span class="line">​</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line">​</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXSIZE 1000000</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> State[<span class="number">9</span>];</span><br><span class="line">State st[MAXSIZE], stEnd;</span><br><span class="line"><span class="keyword">int</span> iDist[MAXSIZE];</span><br><span class="line">​</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; setState;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">int</span> go[][<span class="number">2</span>] = &#123;</span><br><span class="line">    &#123;<span class="number">-1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">-1</span>&#125;,</span><br><span class="line">    &#123;<span class="number">0</span>, <span class="number">1</span>&#125;,</span><br><span class="line">&#125;;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Cmp</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(<span class="keyword">int</span> iIndexA, <span class="keyword">int</span> iIndexB)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">memcmp</span>(&amp;st[iIndexA], &amp;st[iIndexB], <span class="keyword">sizeof</span>(st[iIndexB])) &lt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; Cmp;</span><br><span class="line">​</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>, Cmp&gt; setState2;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    setState2.clear();</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isInsert2</span><span class="params">(<span class="keyword">int</span> iIndex)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (setState2.count(iIndex)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        setState2.insert(iIndex);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    setState.clear();</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isInsert</span><span class="params">(<span class="keyword">int</span> iNum)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> iSum = <span class="number">0</span>;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++) &#123;</span><br><span class="line">        iSum = iSum * <span class="number">10</span> + st[iNum][i];</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (setState.count(iSum)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        setState.insert(iSum);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">bfs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> iFront = <span class="number">1</span>, iRear = <span class="number">2</span>;</span><br><span class="line">    init2();</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">while</span> (iFront &lt; iRear) &#123;</span><br><span class="line">        State &amp;state = st[iFront];</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">memcmp</span>(stEnd, state, <span class="keyword">sizeof</span>(state)) == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> iFront;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">int</span> iX, iY, iZ;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> (iZ = <span class="number">0</span>; iZ &lt; <span class="number">9</span>; iZ++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!state[iZ]) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iX = iZ / <span class="number">3</span>;</span><br><span class="line">        iY = iZ % <span class="number">3</span>;</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> iNewX = iX + go[i][<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">int</span> iNewY = iY + go[i][<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">int</span> iNewZ = iNewX * <span class="number">3</span> + iNewY;</span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> (iNewX &lt; <span class="number">3</span> &amp;&amp; iNewX &gt;= <span class="number">0</span> &amp;&amp; iNewY &lt; <span class="number">3</span> &amp;&amp; iNewY &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                State &amp;newState = st[iRear];</span><br><span class="line">                <span class="built_in">memcpy</span>(&amp;newState, &amp;state, <span class="keyword">sizeof</span>(state));</span><br><span class="line">                newState[iNewZ] = state[iZ];</span><br><span class="line">                newState[iZ] = state[iNewZ];</span><br><span class="line">                iDist[iRear] = iDist[iFront] + <span class="number">1</span>;</span><br><span class="line">​</span><br><span class="line">                <span class="keyword">if</span> (isInsert2(iRear)) &#123;</span><br><span class="line">                    iRear++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        iFront++;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    iDist[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++) &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;st[<span class="number">1</span>][i]);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">9</span>; j++) &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;stEnd[j]);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">int</span> iRes = bfs();</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (iRes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, iDist[iRes]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"-1\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    process();</span><br><span class="line">    system(<span class="string">"pause"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/24/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><span class="page-number current">25</span><a class="page-number" href="/page/26/">26</a><span class="space">&hellip;</span><a class="page-number" href="/page/96/">96</a><a class="extend next" rel="next" href="/page/26/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">955</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
