<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="&amp;emsp;&amp;emsp;Have you ever wondered how to add speech recognition to your Python project? If so, then keep reading! It’s easier than you might think.&amp;emsp;&amp;emsp;Far from a being a fad, the overwhelming">
<meta property="og:type" content="article">
<meta property="og:title" content="The Ultimate Guide To Speech Recognition With Python">
<meta property="og:url" content="http://fukangwei.gitee.io/2019/02/13/深度学习/The Ultimate Guide To Speech Recognition With Python/index.html">
<meta property="og:site_name" content="泥腿子出身">
<meta property="og:description" content="&amp;emsp;&amp;emsp;Have you ever wondered how to add speech recognition to your Python project? If so, then keep reading! It’s easier than you might think.&amp;emsp;&amp;emsp;Far from a being a fad, the overwhelming">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-03-13T07:34:03.396Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Ultimate Guide To Speech Recognition With Python">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;Have you ever wondered how to add speech recognition to your Python project? If so, then keep reading! It’s easier than you might think.&amp;emsp;&amp;emsp;Far from a being a fad, the overwhelming">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/2019/02/13/深度学习/The Ultimate Guide To Speech Recognition With Python/">





  <title>The Ultimate Guide To Speech Recognition With Python | 泥腿子出身</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泥腿子出身</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/02/13/深度学习/The Ultimate Guide To Speech Recognition With Python/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">The Ultimate Guide To Speech Recognition With Python</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T16:11:08+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>&emsp;&emsp;Have you ever wondered how to add speech recognition to your <code>Python</code> project? If so, then keep reading! It’s easier than you might think.<br>&emsp;&emsp;Far from a being a fad, the overwhelming success of <code>speech-enabled</code> products like <code>Amazon Alexa</code> has proven that some degree of speech support will be an essential aspect of household tech for the foreseeable future. If you think about it, the reasons why are pretty obvious. Incorporating speech recognition into your <code>Python</code> application offers a level of interactivity and accessibility that few technologies can match.<br>&emsp;&emsp;The accessibility improvements alone are worth considering. Speech recognition allows the elderly and the physically and visually impaired to interact with <code>state-of-the-art</code> products and services quickly and naturally.<br>&emsp;&emsp;Best of all, including speech recognition in a <code>Python</code> project is really simple. In this guide, you’ll find out how. You’ll learn:</p>
<ul>
<li>How speech recognition works?</li>
<li>What packages are available on <code>PyPI</code>?</li>
<li>How to install and use the <code>SpeechRecognition</code> package - a <code>full-featured</code> and <code>easy-to-use</code> <code>Python</code> speech recognition library.</li>
</ul>
<p>&emsp;&emsp;In the end, you’ll apply what you’ve learned to a simple <code>Guess the Word</code> game and see how it all comes together.</p>
<h3 id="How-Speech-Recognition-Works-An-Overview"><a href="#How-Speech-Recognition-Works-An-Overview" class="headerlink" title="How Speech Recognition Works - An Overview"></a>How Speech Recognition Works - An Overview</h3><p>&emsp;&emsp;Before we get to the <code>nitty-gritty</code> of doing speech recognition in <code>Python</code>, let’s take a moment to talk about how speech recognition works. A full discussion would fill a book, so I won’t bore you with all of the technical details here. In fact, this section is not <code>pre-requisite</code> to the rest of the tutorial. If you’d like to get straight to the point, then feel free to skip ahead.<br>&emsp;&emsp;Speech recognition has its roots in research done at <code>Bell Labs</code> in the early <code>1950s</code>. Early systems were limited to a single speaker and had limited vocabularies of about a dozen words. Modern speech recognition systems have come a long way since their ancient counterparts. They can recognize speech from multiple speakers and have enormous vocabularies in numerous languages.<br>&emsp;&emsp;The first component of speech recognition is, of course, speech. Speech must be converted from physical sound to an electrical signal with a microphone, and then to digital data with an <code>analog-to-digital</code> converter. Once digitized, several models can be used to transcribe the audio to text.<br>&emsp;&emsp;Most modern speech recognition systems rely on what is known as a <code>Hidden Markov Model</code> (<code>HMM</code>). This approach works on the assumption that a speech signal, when viewed on a short enough timescale (say, ten milliseconds), can be reasonably approximated as a stationary process - that is, a process in which statistical properties do not change over time.<br>&emsp;&emsp;In a typical <code>HMM</code>, the speech signal is divided into <code>10-millisecond</code> fragments. The power spectrum of each fragment, which is essentially a plot of the signal’s power as a function of frequency, is mapped to a vector of real numbers known as cepstral coefficients. The dimension of this vector is usually small - sometimes as low as <code>10</code>, although more accurate systems may have dimension <code>32</code> or more. The final output of the <code>HMM</code> is a sequence of these vectors.<br>&emsp;&emsp;To decode the speech into text, groups of vectors are matched to one or more phonemes - a fundamental unit of speech. This calculation requires training, since the sound of a phoneme varies from speaker to speaker, and even varies from one utterance to another by the same speaker. A special algorithm is then applied to determine the most likely word (or words) that produce the given sequence of phonemes.<br>&emsp;&emsp;One can imagine that this whole process may be computationally expensive. In many modern speech recognition systems, neural networks are used to simplify the speech signal using techniques for feature transformation and dimensionality reduction before <code>HMM</code> recognition. <code>Voice activity detectors</code> (<code>VADs</code>) are also used to reduce an audio signal to only the portions that are likely to contain speech. This prevents the recognizer from wasting time analyzing unnecessary parts of the signal.<br>&emsp;&emsp;Fortunately, as a <code>Python</code> programmer, you don’t have to worry about any of this. A number of speech recognition services are available for use online through an <code>API</code>, and many of these services offer <code>Python SDKs</code>.</p>
<h3 id="Picking-a-Python-Speech-Recognition-Package"><a href="#Picking-a-Python-Speech-Recognition-Package" class="headerlink" title="Picking a Python Speech Recognition Package"></a>Picking a Python Speech Recognition Package</h3><p>&emsp;&emsp;A handful of packages for speech recognition exist on <code>PyPI</code>. A few of them include: <code>apiai</code>, <code>assemblyai</code>, <code>google-cloud-speech</code>, <code>pocketsphinx</code>, <code>SpeechRecognition</code>, <code>watson-developer-cloud</code>, <code>wit</code>.<br>&emsp;&emsp;Some of these packages - such as <code>wit</code> and <code>apiai</code> - offer <code>built-in</code> features, like natural language processing for identifying a speaker’s intent, which go beyond basic speech recognition. Others, like <code>google-cloud-speech</code>, focus solely on <code>speech-to-text</code> conversion.<br>&emsp;&emsp;There is one package that stands out in terms of <code>ease-of-use</code>: <code>SpeechRecognition</code>. Recognizing speech requires audio input, and <code>SpeechRecognition</code> makes retrieving this input really easy. Instead of having to build scripts for accessing microphones and processing audio files from scratch, <code>SpeechRecognition</code> will have you up and running in just a few minutes.<br>&emsp;&emsp;The <code>SpeechRecognition</code> library acts as a wrapper for several popular speech <code>APIs</code> and is thus extremely flexible. One of these - the <code>Google Web Speech API</code> - supports a default <code>API</code> key that is <code>hard-coded</code> into the <code>SpeechRecognition</code> library. That means you can get off your feet without having to sign up for a service.<br>&emsp;&emsp;The flexibility and <code>ease-of-use</code> of the <code>SpeechRecognition</code> package make it an excellent choice for any <code>Python</code> project. However, support for every feature of each <code>API</code> it wraps is not guaranteed. You will need to spend some time researching the available options to find out if <code>SpeechRecognition</code> will work in your particular case.<br>&emsp;&emsp;So, now that you’re convinced you should try out <code>SpeechRecognition</code>, the next step is getting it installed in your environment.</p>
<h3 id="Installing-SpeechRecognition"><a href="#Installing-SpeechRecognition" class="headerlink" title="Installing SpeechRecognition"></a>Installing SpeechRecognition</h3><p>&emsp;&emsp;<code>SpeechRecognition</code> is compatible with <code>Python 2.6</code>, <code>2.7</code> and <code>3.3+</code>, but requires some additional installation steps for <code>Python 2</code>. For this tutorial, I’ll assume you are using <code>Python 3.3+</code>.<br>&emsp;&emsp;You can install <code>SpeechRecognition</code> from a terminal with <code>pip</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install SpeechRecognition</span><br></pre></td></tr></table></figure>
<p>Once installed, you should verify the installation by opening an interpreter session and typing:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sr.__version__</span><br><span class="line"><span class="string">'3.8.1'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Go ahead and keep this session open. You’ll start to work with it in just a bit.<br>&emsp;&emsp;<code>SpeechRecognition</code> will work out of the box if all you need to do is work with existing audio files. Specific use cases, however, require a few dependencies. Notably, the <code>PyAudio</code> package is needed for capturing microphone input.<br>&emsp;&emsp;You’ll see which dependencies you need as you read further. For now, let’s dive in and explore the basics of the package.</p>
<h3 id="The-Recognizer-Class"><a href="#The-Recognizer-Class" class="headerlink" title="The Recognizer Class"></a>The Recognizer Class</h3><p>&emsp;&emsp;All of the magic in <code>SpeechRecognition</code> happens with the <code>Recognizer</code> class. The primary purpose of a <code>Recognizer</code> instance is, of course, to recognize speech. Each instance comes with a variety of settings and functionality for recognizing speech from an audio source.<br>&emsp;&emsp;Creating a <code>Recognizer</code> instance is easy. In your current interpreter session, just type:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = sr.Recognizer()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Each Recognizer instance has seven methods for recognizing speech from an audio source using various <code>APIs</code>. These are:</p>
<ul>
<li><code>recognize_bing()</code>: <code>Microsoft Bing Speech</code></li>
<li><code>recognize_google()</code>: <code>Google Web Speech API</code></li>
<li><code>recognize_google_cloud()</code>: <code>Google Cloud Speech</code> - requires installation of the <code>google-cloud-speech</code> package</li>
<li><code>recognize_houndify()</code>: <code>Houndify by SoundHound</code></li>
<li><code>recognize_ibm()</code>: <code>IBM Speech to Text</code></li>
<li><code>recognize_sphinx()</code>: <code>CMU Sphinx</code> - requires installing <code>PocketSphinx</code></li>
<li><code>recognize_wit()</code>: <code>Wit.ai</code></li>
</ul>
<p>Of the seven, only <code>recognize_sphinx()</code> works offline with the <code>CMU Sphinx</code> engine. The other six all require an internet connection.<br>&emsp;&emsp;A full discussion of the features and benefits of each <code>API</code> is beyond the scope of this tutorial. Since <code>SpeechRecognition</code> ships with a default <code>API</code> key for the <code>Google Web Speech API</code>, you can get started with it right away. For this reason, we’ll use the <code>Web Speech API</code> in this guide. The other six <code>APIs</code> all require authentication with either an <code>API</code> key or a <code>username/password</code> combination. For more information, consult the <code>SpeechRecognition</code> docs.<br>&emsp;&emsp;Caution: The default key provided by <code>SpeechRecognition</code> is for testing purposes only, and <code>Google</code> may revoke it at any time. It is not a good idea to use the <code>Google Web Speech API</code> in production. Even with a valid <code>API</code> key, you’ll be limited to only <code>50</code> requests per day, and there is no way to raise this quota. Fortunately, <code>SpeechRecognition&#39;s</code> interface is nearly identical for each <code>API</code>, so what you learn today will be easy to translate to a <code>real-world</code> project.<br>&emsp;&emsp;Each <code>recognize_*()</code> method will throw a <code>RequestError</code> exception if the <code>API</code> is unreachable. For <code>recognize_sphinx()</code>, this could happen as the result of a missing, corrupt or incompatible <code>Sphinx</code> installation. For the other six methods, <code>RequestError</code> may be thrown if quota limits are met, the server is unavailable, or there is no internet connection.<br>&emsp;&emsp;Let’s get our hands dirty. Go ahead and try to call <code>recognize_google()</code> in your interpreter session.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google()</span><br></pre></td></tr></table></figure>
<p>What happened? You probably got something that looks like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: recognize_google() missing <span class="number">1</span> required positional argument: <span class="string">'audio_data'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;You might have guessed this would happen. How could something be recognized from nothing? All seven <code>recognize_*()</code> methods of the <code>Recognizer</code> class require an <code>audio_data</code> argument. In each case, <code>audio_data</code> must be an instance of <code>SpeechRecognition&#39;s</code> <code>AudioData</code> class.<br>&emsp;&emsp;There are two ways to create an <code>AudioData</code> instance: from an audio file or audio recorded by a microphone. Audio files are a little easier to get started with, so let’s take a look at that first.</p>
<h3 id="Working-With-Audio-Files"><a href="#Working-With-Audio-Files" class="headerlink" title="Working With Audio Files"></a>Working With Audio Files</h3><p>&emsp;&emsp;Before you continue, you’ll need to download an audio file. The one I used to get started, <code>harvard.wav</code> can be found here (<code>https://github.com/realpython/python-speech-recognition</code>). Make sure you save it to the same directory in which your <code>Python</code> interpreter session is running.<br>&emsp;&emsp;<code>SpeechRecognition</code> makes working with audio files easy thanks to its handy <code>AudioFile</code> class. This class can be initialized with the path to an audio file and provides a context manager interface for reading and working with the file’s contents.</p>
<h4 id="Supported-File-Types"><a href="#Supported-File-Types" class="headerlink" title="Supported File Types"></a>Supported File Types</h4><p>&emsp;&emsp;Currently, <code>SpeechRecognition</code> supports the following file formats: <code>WAV</code>: must be in <code>PCM/LPCM</code> format, <code>AIFF</code>, <code>AIFF-C</code>, <code>FLAC</code>: must be native <code>FLAC</code> format; <code>OGG-FLAC</code> is not supported.<br>&emsp;&emsp;If you are working on <code>X86</code> based <code>Linux</code>, <code>macOS</code> or <code>Windows</code>, you should be able to work with <code>FLAC</code> files without a problem. On other platforms, you will need to install a <code>FLAC</code> encoder and ensure you have access to the flac command line tool. You can find more information here if this applies to you.</p>
<h4 id="Using-record-to-Capture-Data-From-a-File"><a href="#Using-record-to-Capture-Data-From-a-File" class="headerlink" title="Using record() to Capture Data From a File"></a>Using record() to Capture Data From a File</h4><p>&emsp;&emsp;Type the following into your interpreter session to process the contents of the <code>harvard.wav</code> file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>harvard = sr.AudioFile(<span class="string">'harvard.wav'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> harvard <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>   audio = r.record(source)</span><br></pre></td></tr></table></figure>
<p>The context manager opens the file and reads its contents, storing the data in an <code>AudioFile</code> instance called source. Then the <code>record()</code> method records the data from the entire file into an <code>AudioData</code> instance. You can confirm this by checking the type of audio:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(audio)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">speech_recognition</span>.<span class="title">AudioData</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;You can now invoke <code>recognize_google()</code> to attempt to recognize any speech in the audio. Depending on your internet connection speed, you may have to wait several seconds before seeing the result.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'the stale smell of old beer lingers it takes heat to bring out</span></span><br><span class="line"><span class="string"> the odor a cold dip restores health and zest a salt pickle taste</span></span><br><span class="line"><span class="string"> fine with ham tacos al Pastore are my favorite a zestful food is the hot cross bun'</span></span><br></pre></td></tr></table></figure>
<p>Congratulations! You’ve just transcribed your first audio file!<br>&emsp;&emsp;If you’re wondering where the phrases in the <code>harvard.wav</code> file come from, they are examples of <code>Harvard Sentences</code>. These phrases were published by the <code>IEEE</code> in <code>1965</code> for use in speech intelligibility testing of telephone lines. They are still used in <code>VoIP</code> and cellular testing today.<br>&emsp;&emsp;The <code>Harvard Sentences</code> are comprised of <code>72</code> lists of ten phrases. You can find freely available recordings of these phrases on the <code>Open Speech Repository</code> website. Recordings are available in <code>English</code>, <code>Mandarin Chinese</code>, <code>French</code>, and <code>Hindi</code>. They provide an excellent source of free material for testing your code.</p>
<h4 id="Capturing-Segments-With-offset-and-duration"><a href="#Capturing-Segments-With-offset-and-duration" class="headerlink" title="Capturing Segments With offset and duration"></a>Capturing Segments With offset and duration</h4><p>&emsp;&emsp;What if you only want to capture a portion of the speech in a file? The <code>record()</code> method accepts a duration keyword argument that stops the recording after a specified number of seconds.<br>&emsp;&emsp;For example, the following captures any speech in the first four seconds of the file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> harvard <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source, duration=<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'the stale smell of old beer lingers'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>record()</code> method, when used inside a with block, always moves ahead in the file stream. This means that if you record once for four seconds and then record again for four seconds, the second time returns the four seconds of audio after the first four seconds.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> harvard <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio1 = r.record(source, duration=<span class="number">4</span>)</span><br><span class="line"><span class="meta">... </span>    audio2 = r.record(source, duration=<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio1)</span><br><span class="line"><span class="string">'the stale smell of old beer lingers'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio2)</span><br><span class="line"><span class="string">'it takes heat to bring out the odor a cold dip'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Notice that <code>audio2</code> contains a portion of the third phrase in the file. When specifying a duration, the recording might stop <code>mid-phrase</code> or even <code>mid-word-which</code> can hurt the accuracy of the transcription. More on this in a bit.<br>&emsp;&emsp;In addition to specifying a recording duration, the <code>record()</code> method can be given a specific starting point using the offset keyword argument. This value represents the number of seconds from the beginning of the file to ignore before starting to record.<br>&emsp;&emsp;To capture only the second phrase in the file, you could start with an offset of four seconds and record for, say, three seconds.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> harvard <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source, offset=<span class="number">4</span>, duration=<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recognizer.recognize_google(audio)</span><br><span class="line"><span class="string">'it takes heat to bring out the odor'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The offset and duration keyword arguments are useful for segmenting an audio file if you have prior knowledge of the structure of the speech in the file. However, using them hastily can result in poor transcriptions. To see this effect, try the following in your interpreter:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> harvard <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source, offset=<span class="number">4.7</span>, duration=<span class="number">2.8</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recognizer.recognize_google(audio)</span><br><span class="line"><span class="string">'Mesquite to bring out the odor Aiko'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;By starting the recording at <code>4.7</code> seconds, you miss the <code>it t</code> portion a the beginning of the phrase <code>it takes heat to bring out the odor</code>, so the <code>API</code> only got <code>akes heat</code> which it matched to <code>Mesquite</code>.<br>&emsp;&emsp;Similarly, at the end of the recording, you captured <code>a co</code>, which is the beginning of the third phrase <code>a cold dip restores health and zest</code>. This was matched to <code>Aiko</code> by the <code>API</code>.<br>&emsp;&emsp;There is another reason you may get inaccurate transcriptions. Noise! The above examples worked well because the audio file is reasonably clean. In the real world, unless you have the opportunity to process audio files beforehand, you can not expect the audio to be <code>noise-free</code>.</p>
<h4 id="The-Effect-of-Noise-on-Speech-Recognition"><a href="#The-Effect-of-Noise-on-Speech-Recognition" class="headerlink" title="The Effect of Noise on Speech Recognition"></a>The Effect of Noise on Speech Recognition</h4><p>&emsp;&emsp;Noise is a fact of life. All audio recordings have some degree of noise in them, and <code>un-handled</code> noise can wreck the accuracy of speech recognition apps.<br>&emsp;&emsp;To get a feel for how noise can affect speech recognition, download the <code>jackhammer.wav</code> file here (<code>https://github.com/realpython/python-speech-recognition</code>). As always, make sure you save this to your interpreter session’s working directory.<br>&emsp;&emsp;This file has the phrase <code>the stale smell of old beer lingers</code> spoken with a loud jackhammer in the background. What happens when you try to transcribe this file?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>jackhammer = sr.AudioFile(<span class="string">'jackhammer.wav'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> jackhammer <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'the snail smell of old gear vendors'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;So how do you deal with this? One thing you can try is using the <code>adjust_for_ambient_noise()</code> method of the Recognizer class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> jackhammer <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    r.adjust_for_ambient_noise(source)</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'still smell of old beer vendors'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;That got you a little closer to the actual phrase, but it still isn’t perfect. Also, <code>the</code> is missing from the beginning of the phrase. Why is that?<br>&emsp;&emsp;The <code>adjust_for_ambient_noise()</code> method reads the first second of the file stream and calibrates the recognizer to the noise level of the audio. Hence, that portion of the stream is consumed before you call <code>record()</code> to capture the data.<br>&emsp;&emsp;You can adjust the <code>time-frame</code> that <code>adjust_for_ambient_noise()</code> uses for analysis with the duration keyword argument. This argument takes a numerical value in seconds and is set to <code>1</code> by default. Try lowering this value to <code>0.5</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> jackhammer <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    r.adjust_for_ambient_noise(source, duration=<span class="number">0.5</span>)</span><br><span class="line"><span class="meta">... </span>    audio = r.record(source)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'the snail smell like old Beer Mongers'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Well, that got you <code>the</code> at the beginning of the phrase, but now you have some new issues! Sometimes it isn’t possible to remove the effect of the noise - the signal is just too noisy to be dealt with successfully. That’s the case with this file.<br>&emsp;&emsp;If you find yourself running up against these issues frequently, you may have to resort to some <code>pre-processing</code> of the audio. This can be done with audio editing software or a <code>Python</code> package (such as <code>SciPy</code>) that can apply filters to the files. A detailed discussion of this is beyond the scope of this tutorial - check out <code>Allen Downey&#39;s Think DSP</code> book if you are interested. For now, just be aware that ambient noise in an audio file can cause problems and must be addressed in order to maximize the accuracy of speech recognition.<br>&emsp;&emsp;When working with noisy files, it can be helpful to see the actual <code>API</code> response. Most <code>APIs</code> return a <code>JSON</code> string containing many possible transcriptions. The <code>recognize_google()</code> method will always return the most likely transcription unless you force it to give you the full response.<br>&emsp;&emsp;You can do this by setting the <code>show_all</code> keyword argument of the <code>recognize_google()</code> method to <code>True</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio, show_all=<span class="keyword">True</span>)</span><br><span class="line">&#123;<span class="string">'alternative'</span>: [</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the snail smell like old Beer Mongers'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smell of old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the snail smell like old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the stale smell of old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the snail smell like old beermongers'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'destihl smell of old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smell like old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'bastille smell of old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smell like old beermongers'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smell of old beer venders'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smelling old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'musty smell of old beer vendors'</span>&#125;,</span><br><span class="line">  &#123;<span class="string">'transcript'</span>: <span class="string">'the still smell of old beer vendor'</span>&#125;</span><br><span class="line">], <span class="string">'final'</span>: <span class="keyword">True</span>&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;As you can see, <code>recognize_google()</code> returns a dictionary with the key <code>alternative</code> that points to a list of possible transcripts. The structure of this response may vary from <code>API</code> to <code>API</code> and is mainly useful for debugging.<br>&emsp;&emsp;By now, you have a pretty good idea of the basics of the <code>SpeechRecognition</code> package. You’ve seen how to create an <code>AudioFile</code> instance from an audio file and use the <code>record()</code> method to capture data from the file. You learned how record segments of a file using the offset and duration keyword arguments of <code>record()</code>, and you experienced the detrimental effect noise can have on transcription accuracy.<br>&emsp;&emsp;Now for the fun part. Let’s transition from transcribing static audio files to making your project interactive by accepting input from a microphone.</p>
<h3 id="Working-With-Microphones"><a href="#Working-With-Microphones" class="headerlink" title="Working With Microphones"></a>Working With Microphones</h3><p>&emsp;&emsp;To access your microphone with <code>SpeechRecognizer</code>, you’ll have to install the <code>PyAudio</code> package. Go ahead and close your current interpreter session, and let’s do that.</p>
<h4 id="Installing-PyAudio"><a href="#Installing-PyAudio" class="headerlink" title="Installing PyAudio"></a>Installing PyAudio</h4><p>&emsp;&emsp;The process for installing <code>PyAudio</code> will vary depending on your operating system.<br>&emsp;&emsp;<code>Debian Linux</code>: If you’re on <code>Debian-based Linux</code> (like <code>Ubuntu</code>), you can install <code>PyAudio</code> with apt:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python-pyaudio python3-pyaudio</span><br></pre></td></tr></table></figure>
<p>Once installed, you may still need to run pip install <code>pyaudio</code>, especially if you are working in a virtual environment.<br>&emsp;&emsp;<code>macOS</code>: For <code>macOS</code>, first you will need to install <code>PortAudio</code> with <code>Homebrew</code>, and then install <code>PyAudio</code> with <code>pip</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew install portaudio</span><br><span class="line">pip install pyaudio</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>Windows</code>: On <code>Windows</code>, you can install <code>PyAudio</code> with <code>pip</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyaudio</span><br></pre></td></tr></table></figure>
<h4 id="Testing-the-Installation"><a href="#Testing-the-Installation" class="headerlink" title="Testing the Installation"></a>Testing the Installation</h4><p>&emsp;&emsp;Once you’ve got <code>PyAudio</code> installed, you can test the installation from the console.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m speech_recognition</span><br></pre></td></tr></table></figure>
<p>Make sure your default microphone is on and unmuted. If the installation worked, you should see something like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A moment of silence, please...</span><br><span class="line">Set minimum energy threshold to <span class="number">600.4452854381937</span></span><br><span class="line">Say something!</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Go ahead and play around with it a little bit by speaking into your microphone and seeing how well <code>SpeechRecognition</code> transcribes your speech.<br>&emsp;&emsp;<strong>Note</strong>: If you are on <code>Ubuntu</code> and get some funky output like <code>ALSA lib ... Unknown PCM</code>, refer to this page for tips on suppressing these messages. This output comes from the <code>ALSA</code> package installed with <code>Ubuntu</code> - not <code>SpeechRecognition</code> or <code>PyAudio</code>. In all reality, these messages may indicate a problem with your <code>ALSA</code> configuration, but in my experience, they do not impact the functionality of your code. They are mostly a nuisance.</p>
<h4 id="The-Microphone-Class"><a href="#The-Microphone-Class" class="headerlink" title="The Microphone Class"></a>The Microphone Class</h4><p>&emsp;&emsp;Open up another interpreter session and create an instance of the recognizer class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = sr.Recognizer()</span><br></pre></td></tr></table></figure>
<p>Now, instead of using an audio file as the source, you will use the default system microphone. You can access this by creating an instance of the <code>Microphone</code> class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>mic = sr.Microphone()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;If your system has no default microphone (such as on a <code>RaspberryPi</code>), or you want to use a microphone other than the default, you will need to specify which one to use by supplying a device index. You can get a list of microphone names by calling the <code>list_microphone_names()</code> static method of the <code>Microphone</code> class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sr.Microphone.list_microphone_names()</span><br><span class="line">[<span class="string">'HDA Intel PCH: ALC272 Analog (hw:0,0)'</span>,</span><br><span class="line"> <span class="string">'HDA Intel PCH: HDMI 0 (hw:0,3)'</span>,</span><br><span class="line"> <span class="string">'sysdefault'</span>,</span><br><span class="line"> <span class="string">'front'</span>,</span><br><span class="line"> <span class="string">'surround40'</span>,</span><br><span class="line"> <span class="string">'surround51'</span>,</span><br><span class="line"> <span class="string">'surround71'</span>,</span><br><span class="line"> <span class="string">'hdmi'</span>,</span><br><span class="line"> <span class="string">'pulse'</span>,</span><br><span class="line"> <span class="string">'dmix'</span>,</span><br><span class="line"> <span class="string">'default'</span>]</span><br></pre></td></tr></table></figure>
<p>Note that your output may differ from the above example. The device index of the microphone is the index of its name in the list returned by <code>list_microphone_names()</code>. For example, given the above output, if you want to use the microphone called <code>front</code>, which has index <code>3</code> in the list, you would create a microphone instance like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is just an example, do not run</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mic = sr.Microphone(device_index=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>For most projects, though, you’ll probably want to use the default system microphone.</p>
<h4 id="Using-listen-to-Capture-Microphone-Input"><a href="#Using-listen-to-Capture-Microphone-Input" class="headerlink" title="Using listen() to Capture Microphone Input"></a>Using listen() to Capture Microphone Input</h4><p>&emsp;&emsp;Now that you’ve got a <code>Microphone</code> instance ready to go, it’s time to capture some input.<br>&emsp;&emsp;Just like the <code>AudioFile</code> class, <code>Microphone</code> is a context manager. You can capture input from the microphone using the <code>listen()</code> method of the <code>Recognizer</code> class inside of the with block. This method takes an audio source as its first argument and records input from the source until silence is detected.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> mic <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    audio = r.listen(source)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Once you execute the with block, try speaking <code>hello</code> into your microphone. Wait a moment for the interpreter prompt to display again. Once the <code>&gt;&gt;&gt;</code> prompt returns, you’re ready to recognize the speech.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.recognize_google(audio)</span><br><span class="line"><span class="string">'hello'</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;If the prompt never returns, your microphone is most likely picking up too much ambient noise. You can interrupt the process with <code>ctrl + c</code> to get your prompt back.<br>&emsp;&emsp;To handle ambient noise, you’ll need to use the <code>adjust_for_ambient_noise()</code> method of the <code>Recognizer</code> class, just like you did when trying to make sense of the noisy audio file. Since input from a microphone is far less predictable than input from an audio file, it is a good idea to do this anytime you listen for microphone input.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> mic <span class="keyword">as</span> source:</span><br><span class="line"><span class="meta">... </span>    r.adjust_for_ambient_noise(source)</span><br><span class="line"><span class="meta">... </span>    audio = r.listen(source)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;After running the above code, wait a second for <code>adjust_for_ambient_noise()</code> to do its thing, then try speaking <code>hello</code> into the microphone. Again, you will have to wait a moment for the interpreter prompt to return before trying to recognize the speech.<br>&emsp;&emsp;<code>Recall that adjust_for_ambient_noise()</code> analyzes the audio source for one second. If this seems too long to you, feel free to adjust this with the duration keyword argument.<br>&emsp;&emsp;The <code>SpeechRecognition</code> documentation recommends using a duration no less than <code>0.5</code> seconds. In some cases, you may find that durations longer than the default of one second generate better results. The minimum value you need depends on the microphone’s ambient environment. Unfortunately, this information is typically unknown during development. In my experience, the default duration of one second is adequate for most applications.</p>
<h4 id="Handling-Unrecognizable-Speech"><a href="#Handling-Unrecognizable-Speech" class="headerlink" title="Handling Unrecognizable Speech"></a>Handling Unrecognizable Speech</h4><p>&emsp;&emsp;Try typing the previous code example in to the interpeter and making some unintelligible noises into the microphone. You should get something like this in response:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"/home/david/real_python/speech_recognition_primer/</span></span><br><span class="line"><span class="string">       venv/lib/python3.5/site-packages/speech_recognition/__init__.py"</span>,</span><br><span class="line">       line <span class="number">858</span>, <span class="keyword">in</span> recognize_google</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(actual_result, dict) <span class="keyword">or</span> len(actual_result.get(<span class="string">"alternative"</span>, [])) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> UnknownValueError()</span><br><span class="line">speech_recognition.UnknownValueError</span><br></pre></td></tr></table></figure>
<p>Audio that cannot be matched to text by the <code>API</code> raises an <code>UnknownValueError</code> exception. You should always wrap calls to the <code>API</code> with try and except blocks to handle this exception.<br>&emsp;&emsp;<strong>Note</strong>: You may have to try harder than you expect to get the exception thrown. The <code>API</code> works very hard to transcribe any vocal sounds. Even short grunts were transcribed as words like <code>how</code> for me. Coughing, hand claps, and tongue clicks would consistently raise the exception.</p>
<h4 id="Putting-It-All-Together-A-“Guess-the-Word”-Game"><a href="#Putting-It-All-Together-A-“Guess-the-Word”-Game" class="headerlink" title="Putting It All Together: A “Guess the Word” Game"></a>Putting It All Together: A “Guess the Word” Game</h4><p>&emsp;&emsp;Now that you’ve seen the basics of recognizing speech with the <code>SpeechRecognition</code> package let’s put your newfound knowledge to use and write a small game that picks a random word from a list and gives the user three attempts to guess the word.<br>&emsp;&emsp;Here is the full script:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recognize_speech_from_mic</span><span class="params">(recognizer, microphone)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Transcribe speech from recorded from `microphone`. Returns a dictionary with three keys:</span></span><br><span class="line"><span class="string">    "success": a boolean indicating whether or not the API request was successful</span></span><br><span class="line"><span class="string">    "error": `None` if no error occured, otherwise a string containing an error message</span></span><br><span class="line"><span class="string">             if the API could not be reached or speech was unrecognizable</span></span><br><span class="line"><span class="string">    "transcription": `None` if speech could not be transcribed, otherwise</span></span><br><span class="line"><span class="string">                     a string containing the transcribed text</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># check that recognizer and microphone arguments are appropriate type</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(recognizer, sr.Recognizer):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"`recognizer` must be `Recognizer` instance"</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(microphone, sr.Microphone):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"`microphone` must be `Microphone` instance"</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="comment"># adjust the recognizer sensitivity to ambient noise and record audio from the microphone</span></span><br><span class="line">    <span class="keyword">with</span> microphone <span class="keyword">as</span> source:</span><br><span class="line">        recognizer.adjust_for_ambient_noise(source)</span><br><span class="line">        audio = recognizer.listen(source)</span><br><span class="line">​</span><br><span class="line">    response = &#123;<span class="string">"success"</span>: <span class="keyword">True</span>, <span class="string">"error"</span>: <span class="keyword">None</span>, <span class="string">"transcription"</span>: <span class="keyword">None</span>&#125;  <span class="comment"># set up the response object</span></span><br><span class="line">​</span><br><span class="line">    <span class="comment"># try recognizing the speech in the recording. if a RequestError or UnknownValueError exception is</span></span><br><span class="line">    <span class="comment"># caught, update the response object accordingly</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response[<span class="string">"transcription"</span>] = recognizer.recognize_google(audio)</span><br><span class="line">    <span class="keyword">except</span> sr.RequestError:  <span class="comment"># API was unreachable or unresponsive</span></span><br><span class="line">        response[<span class="string">"success"</span>] = <span class="keyword">False</span></span><br><span class="line">        response[<span class="string">"error"</span>] = <span class="string">"API unavailable"</span></span><br><span class="line">    <span class="keyword">except</span> sr.UnknownValueError:</span><br><span class="line">        response[<span class="string">"error"</span>] = <span class="string">"Unable to recognize speech"</span>  <span class="comment"># speech was unintelligible</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># set the list of words, maxnumber of guesses, and prompt limit</span></span><br><span class="line">    WORDS = [<span class="string">"apple"</span>, <span class="string">"banana"</span>, <span class="string">"grape"</span>, <span class="string">"orange"</span>, <span class="string">"mango"</span>, <span class="string">"lemon"</span>]</span><br><span class="line">    NUM_GUESSES = <span class="number">3</span></span><br><span class="line">    PROMPT_LIMIT = <span class="number">5</span></span><br><span class="line">​</span><br><span class="line">    <span class="comment"># create recognizer and mic instances</span></span><br><span class="line">    recognizer = sr.Recognizer()</span><br><span class="line">    microphone = sr.Microphone()</span><br><span class="line">​</span><br><span class="line">    word = random.choice(WORDS)  <span class="comment"># get a random word from the list</span></span><br><span class="line">​</span><br><span class="line">    instructions = (  <span class="comment"># format the instructions string</span></span><br><span class="line">        <span class="string">"I'm thinking of one of these words:\n"</span></span><br><span class="line">        <span class="string">"&#123;words&#125;\n"</span></span><br><span class="line">        <span class="string">"You have &#123;n&#125; tries to guess which one.\n"</span></span><br><span class="line">    ).format(words=<span class="string">', '</span>.join(WORDS), n=NUM_GUESSES)</span><br><span class="line">​</span><br><span class="line">    print(instructions)  <span class="comment"># show instructions and wait 3 seconds before starting the game</span></span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_GUESSES):</span><br><span class="line">        <span class="comment"># get the guess from the user</span></span><br><span class="line">        <span class="comment"># if a transcription is returned, break out of the loop and continue</span></span><br><span class="line">        <span class="comment"># if no transcription returned and API request failed, break loop and continue</span></span><br><span class="line">        <span class="comment"># if API request succeeded but no transcription was returned, re-prompt the user</span></span><br><span class="line">        <span class="comment"># to say their guess again. Do this up to PROMPT_LIMIT times</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(PROMPT_LIMIT):</span><br><span class="line">            print(<span class="string">'Guess &#123;&#125;. Speak!'</span>.format(i + <span class="number">1</span>))</span><br><span class="line">            guess = recognize_speech_from_mic(recognizer, microphone)</span><br><span class="line">            <span class="keyword">if</span> guess[<span class="string">"transcription"</span>]:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> guess[<span class="string">"success"</span>]:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            print(<span class="string">"I didn't catch that. What did you say?\n"</span>)</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> guess[<span class="string">"error"</span>]:  <span class="comment"># if there was an error, stop the game</span></span><br><span class="line">            print(<span class="string">"ERROR: &#123;&#125;"</span>.format(guess[<span class="string">"error"</span>]))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">​</span><br><span class="line">        print(<span class="string">"You said: &#123;&#125;"</span>.format(guess[<span class="string">"transcription"</span>]))  <span class="comment"># show the user the transcription</span></span><br><span class="line">​</span><br><span class="line">        <span class="comment"># determine if guess is correct and if any attempts remain</span></span><br><span class="line">        guess_is_correct = guess[<span class="string">"transcription"</span>].lower() == word.lower()</span><br><span class="line">        user_has_more_attempts = i &lt; NUM_GUESSES - <span class="number">1</span></span><br><span class="line">​</span><br><span class="line">        <span class="comment"># determine if the user has won the game. if not, repeat the loop if user has</span></span><br><span class="line">        <span class="comment"># more attempts; if no attempts left, the user loses the game</span></span><br><span class="line">        <span class="keyword">if</span> guess_is_correct:</span><br><span class="line">            print(<span class="string">"Correct! You win!"</span>.format(word))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">elif</span> user_has_more_attempts:</span><br><span class="line">            print(<span class="string">"Incorrect. Try again.\n"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Sorry, you lose!\nI was thinking of '&#123;&#125;'."</span>.format(word))</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>recognize_speech_from_mic()</code> function takes a <code>Recognizer</code> and <code>Microphone</code> instance as arguments and returns a dictionary with three keys. The first key, <code>success</code>, is a boolean that indicates whether or not the <code>API</code> request was successful. The second key, <code>error</code>, is either <code>None</code> or an error message indicating that the <code>API</code> is unavailable or the speech was unintelligible. Finally, the <code>transcription</code> key contains the transcription of the audio recorded by the microphone.<br>&emsp;&emsp;The function first checks that the recognizer and microphone arguments are of the correct type, and raises a <code>TypeError</code> if either is invalid:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> isinstance(recognizer, sr.Recognizer):</span><br><span class="line">    <span class="keyword">raise</span> TypeError(<span class="string">'`recognizer` must be `Recognizer` instance'</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> isinstance(microphone, sr.Microphone):</span><br><span class="line">    <span class="keyword">raise</span> TypeError(<span class="string">'`microphone` must be a `Microphone` instance'</span>)</span><br></pre></td></tr></table></figure>
<p>The <code>listen()</code> method is then used to record microphone input:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> microphone <span class="keyword">as</span> source:</span><br><span class="line">    recognizer.adjust_for_ambient_noise(source)</span><br><span class="line">    audio = recognizer.listen(source)</span><br></pre></td></tr></table></figure>
<p>The <code>adjust_for_ambient_noise()</code> method is used to calibrate the recognizer for changing noise conditions each time the <code>recognize_speech_from_mic()</code> function is called.<br>&emsp;&emsp;Next, <code>recognize_google()</code> is called to transcribe any speech in the recording. A <code>try...except</code> block is used to catch the <code>RequestError</code> and <code>UnknownValueError</code> exceptions and handle them accordingly. The success of the <code>API</code> request, any error messages, and the transcribed speech are stored in the success, error and transcription keys of the response dictionary, which is returned by the <code>recognize_speech_from_mic()</code> function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">response = &#123;<span class="string">"success"</span>: <span class="keyword">True</span>, <span class="string">"error"</span>: <span class="keyword">None</span>, <span class="string">"transcription"</span>: <span class="keyword">None</span>&#125;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response[<span class="string">"transcription"</span>] = recognizer.recognize_google(audio)</span><br><span class="line"><span class="keyword">except</span> sr.RequestError:  <span class="comment"># API was unreachable or unresponsive</span></span><br><span class="line">    response[<span class="string">"success"</span>] = <span class="keyword">False</span></span><br><span class="line">    response[<span class="string">"error"</span>] = <span class="string">"API unavailable"</span></span><br><span class="line"><span class="keyword">except</span> sr.UnknownValueError:</span><br><span class="line">    response[<span class="string">"error"</span>] = <span class="string">"Unable to recognize speech"</span>  <span class="comment"># speech was unintelligible</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;You can test the <code>recognize_speech_from_mic()</code> function by saving the above script to a file called <code>guessing_game.py</code> and running the following in an interpreter session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> guessing_game <span class="keyword">import</span> recognize_speech_from_mic</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = sr.Recognizer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = sr.Microphone()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recognize_speech_from_mic(r, m)</span><br><span class="line">&#123;<span class="string">'success'</span>: <span class="keyword">True</span>, <span class="string">'error'</span>: <span class="keyword">None</span>, <span class="string">'transcription'</span>: <span class="string">'hello'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Your output will vary depending on what you say</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The game itself is pretty simple. First, a list of words, a maximum number of allowed guesses and a prompt limit are declared:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WORDS = [<span class="string">'apple'</span>, <span class="string">'banana'</span>, <span class="string">'grape'</span>, <span class="string">'orange'</span>, <span class="string">'mango'</span>, <span class="string">'lemon'</span>]</span><br><span class="line">NUM_GUESSES = <span class="number">3</span></span><br><span class="line">PROMPT_LIMIT = <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>Next, a <code>Recognizer</code> and Microphone instance is created and a random word is chosen from <code>WORDS</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">recognizer = sr.Recognizer()</span><br><span class="line">microphone = sr.Microphone()</span><br><span class="line">word = random.choice(WORDS)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;After printing some instructions and waiting for three seconds, a for loop is used to manage each user attempt at guessing the chosen word. The first thing inside the for loop is another for loop that prompts the user at most <code>PROMPT_LIMIT</code> times for a guess, attempting to recognize the input each time with the <code>recognize_speech_from_mic()</code> function and storing the dictionary returned to the local variable guess.<br>&emsp;&emsp;If the <code>transcription</code> key of guess is not <code>None</code>, then the user’s speech was transcribed and the inner loop is terminated with break. If the speech was not transcribed and the <code>success</code> key is set to <code>False</code>, then an <code>API</code> error occurred and the loop is again terminated with break. Otherwise, the <code>API</code> request was successful but the speech was unrecognizable. The user is warned and the for loop repeats, giving the user another chance at the current attempt.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(PROMPT_LIMIT):</span><br><span class="line">    print(<span class="string">'Guess &#123;&#125;. Speak!'</span>.format(i + <span class="number">1</span>))</span><br><span class="line">    guess = recognize_speech_from_mic(recognizer, microphone)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> guess[<span class="string">"transcription"</span>]:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> guess[<span class="string">"success"</span>]:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">"I didn't catch that. What did you say?\n"</span>)</span><br></pre></td></tr></table></figure>
<p>Once the inner for loop terminates, the guess dictionary is checked for errors. If any occurred, the error message is displayed and the outer for loop is terminated with break, which will end the program execution.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> guess[<span class="string">'error'</span>]:</span><br><span class="line">    print(<span class="string">"ERROR: &#123;&#125;"</span>.format(guess[<span class="string">"error"</span>]))</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;If there weren’t any errors, the transcription is compared to the randomly selected word. The <code>lower()</code> method for string objects is used to ensure better matching of the guess to the chosen word. The <code>API</code> may return speech matched to the word <code>apple</code> as <code>Apple</code> or <code>apple</code>, and either response should count as a correct answer.<br>&emsp;&emsp;If the guess was correct, the user wins and the game is terminated. If the user was incorrect and has any remaining attempts, the outer for loop repeats and a new guess is retrieved. Otherwise, the user loses the game.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">guess_is_correct = guess[<span class="string">"transcription"</span>].lower() == word.lower()</span><br><span class="line">user_has_more_attempts = i &lt; NUM_GUESSES - <span class="number">1</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> guess_is_correct:</span><br><span class="line">    print(<span class="string">'Correct! You win!'</span>.format(word))</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">elif</span> user_has_more_attempts:</span><br><span class="line">    print(<span class="string">'Incorrect. Try again.\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"Sorry, you lose!\nI was thinking of '&#123;&#125;'."</span>.format(word))</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>When run, the output will look something like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">I<span class="string">'m thinking of one of these words:</span></span><br><span class="line"><span class="string">apple, banana, grape, orange, mango, lemon</span></span><br><span class="line"><span class="string">You have 3 tries to guess which one.</span></span><br><span class="line"><span class="string">​</span></span><br><span class="line"><span class="string">Guess 1. Speak!</span></span><br><span class="line"><span class="string">You said: banana</span></span><br><span class="line"><span class="string">Incorrect. Try again.</span></span><br><span class="line"><span class="string">​</span></span><br><span class="line"><span class="string">Guess 2. Speak!</span></span><br><span class="line"><span class="string">You said: lemon</span></span><br><span class="line"><span class="string">Incorrect. Try again.</span></span><br><span class="line"><span class="string">​</span></span><br><span class="line"><span class="string">Guess 3. Speak!</span></span><br><span class="line"><span class="string">You said: Orange</span></span><br><span class="line"><span class="string">Correct! You win!</span></span><br></pre></td></tr></table></figure>
<h4 id="Recognizing-Speech-in-Languages-Other-Than-English"><a href="#Recognizing-Speech-in-Languages-Other-Than-English" class="headerlink" title="Recognizing Speech in Languages Other Than English"></a>Recognizing Speech in Languages Other Than English</h4><p>&emsp;&emsp;Throughout this tutorial, we’ve been recognizing speech in <code>English</code>, which is the default language for each <code>recognize_*()</code> method of the <code>SpeechRecognition</code> package. However, it is absolutely possible to recognize speech in other languages, and is quite simple to accomplish.<br>&emsp;&emsp;To recognize speech in a different language, set the language keyword argument of the <code>recognize_*()</code> method to a string corresponding to the desired language. Most of the methods accept a <code>BCP-47</code> language tag, such as <code>en-US</code> for <code>American English</code>, or <code>fr-FR</code> for <code>French</code>. For example, the following recognizes <code>French</code> speech in an audio file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line">​</span><br><span class="line">r = sr.Recognizer()</span><br><span class="line">​</span><br><span class="line"><span class="keyword">with</span> sr.AudioFile(<span class="string">'path/to/audiofile.wav'</span>) <span class="keyword">as</span> source:</span><br><span class="line">    audio = r.record(source)</span><br><span class="line">​</span><br><span class="line">r.recognize_google(audio, language=<span class="string">'fr-FR'</span>)</span><br></pre></td></tr></table></figure>
<p>Only the following methods accept a language keyword argument: <code>recognize_bing</code>, <code>recognize_google</code>, <code>recognize_google_cloud</code>, <code>recognize_ibm</code> and <code>recognize_sphinx</code>.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/13/深度学习/TensorFlow之线程和队列/" rel="next" title="TensorFlow之线程和队列">
                <i class="fa fa-chevron-left"></i> TensorFlow之线程和队列
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/13/深度学习/TensorFlow之函数总结/" rel="prev" title="TensorFlow之函数总结">
                TensorFlow之函数总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">939</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#How-Speech-Recognition-Works-An-Overview"><span class="nav-number">1.</span> <span class="nav-text">How Speech Recognition Works - An Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Picking-a-Python-Speech-Recognition-Package"><span class="nav-number">2.</span> <span class="nav-text">Picking a Python Speech Recognition Package</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Installing-SpeechRecognition"><span class="nav-number">3.</span> <span class="nav-text">Installing SpeechRecognition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Recognizer-Class"><span class="nav-number">4.</span> <span class="nav-text">The Recognizer Class</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Working-With-Audio-Files"><span class="nav-number">5.</span> <span class="nav-text">Working With Audio Files</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Supported-File-Types"><span class="nav-number">5.1.</span> <span class="nav-text">Supported File Types</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Using-record-to-Capture-Data-From-a-File"><span class="nav-number">5.2.</span> <span class="nav-text">Using record() to Capture Data From a File</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Capturing-Segments-With-offset-and-duration"><span class="nav-number">5.3.</span> <span class="nav-text">Capturing Segments With offset and duration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Effect-of-Noise-on-Speech-Recognition"><span class="nav-number">5.4.</span> <span class="nav-text">The Effect of Noise on Speech Recognition</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Working-With-Microphones"><span class="nav-number">6.</span> <span class="nav-text">Working With Microphones</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Installing-PyAudio"><span class="nav-number">6.1.</span> <span class="nav-text">Installing PyAudio</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Testing-the-Installation"><span class="nav-number">6.2.</span> <span class="nav-text">Testing the Installation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Microphone-Class"><span class="nav-number">6.3.</span> <span class="nav-text">The Microphone Class</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Using-listen-to-Capture-Microphone-Input"><span class="nav-number">6.4.</span> <span class="nav-text">Using listen() to Capture Microphone Input</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Handling-Unrecognizable-Speech"><span class="nav-number">6.5.</span> <span class="nav-text">Handling Unrecognizable Speech</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Putting-It-All-Together-A-“Guess-the-Word”-Game"><span class="nav-number">6.6.</span> <span class="nav-text">Putting It All Together: A “Guess the Word” Game</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Recognizing-Speech-in-Languages-Other-Than-English"><span class="nav-number">6.7.</span> <span class="nav-text">Recognizing Speech in Languages Other Than English</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  


  

  

</body>
</html>
