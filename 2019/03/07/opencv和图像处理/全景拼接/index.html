<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="&amp;emsp;&amp;emsp;官方代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &amp;lt;iostre">
<meta property="og:type" content="article">
<meta property="og:title" content="全景拼接">
<meta property="og:url" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/index.html">
<meta property="og:site_name" content="泥腿子出身">
<meta property="og:description" content="&amp;emsp;&amp;emsp;官方代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &amp;lt;iostre">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/1.png">
<meta property="og:image" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/2.png">
<meta property="og:image" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/3.png">
<meta property="og:image" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/4.png">
<meta property="og:updated_time" content="2019-03-07T08:16:54.235Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="全景拼接">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;官方代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &amp;lt;iostre">
<meta name="twitter:image" content="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '561O3H1PZB',
      apiKey: '7631d3cf19ac49bd39ada7163ec937a7',
      indexName: 'fuxinzi',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/">





  <title>全景拼接 | 泥腿子出身</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泥腿子出身</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fukangwei.gitee.io/2019/03/07/opencv和图像处理/全景拼接/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="付康为">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泥腿子出身">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">全景拼接</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-07T15:04:09+08:00">
                2019-03-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>&emsp;&emsp;官方代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/stitching/stitcher.hpp"</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">bool</span> try_use_gpu = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;Mat&gt; imgs;</span><br><span class="line"><span class="built_in">string</span> result_name = <span class="string">"result.jpg"</span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printUsage</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span></span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[] )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> retval = parseCmdArgs ( argc, argv );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( retval ) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    Mat pano;</span><br><span class="line">    Stitcher stitcher = Stitcher::createDefault ( try_use_gpu );</span><br><span class="line">    Stitcher::Status status = stitcher.stitch ( imgs, pano );</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> ( status != Stitcher::OK ) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span> ( status ) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    imwrite ( result_name, pano );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printUsage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt;</span><br><span class="line">         <span class="string">"Rotation model images stitcher.\n\n"</span></span><br><span class="line">         <span class="string">"stitching img1 img2 [...imgN]\n\n"</span></span><br><span class="line">         <span class="string">"Flags:\n"</span></span><br><span class="line">         <span class="string">"  --try_use_gpu (yes|no)\n"</span></span><br><span class="line">         <span class="string">"      Try to use GPU. The default value is 'no'. All default values\n"</span></span><br><span class="line">         <span class="string">"      are for CPU mode.\n"</span></span><br><span class="line">         <span class="string">"  --output &lt;result_img&gt;\n"</span></span><br><span class="line">         <span class="string">"      The default is 'result.jpg'.\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span> <span class="params">( <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( argc == <span class="number">1</span> ) &#123;</span><br><span class="line">        printUsage();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">1</span>; i &lt; argc; ++i ) &#123;</span><br><span class="line">        <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--help"</span> || <span class="built_in">string</span> ( argv[i] ) == <span class="string">"/?"</span> ) &#123;</span><br><span class="line">            printUsage();</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--try_use_gpu"</span> ) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i + <span class="number">1</span>] ) == <span class="string">"no"</span> ) &#123;</span><br><span class="line">                try_use_gpu = <span class="literal">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i + <span class="number">1</span>] ) == <span class="string">"yes"</span> ) &#123;</span><br><span class="line">                try_use_gpu = <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; <span class="string">"Bad --try_use_gpu flag value\n"</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">​</span><br><span class="line">            i++;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( <span class="built_in">string</span> ( argv[i] ) == <span class="string">"--output"</span> ) &#123;</span><br><span class="line">            result_name = argv[i + <span class="number">1</span>];</span><br><span class="line">            i++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Mat img = imread ( argv[i] );</span><br><span class="line">​</span><br><span class="line">            <span class="keyword">if</span> ( img.empty() ) &#123;</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't read image '"</span> &lt;&lt; argv[i] &lt;&lt; <span class="string">"'\n"</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">​</span><br><span class="line">            imgs.push_back ( img );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/1.png"></p>
<p>&emsp;&emsp;基于不同模式的全景拼接如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/stitching/stitcher.hpp"</span></span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line">​</span><br><span class="line"><span class="keyword">bool</span> try_use_gpu = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;Mat&gt; imgs;</span><br><span class="line"><span class="built_in">string</span> result_name = <span class="string">"result.jpg"</span>;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">parseCmdArgs</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="comment">/* 输入的图片全部填充到容器imgs中，并将输入的图片显示出来 */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; argc - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">        Mat img = imread(argv[i]);</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> (img.empty()) &#123;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't read image '"</span> &lt;&lt; argv[i] &lt;&lt; <span class="string">"'\n"</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">​</span><br><span class="line">        imgs.push_back(img);</span><br><span class="line">        imshow(argv[i], img);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> retval = parseCmdArgs(argc, argv);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (retval) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    Mat pano;</span><br><span class="line">    <span class="comment">/* 创建一个stitcher对象 */</span></span><br><span class="line">    Stitcher stitcher = Stitcher::createDefault(try_use_gpu);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'1'</span>) &#123;  <span class="comment">/* 1是平面拼接 */</span></span><br><span class="line">        PlaneWarper *cw = <span class="keyword">new</span> PlaneWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'2'</span>) &#123; <span class="comment">/* 2是柱面拼接 */</span></span><br><span class="line">        SphericalWarper *cw = <span class="keyword">new</span> SphericalWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (argv[<span class="number">3</span>][<span class="number">0</span>] == <span class="string">'3'</span>) &#123; <span class="comment">/* 3是立体画面拼接 */</span></span><br><span class="line">        StereographicWarper *cw = <span class="keyword">new</span> cv::StereographicWarper();</span><br><span class="line">        stitcher.setWarper(cw);</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* 使用Surf算法来寻找特征点，支持Surf和Orb两种方式 */</span></span><br><span class="line">    detail::SurfFeaturesFinder *featureFinder = <span class="keyword">new</span> detail::SurfFeaturesFinder();</span><br><span class="line">    stitcher.setFeaturesFinder(featureFinder);</span><br><span class="line">​</span><br><span class="line">    <span class="comment">/* 匹配给定的图像和估计相机的旋转 */</span></span><br><span class="line">    Stitcher::Status status = stitcher.estimateTransform(imgs);</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (status != Stitcher::OK) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span>(status) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    status = stitcher.composePanorama(pano); <span class="comment">/* 生成全景图像 */</span>  </span><br><span class="line">​</span><br><span class="line">    <span class="keyword">if</span> (status != Stitcher::OK) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Can't stitch images, error code = "</span> &lt;&lt; <span class="keyword">int</span>(status) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">​</span><br><span class="line">    imwrite(result_name, pano);</span><br><span class="line">    imshow(<span class="string">"show"</span>, pano);</span><br><span class="line">    cv::waitKey(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/2.png"></p>
<hr>
<h3 id="基于OpenCV全景拼接"><a href="#基于OpenCV全景拼接" class="headerlink" title="基于OpenCV全景拼接"></a>基于OpenCV全景拼接</h3><p>&emsp;&emsp;基于<code>OpenCV</code>的图片拼接和全景图构建，用于<code>缝合</code>两张有重叠区域的图来创建一张全景图。构建全景图利用到的计算机视觉和图像处理技术有：关键点检测、局部不变特征、关键点匹配、<code>RANSAC</code>和透视变形。因为处理关键点检测和局部不变性在<code>OpenCV 2.4.X</code>和<code>OpenCV 3.X</code>中有很大的不同，比如<code>SIFT</code>和<code>SURF</code>，这里将给出兼容两个版本的代码。<br>&emsp;&emsp;全景拼接算法由四部分组成：</p>
<ul>
<li><code>Step 1</code>: Detect keypoints (<code>DoG</code>, <code>Harris</code> etc) and extract local invariant descriptors (<code>SIFT</code>, <code>SURF</code> etc) from the two input images.</li>
<li><code>Step 2</code>: Match the descriptors between the two images.</li>
<li><code>Step 3</code>: Use the <code>RANSAC</code> algorithm to estimate a homography matrix using our matched feature vectors.</li>
<li><code>Step 4</code>: Apply a warping transformation using the homography matrix obtained from <code>Step 3</code>.</li>
</ul>
<p>将所有的步骤都封装在<code>panorama.py</code>，定义一个<code>Stitcher</code>类来构建全图。<br>&emsp;&emsp;<code>panorama.py</code>如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stitcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.isv3 = imutils.is_cv3()  <span class="comment"># determine if we are using OpenCV v3.X</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stitch</span><span class="params">(self, images, ratio=<span class="number">0.75</span>, reprojThresh=<span class="number">4.0</span>, showMatches=False)</span>:</span></span><br><span class="line">        <span class="comment"># unpack the images, then detect keypoints and extract local invariant descriptors from them</span></span><br><span class="line">        (imageB, imageA) = images</span><br><span class="line">        (kpsA, featuresA) = self.detectAndDescribe(imageA)</span><br><span class="line">        (kpsB, featuresB) = self.detectAndDescribe(imageB)</span><br><span class="line">        <span class="comment"># match features between the two images</span></span><br><span class="line">        M = self.matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> M <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment"># if the match is None, then there aren't enough matched keypoints to create a panorama</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">​</span><br><span class="line">        (matches, H, status) = M  <span class="comment"># otherwise, apply a perspective warp to stitch the images together</span></span><br><span class="line">        result = cv2.warpPerspective(imageA, H, (imageA.shape[<span class="number">1</span>] + imageB.shape[<span class="number">1</span>], imageA.shape[<span class="number">0</span>]))</span><br><span class="line">        result[<span class="number">0</span>:imageB.shape[<span class="number">0</span>], <span class="number">0</span>:imageB.shape[<span class="number">1</span>]] = imageB</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> showMatches:  <span class="comment"># check to see if the keypoint matches should be visualized</span></span><br><span class="line">            vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches, status)</span><br><span class="line">            <span class="keyword">return</span> (result, vis)  <span class="comment"># return a tuple of the stitched image and the visualization</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">return</span> result  <span class="comment"># return the stitched image</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detectAndDescribe</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  <span class="comment"># convert the image to grayscale</span></span><br><span class="line">​</span><br><span class="line">        <span class="keyword">if</span> self.isv3:  <span class="comment"># check to see if we are using OpenCV 3.X</span></span><br><span class="line">            descriptor = cv2.xfeatures2d.SIFT_create()  <span class="comment"># detect and extract features from the image</span></span><br><span class="line">            (kps, features) = descriptor.detectAndCompute(image, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># otherwise, we are using OpenCV 2.4.X</span></span><br><span class="line">            detector = cv2.FeatureDetector_create(<span class="string">"SIFT"</span>)  <span class="comment"># detect keypoints in the image</span></span><br><span class="line">            kps = detector.detect(gray)</span><br><span class="line">            extractor = cv2.DescriptorExtractor_create(<span class="string">"SIFT"</span>)  <span class="comment"># extract features from the image</span></span><br><span class="line">            (kps, features) = extractor.compute(gray, kps)</span><br><span class="line">​</span><br><span class="line">        kps = np.float32([kp.pt <span class="keyword">for</span> kp <span class="keyword">in</span> kps])  <span class="comment"># convert the keypoints from KeyPoint objects to NumPy arrays</span></span><br><span class="line">        <span class="keyword">return</span> (kps, features)  <span class="comment"># return a tuple of keypoints and features</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">matchKeypoints</span><span class="params">(self, kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span>:</span></span><br><span class="line">        <span class="comment"># compute the raw matches and initialize the list of actual matches</span></span><br><span class="line">        matcher = cv2.DescriptorMatcher_create(<span class="string">"BruteForce"</span>)</span><br><span class="line">        rawMatches = matcher.knnMatch(featuresA, featuresB, <span class="number">2</span>)</span><br><span class="line">        matches = []</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> rawMatches:  <span class="comment"># loop over the raw matches</span></span><br><span class="line">            <span class="comment"># ensure the distance is within a certain ratio of each other (i.e. Lowe's ratio test)</span></span><br><span class="line">            <span class="keyword">if</span> len(m) == <span class="number">2</span> <span class="keyword">and</span> m[<span class="number">0</span>].distance &lt; m[<span class="number">1</span>].distance * ratio:</span><br><span class="line">                matches.append((m[<span class="number">0</span>].trainIdx, m[<span class="number">0</span>].queryIdx))</span><br><span class="line">        <span class="keyword">if</span> len(matches) &gt; <span class="number">4</span>:  <span class="comment"># computing a homography requires at least 4 matches</span></span><br><span class="line">            <span class="comment"># construct the two sets of points</span></span><br><span class="line">            ptsA = np.float32([kpsA[i] <span class="keyword">for</span> (_, i) <span class="keyword">in</span> matches])</span><br><span class="line">            ptsB = np.float32([kpsB[i] <span class="keyword">for</span> (i, _) <span class="keyword">in</span> matches])</span><br><span class="line">            <span class="comment"># compute the homography between the two sets of points</span></span><br><span class="line">            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)</span><br><span class="line">            <span class="comment"># return the matches along with the homograpy matrix and status of each matched point</span></span><br><span class="line">            <span class="keyword">return</span> (matches, H, status)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span>  <span class="comment"># otherwise, no homograpy could be computed</span></span><br><span class="line">​</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drawMatches</span><span class="params">(self, imageA, imageB, kpsA, kpsB, matches, status)</span>:</span></span><br><span class="line">        <span class="comment"># initialize the output visualization image</span></span><br><span class="line">        (hA, wA) = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">        (hB, wB) = imageB.shape[:<span class="number">2</span>]</span><br><span class="line">        vis = np.zeros((max(hA, hB), wA + wB, <span class="number">3</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">        vis[<span class="number">0</span>:hA, <span class="number">0</span>:wA] = imageA</span><br><span class="line">        vis[<span class="number">0</span>:hB, wA:] = imageB</span><br><span class="line">​</span><br><span class="line">        <span class="keyword">for</span> ((trainIdx, queryIdx), s) <span class="keyword">in</span> zip(matches, status):  <span class="comment"># loop over the matches</span></span><br><span class="line">            <span class="keyword">if</span> s == <span class="number">1</span>:  <span class="comment"># only process the match if the keypoint was successfully matched</span></span><br><span class="line">                <span class="comment"># draw the match</span></span><br><span class="line">                ptA = (int(kpsA[queryIdx][<span class="number">0</span>]), int(kpsA[queryIdx][<span class="number">1</span>]))</span><br><span class="line">                ptB = (int(kpsB[trainIdx][<span class="number">0</span>]) + wA, int(kpsB[trainIdx][<span class="number">1</span>]))</span><br><span class="line">                cv2.line(vis, ptA, ptB, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> vis  <span class="comment"># return the visualization</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Let’s go ahead and get started by reviewing <code>panorama.py</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">​</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stitcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.isv3 = imutils.is_cv3()  <span class="comment"># determine if we are using OpenCV v3.X</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;We start off on <code>Lines 1-3</code> by importing our necessary packages. We’ll be using <code>NumPy</code> for <code>matrix/array</code> operations, <code>imutils</code> for a set of <code>OpenCV</code> convenience methods, and finally <code>cv2</code> for our <code>OpenCV</code> bindings.<br>&emsp;&emsp;From there, we define the <code>Stitcher</code> class on <code>Line 5</code>. The constructor to <code>Stitcher</code> simply checks which version of <code>OpenCV</code> we are using by making a call to the <code>is_cv3</code> method. Since there are major differences in how <code>OpenCV 2.4</code> and <code>OpenCV 3</code> handle keypoint detection and local invariant descriptors, it’s important that we determine the version of <code>OpenCV</code> that we are using.<br>&emsp;&emsp;Next up, let’s start working on the <code>stitch</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stitch</span><span class="params">(self, images, ratio=<span class="number">0.75</span>, reprojThresh=<span class="number">4.0</span>, showMatches=False)</span>:</span></span><br><span class="line">    <span class="comment"># unpack the images, then detect keypoints and extract local invariant descriptors from them</span></span><br><span class="line">    (imageB, imageA) = images</span><br><span class="line">    (kpsA, featuresA) = self.detectAndDescribe(imageA)</span><br><span class="line">    (kpsB, featuresB) = self.detectAndDescribe(imageB)</span><br><span class="line">    <span class="comment"># match features between the two images</span></span><br><span class="line">    M = self.matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span><br><span class="line">    <span class="keyword">if</span> M <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment"># if the match is None, then there aren't enough matched keypoints to create a panorama</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>stitch</code> method requires only a single parameter, <code>images</code>, which is the list of (two) images that we are going to <code>stitch</code> together to form the panorama.<br>&emsp;&emsp;We can also optionally supply <code>ratio</code>, used for <code>David Lowe&#39;s</code> ratio test when matching features, <code>reprojThresh</code> which is the maximum pixel <code>wiggle room</code> allowed by the <code>RANSAC</code> algorithm, and finally <code>showMatches</code>, a <code>boolean</code> used to indicate if the keypoint matches should be visualized or not.<br>&emsp;&emsp;<code>Line 3</code> unpacks the <code>images</code> list (which again, we presume to contain only two images). The ordering to the <code>images</code> list is important: we expect <code>images</code> to be supplied in <code>left-to-right</code> order. If <code>images</code> are not supplied in this order, then our code will still run, but our output panorama will only contain one image, not both.<br>&emsp;&emsp;Once we have unpacked the <code>images</code> list, we make a call to the <code>detectAndDescribe</code> method on <code>Lines 4</code> and <code>5</code>. This method simply detects keypoints and extracts local invariant descriptors (i.e. <code>SIFT</code>) from the two images.<br>&emsp;&emsp;Given the keypoints and features, we use <code>matchKeypoints</code> (Lines <code>7</code>) to match the features in the two images. We’ll define this method later in the lesson.<br>&emsp;&emsp;If the returned matches <code>M</code> are <code>None</code>, then not enough keypoints were matched to create a panorama, so we simply return to the calling function.<br>&emsp;&emsp;Otherwise, we are now ready to apply the perspective transform:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(matches, H, status) = M  <span class="comment"># otherwise, apply a perspective warp to stitch the images together</span></span><br><span class="line">result = cv2.warpPerspective(imageA, H, (imageA.shape[<span class="number">1</span>] + imageB.shape[<span class="number">1</span>], imageA.shape[<span class="number">0</span>]))</span><br><span class="line">result[<span class="number">0</span>:imageB.shape[<span class="number">0</span>], <span class="number">0</span>:imageB.shape[<span class="number">1</span>]] = imageB</span><br><span class="line">​</span><br><span class="line"><span class="keyword">if</span> showMatches:  <span class="comment"># check to see if the keypoint matches should be visualized</span></span><br><span class="line">    vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches, status)</span><br><span class="line">    <span class="keyword">return</span> (result, vis)  <span class="comment"># return a tuple of the stitched image and the visualization</span></span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> result  <span class="comment"># return the stitched image</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Provided that <code>M</code> is not <code>None</code>, we unpack the tuple on <code>Line 1</code>, giving us a list of keypoint matches, the homography matrix <code>H</code> derived from the <code>RANSAC</code> algorithm, and finally status, a list of indexes to indicate which keypoints in matches were successfully spatially verified using <code>RANSAC</code>.<br>&emsp;&emsp;Given our homography matrix <code>H</code>, we are now ready to stitch the two images together. First, we make a call to <code>cv2.warpPerspective</code> which requires three arguments: the image we want to warp (in this case, the right image), the <code>3 x 3</code> transformation matrix (<code>H</code>), and finally the shape out of the output image. We derive the shape out of the output image by taking the sum of the widths of both images and then using the height of the second image.<br>&emsp;&emsp;<code>Line 5</code> makes a check to see if we should visualize the keypoint matches, and if so, we make a call to <code>drawMatches</code> and return a tuple of both the panorama and visualization to the calling method. Otherwise, we simply returned the stitched image.<br>&emsp;&emsp;Now that the stitch method has been defined, let’s look into some of the helper methods that it calls. We’ll start with <code>detectAndDescribe</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectAndDescribe</span><span class="params">(self, image)</span>:</span></span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  <span class="comment"># convert the image to grayscale</span></span><br><span class="line">    <span class="keyword">if</span> self.isv3:  <span class="comment"># check to see if we are using OpenCV 3.X</span></span><br><span class="line">        descriptor = cv2.xfeatures2d.SIFT_create()  <span class="comment"># detect and extract features from the image</span></span><br><span class="line">        (kps, features) = descriptor.detectAndCompute(image, <span class="keyword">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># otherwise, we are using OpenCV 2.4.X</span></span><br><span class="line">        detector = cv2.FeatureDetector_create(<span class="string">"SIFT"</span>)  <span class="comment"># detect keypoints in the image</span></span><br><span class="line">        kps = detector.detect(gray)</span><br><span class="line">        extractor = cv2.DescriptorExtractor_create(<span class="string">"SIFT"</span>)  <span class="comment"># extract features from the image</span></span><br><span class="line">        (kps, features) = extractor.compute(gray, kps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert the keypoints from KeyPoint objects to NumPy arrays</span></span><br><span class="line">    kps = np.float32([kp.pt <span class="keyword">for</span> kp <span class="keyword">in</span> kps])</span><br><span class="line">    <span class="keyword">return</span> (kps, features)  <span class="comment"># return a tuple of keypoints and features</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;As the name suggests, the <code>detectAndDescribe</code> method accepts an image, then detects keypoints and extracts local invariant descriptors. In our implementation we use the <code>Difference of Gaussian</code> (<code>DoG</code>) keypoint detector and the <code>SIFT</code> feature extractor.<br>&emsp;&emsp;On <code>Line 3</code> we check to see if we are using <code>OpenCV 3.X</code>. If we are, then we use the <code>cv2.xfeatures2d.SIFT_create</code> function to instantiate both our <code>DoG</code> keypoint detector and <code>SIFT</code> feature extractor. A call to <code>detectAndCompute</code> handles extracting the keypoints and features.<br>&emsp;&emsp;<code>Lines 7-10</code> handle if we are using <code>OpenCV 2.4</code>. The <code>cv2.FeatureDetector_create</code> function instantiates our keypoint detector (<code>DoG</code>). A call to detect returns our set of keypoints.<br>&emsp;&emsp;From there, we need to initialize <code>cv2.DescriptorExtractor_create</code> using the <code>SIFT</code> keyword to setup our <code>SIFT</code> feature extractor. Calling the compute method of the extractor returns a set of feature vectors which quantify the region surrounding each of the detected keypoints in the image.<br>&emsp;&emsp;Finally, our keypoints are converted from <code>KeyPoint</code> objects to a <code>NumPy</code> array and returned to the calling method.<br>&emsp;&emsp;Next up, let’s look at the <code>matchKeypoints</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matchKeypoints</span><span class="params">(self, kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)</span>:</span></span><br><span class="line">    <span class="comment"># compute the raw matches and initialize the list of actual matches</span></span><br><span class="line">    matcher = cv2.DescriptorMatcher_create(<span class="string">"BruteForce"</span>)</span><br><span class="line">    rawMatches = matcher.knnMatch(featuresA, featuresB, <span class="number">2</span>)</span><br><span class="line">    matches = []</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> rawMatches:  <span class="comment"># loop over the raw matches</span></span><br><span class="line">        <span class="comment"># ensure the distance is within a certain ratio of each other (i.e. Lowe's ratio test)</span></span><br><span class="line">        <span class="keyword">if</span> len(m) == <span class="number">2</span> <span class="keyword">and</span> m[<span class="number">0</span>].distance &lt; m[<span class="number">1</span>].distance * ratio:</span><br><span class="line">            matches.append((m[<span class="number">0</span>].trainIdx, m[<span class="number">0</span>].queryIdx))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;The <code>matchKeypoints</code> function requires four arguments: the keypoints and feature vectors associated with the first image, followed by the keypoints and feature vectors associated with the second image. <code>David Lowe&#39;s</code> ratio test variable and <code>RANSAC</code> <code>re-projection</code> threshold are also be supplied.<br>&emsp;&emsp;Matching features together is actually a fairly straightforward process. We simply loop over the descriptors from both images, compute the distances, and find the smallest distance for each pair of descriptors. Since this is a very common practice in computer vision, <code>OpenCV</code> has a <code>built-in</code> function called <code>cv2.DescriptorMatcher_create</code> that constructs the feature matcher for us. The <code>BruteForce</code> value indicates that we are going to exhaustively compute the <code>Euclidean</code> distance between all feature vectors from both images and find the pairs of descriptors that have the smallest distance.<br>&emsp;&emsp;A call to <code>knnMatch</code> on <code>Line 4</code> performs <code>k-NN</code> matching between the two feature vector sets using <code>k=2</code> (indicating the top two matches for each feature vector are returned).<br>&emsp;&emsp;The reason we want the top two matches rather than just the top one match is because we need to apply <code>David Lowe&#39;s</code> ratio test for <code>false-positive</code> match pruning.<br>&emsp;&emsp;Again, <code>Line 4</code> computes the <code>rawMatches</code> for each pair of descriptors, but there is a chance that some of these pairs are <code>false</code> positives, meaning that the image patches are not actually true matches. In an attempt to prune these <code>false-positive</code> matches, we can loop over each of the <code>rawMatches</code> individually and apply <code>Lowe&#39;s</code> ratio test, which is used to determine <code>high-quality</code> feature matches. Typical values for <code>Lowe&#39;s</code> ratio are normally in the range <code>[0.7, 0.8]</code>.<br>&emsp;&emsp;Once we have obtained the matches using <code>Lowe&#39;s</code> ratio test, we can compute the homography between the two sets of keypoints:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> len(matches) &gt; <span class="number">4</span>:  <span class="comment"># computing a homography requires at least 4 matches</span></span><br><span class="line">    <span class="comment"># construct the two sets of points</span></span><br><span class="line">    ptsA = np.float32([kpsA[i] <span class="keyword">for</span> (_, i) <span class="keyword">in</span> matches])</span><br><span class="line">    ptsB = np.float32([kpsB[i] <span class="keyword">for</span> (i, _) <span class="keyword">in</span> matches])</span><br><span class="line">    <span class="comment"># compute the homography between the two sets of points</span></span><br><span class="line">    (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)</span><br><span class="line">    <span class="comment"># return the matches along with the homograpy matrix and status of each matched point</span></span><br><span class="line">    <span class="keyword">return</span> (matches, H, status)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">None</span> <span class="comment"># otherwise, no homograpy could be computed</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;Computing a homography between two sets of points requires at a bare minimum an initial set of four matches. For a more reliable homography estimation, we should have substantially more than just four matched points.<br>&emsp;&emsp;Finally, the last method in our <code>Stitcher</code> method, <code>drawMatches</code> is used to visualize keypoint correspondences between two images:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawMatches</span><span class="params">(self, imageA, imageB, kpsA, kpsB, matches, status)</span>:</span></span><br><span class="line">    <span class="comment"># initialize the output visualization image</span></span><br><span class="line">    (hA, wA) = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">    (hB, wB) = imageB.shape[:<span class="number">2</span>]</span><br><span class="line">    vis = np.zeros((max(hA, hB), wA + wB, <span class="number">3</span>), dtype=<span class="string">"uint8"</span>)</span><br><span class="line">    vis[<span class="number">0</span>:hA, <span class="number">0</span>:wA] = imageA</span><br><span class="line">    vis[<span class="number">0</span>:hB, wA:] = imageB</span><br><span class="line">    <span class="keyword">for</span> ((trainIdx, queryIdx), s) <span class="keyword">in</span> zip(matches, status):  <span class="comment"># loop over the matches</span></span><br><span class="line">        <span class="keyword">if</span> s == <span class="number">1</span>:  <span class="comment"># only process the match if the keypoint was successfully matched</span></span><br><span class="line">            <span class="comment"># draw the match</span></span><br><span class="line">            ptA = (int(kpsA[queryIdx][<span class="number">0</span>]), int(kpsA[queryIdx][<span class="number">1</span>]))</span><br><span class="line">            ptB = (int(kpsB[trainIdx][<span class="number">0</span>]) + wA, int(kpsB[trainIdx][<span class="number">1</span>]))</span><br><span class="line">            cv2.line(vis, ptA, ptB, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> vis  <span class="comment"># return the visualization</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;This method requires that we pass in the two original images, the set of keypoints associated with each image, the initial matches after applying <code>Lowe&#39;s</code> ratio test, and finally the status list provided by the homography calculation. Using these variables, we can visualize the <code>inlier</code> keypoints by drawing a straight line from keypoint <code>N</code> in the first image to keypoint <code>M</code> in the second image.<br>&emsp;&emsp;示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> Stitcher</span><br><span class="line">​</span><br><span class="line">imageA = cv2.imread(<span class="string">"Panorama-1.png"</span>)</span><br><span class="line">imageB = cv2.imread(<span class="string">"Panorama-2.png"</span>)</span><br><span class="line">​</span><br><span class="line">print(<span class="string">"former size is:"</span>)</span><br><span class="line">print(imageA.shape)</span><br><span class="line">print(imageB.shape)</span><br><span class="line"><span class="comment"># 使图片的高度相等</span></span><br><span class="line">height, width = imageA.shape[:<span class="number">2</span>]</span><br><span class="line">imageB = imutils.resize(imageB, height=height)</span><br><span class="line">print(<span class="string">"after size is:"</span>)</span><br><span class="line">print(imageA.shape)</span><br><span class="line">print(imageB.shape)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># stitch the images together to create a panorama</span></span><br><span class="line">stitcher = Stitcher()</span><br><span class="line">(result, vis) = stitcher.stitch([imageA, imageB], showMatches=<span class="keyword">True</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># show the images</span></span><br><span class="line">cv2.imshow(<span class="string">"Image A"</span>, imageA)</span><br><span class="line">cv2.imshow(<span class="string">"Image B"</span>, imageB)</span><br><span class="line">cv2.imshow(<span class="string">"Keypoint Matches"</span>, vis)</span><br><span class="line">cv2.imshow(<span class="string">"Result"</span>, result)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/3.png" height="236" width="572"></p>
<p><img src="/2019/03/07/opencv和图像处理/全景拼接/4.png" height="470" width="573"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/07/opencv和图像处理/meanshift跟踪算法/" rel="next" title="meanshift跟踪算法">
                <i class="fa fa-chevron-left"></i> meanshift跟踪算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/07/opencv和图像处理/位操作/" rel="prev" title="位操作">
                位操作 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">付康为</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">949</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于OpenCV全景拼接"><span class="nav-number">1.</span> <span class="nav-text">基于OpenCV全景拼接</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">付康为</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  


  

  

</body>
</html>
